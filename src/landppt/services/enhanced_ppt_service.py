"""
Enhanced PPT Service with real AI integration and project management
"""

import json
import re
import logging
import uuid
import asyncio
import time
import os
import tempfile
from pathlib import Path
from typing import Dict, Any, List, Optional

from ..api.models import (
    PPTGenerationRequest, PPTOutline, EnhancedPPTOutline,
    SlideContent, PPTProject, TodoBoard
)
from ..ai import get_ai_provider, AIMessage, MessageRole
from ..core.config import ai_config
from .ppt_service import PPTService
from .db_project_manager import DatabaseProjectManager
from .global_master_template_service import GlobalMasterTemplateService
from .deep_research_service import DEEPResearchService
from .research_report_generator import ResearchReportGenerator
from .research.enhanced_research_service import EnhancedResearchService
from .research.enhanced_report_generator import EnhancedReportGenerator
from .prompts import prompts_manager
from .image.image_service import ImageService
from .image.adapters.ppt_prompt_adapter import PPTSlideContext
from ..utils.thread_pool import run_blocking_io, to_thread

# Configure logger for this module
logger = logging.getLogger(__name__)

class EnhancedPPTService(PPTService):
    """Enhanced PPT service with real AI integration and project management"""

    def __init__(self, provider_name: Optional[str] = None):
        super().__init__()
        self.provider_name = provider_name
        self.project_manager = DatabaseProjectManager()
        self.global_template_service = GlobalMasterTemplateService(provider_name)

        # é…ç½®å±žæ€§ï¼Œç”¨äºŽsummeryanyfileé›†æˆ
        # åˆå§‹åŒ–é…ç½®ï¼ˆå°†åœ¨éœ€è¦æ—¶å®žæ—¶æ›´æ–°ï¼‰
        self.config = self._get_current_ai_config()

        # åˆå§‹åŒ–æ–‡ä»¶ç¼“å­˜ç®¡ç†å™¨ - è®¾ç½®ç¼“å­˜ç›®å½•åˆ°é¡¹ç›®æ ¹ç›®å½•ä¸‹çš„tempæ–‡ä»¶å¤¹ï¼Œæ¯ä¸ªæ¨¡å¼çš„ç¼“å­˜åˆ†å¼€ç®¡ç†
        try:
            from summeryanyfile.core.file_cache_manager import FileCacheManager
            import os
            from pathlib import Path

            # èŽ·å–é¡¹ç›®æ ¹ç›®å½•
            project_root = Path(__file__).parent.parent.parent.parent

            # ä¸ºä¸åŒæ¨¡å¼åˆ›å»ºåˆ†ç¦»çš„ç¼“å­˜ç›®å½•
            base_cache_dir = project_root / "temp"

            # åˆ›å»ºåˆ†æ¨¡å¼çš„ç¼“å­˜ç›®å½•ç»“æž„
            cache_dirs = {
                'summeryanyfile': base_cache_dir / "summeryanyfile_cache",
                'style_genes': base_cache_dir / "style_genes_cache",
                'ai_responses': base_cache_dir / "ai_responses_cache",
                'templates': base_cache_dir / "templates_cache"
            }

            # ç¡®ä¿æ‰€æœ‰ç¼“å­˜ç›®å½•å­˜åœ¨
            for cache_type, cache_path in cache_dirs.items():
                cache_path.mkdir(parents=True, exist_ok=True)

            # åˆå§‹åŒ–ä¸»è¦çš„æ–‡ä»¶ç¼“å­˜ç®¡ç†å™¨ï¼ˆç”¨äºŽsummeryanyfileï¼‰
            self.file_cache_manager = FileCacheManager(cache_dir=str(cache_dirs['summeryanyfile']))

            # å­˜å‚¨ç¼“å­˜ç›®å½•é…ç½®ä¾›å…¶ä»–åŠŸèƒ½ä½¿ç”¨
            self.cache_dirs = cache_dirs

            logger.info(f"æ–‡ä»¶ç¼“å­˜ç®¡ç†å™¨å·²åˆå§‹åŒ–ï¼Œåˆ†æ¨¡å¼ç¼“å­˜ç›®å½•: {cache_dirs}")
        except ImportError as e:
            logger.warning(f"æ— æ³•å¯¼å…¥æ–‡ä»¶ç¼“å­˜ç®¡ç†å™¨: {e}")
            self.file_cache_manager = None
            self.cache_dirs = None

        # åˆå§‹åŒ–ç ”ç©¶æœåŠ¡
        self.research_service = None
        self.report_generator = None
        self._initialize_research_services()

        # åˆå§‹åŒ–å›¾ç‰‡æœåŠ¡
        self.image_service = None
        self._initialize_image_service()

    @property
    def ai_provider(self):
        """Dynamically get AI provider to ensure latest config"""
        provider_name = self.provider_name or ai_config.default_ai_provider
        return get_ai_provider(provider_name)

    def _initialize_research_services(self):
        """Initialize research services if available"""
        try:
            # Initialize legacy research service
            self.research_service = DEEPResearchService()
            self.report_generator = ResearchReportGenerator()

            # Initialize enhanced research service
            self.enhanced_research_service = EnhancedResearchService()
            self.enhanced_report_generator = EnhancedReportGenerator()

            # Check availability
            legacy_available = self.research_service.is_available()
            enhanced_available = self.enhanced_research_service.is_available()

            if enhanced_available:
                logger.info("Enhanced Research service initialized successfully")
                available_providers = self.enhanced_research_service.get_available_providers()
                logger.info(f"Available research providers: {', '.join(available_providers)}")
            elif legacy_available:
                logger.info("DEEP Research service initialized successfully")
            else:
                logger.warning("No research services available - check API configurations")

        except Exception as e:
            logger.warning(f"Failed to initialize research services: {e}")
            self.research_service = None
            self.report_generator = None
            self.enhanced_research_service = None
            self.enhanced_report_generator = None

    def _convert_enhanced_to_legacy_report(self, enhanced_report):
        """Convert enhanced research report to legacy format for compatibility"""
        try:
            from .deep_research_service import ResearchReport, ResearchStep

            # Convert enhanced steps to legacy steps
            legacy_steps = []
            for enhanced_step in enhanced_report.steps:
                # Combine all search results for legacy format
                combined_results = []

                if enhanced_step.tavily_results:
                    combined_results.extend(enhanced_step.tavily_results)

                if enhanced_step.searxng_results:
                    for result in enhanced_step.searxng_results.results:
                        combined_results.append({
                            'url': result.url,
                            'title': result.title,
                            'content': result.content,
                            'score': result.score
                        })

                legacy_step = ResearchStep(
                    step_number=enhanced_step.step_number,
                    query=enhanced_step.query,
                    description=enhanced_step.description,
                    results=combined_results,
                    analysis=enhanced_step.analysis,
                    completed=enhanced_step.completed
                )
                legacy_steps.append(legacy_step)

            # Create legacy report
            legacy_report = ResearchReport(
                topic=enhanced_report.topic,
                language=enhanced_report.language,
                steps=legacy_steps,
                executive_summary=enhanced_report.executive_summary,
                key_findings=enhanced_report.key_findings,
                recommendations=enhanced_report.recommendations,
                sources=enhanced_report.sources,
                created_at=enhanced_report.created_at,
                total_duration=enhanced_report.total_duration
            )

            return legacy_report

        except Exception as e:
            logger.error(f"Failed to convert enhanced report to legacy format: {e}")
            return None

    def _initialize_image_service(self):
        """Initialize image service"""
        try:
            from .image.config.image_config import get_image_config

            # èŽ·å–å›¾ç‰‡æœåŠ¡é…ç½®
            config_manager = get_image_config()
            image_config = config_manager.get_config()

            # æ›´æ–°ç¼“å­˜ç›®å½•é…ç½®
            if self.cache_dirs:
                image_config['cache']['base_dir'] = str(self.cache_dirs['ai_responses'] / 'images_cache')

            # éªŒè¯é…ç½®
            config_errors = config_manager.validate_config()
            if config_errors:
                logger.warning(f"Image service configuration errors: {config_errors}")

            # æ£€æŸ¥å·²é…ç½®çš„æä¾›è€…
            configured_providers = config_manager.get_configured_providers()
            if configured_providers:
                logger.info(f"Configured image providers: {configured_providers}")
            else:
                logger.warning("No image providers configured. Please set API keys in environment variables.")

            self.image_service = ImageService(image_config)
            # å¼‚æ­¥åˆå§‹åŒ–å›¾ç‰‡æœåŠ¡
            import asyncio
            if asyncio.get_event_loop().is_running():
                # å¦‚æžœåœ¨å¼‚æ­¥çŽ¯å¢ƒä¸­ï¼Œåˆ›å»ºä»»åŠ¡æ¥åˆå§‹åŒ–
                asyncio.create_task(self._async_initialize_image_service())
            else:
                # å¦‚æžœä¸åœ¨å¼‚æ­¥çŽ¯å¢ƒä¸­ï¼ŒåŒæ­¥åˆå§‹åŒ–
                asyncio.run(self.image_service.initialize())
            logger.info("Image service initialized successfully")

        except Exception as e:
            logger.warning(f"Failed to initialize image service: {e}")
            self.image_service = None

    async def _async_initialize_image_service(self):
        """å¼‚æ­¥åˆå§‹åŒ–å›¾ç‰‡æœåŠ¡"""
        try:
            if self.image_service and not self.image_service.initialized:
                await self.image_service.initialize()
                logger.debug("Image service async initialization completed")
        except Exception as e:
            logger.error(f"Failed to async initialize image service: {e}")

    def reload_research_config(self):
        """Reload research service configuration"""
        if self.research_service:
            try:
                self.research_service.reload_config()
                logger.info("Research service configuration reloaded in EnhancedPPTService")
            except Exception as e:
                logger.warning(f"Failed to reload research service config: {e}")
                # If reload fails, reinitialize
                self._initialize_research_services()

    def _get_model_name_for_provider(self, provider_name: str) -> str:
        """æ ¹æ®providerèŽ·å–æ­£ç¡®çš„æ¨¡åž‹åç§°"""
        if provider_name == "openai":
            return ai_config.openai_model
        elif provider_name == "anthropic":
            return ai_config.anthropic_model
        elif provider_name == "ollama":
            return ai_config.ollama_model
        elif provider_name == "google" or provider_name == "gemini":
            return ai_config.google_model
        else:
            # é»˜è®¤è¿”å›žOpenAIæ¨¡åž‹
            return ai_config.openai_model

    def _get_current_ai_config(self):
        """èŽ·å–å½“å‰æœ€æ–°çš„AIé…ç½®"""
        current_provider = self.provider_name or ai_config.default_ai_provider
        model_name = self._get_model_name_for_provider(current_provider)

        return {
            "llm_model": model_name,
            "llm_provider": current_provider,
            "temperature": getattr(ai_config, 'temperature', 0.7),
            "max_tokens": getattr(ai_config, 'max_tokens', 2000)
        }

    def update_ai_config(self):
        """æ›´æ–°AIé…ç½®åˆ°æœ€æ–°çŠ¶æ€"""
        self.config = self._get_current_ai_config()
        logger.info(f"AIé…ç½®å·²æ›´æ–°: provider={self.config['llm_provider']}, model={self.config['llm_model']}")

    def _configure_summeryfile_api(self, generator):
        """é…ç½®summeryanyfileçš„APIè®¾ç½®"""
        try:
            import os
            # èŽ·å–å½“å‰providerçš„é…ç½®
            current_provider = self.provider_name or ai_config.default_ai_provider
            provider_config = ai_config.get_provider_config(current_provider)

            # è®¾ç½®é€šç”¨é…ç½®å‚æ•°
            if provider_config.get("max_tokens"):
                os.environ["MAX_TOKENS"] = str(provider_config["max_tokens"])
            if provider_config.get("temperature"):
                os.environ["TEMPERATURE"] = str(provider_config["temperature"])

            if current_provider == "openai":
                # è®¾ç½®OpenAI APIé…ç½®
                if provider_config.get("api_key"):
                    os.environ["OPENAI_API_KEY"] = provider_config["api_key"]
                if provider_config.get("base_url"):
                    os.environ["OPENAI_BASE_URL"] = provider_config["base_url"]

                logger.info(f"å·²é…ç½®summeryanyfile OpenAI API: model={provider_config.get('model')}, base_url={provider_config.get('base_url')}")

            elif current_provider == "anthropic":
                # è®¾ç½®Anthropic APIé…ç½®
                if provider_config.get("api_key"):
                    os.environ["ANTHROPIC_API_KEY"] = provider_config["api_key"]

                logger.info(f"å·²é…ç½®summeryanyfile Anthropic API: model={provider_config.get('model')}")

            elif current_provider == "google" or current_provider == "gemini":
                # è®¾ç½®Google/Gemini APIé…ç½®
                if provider_config.get("api_key"):
                    os.environ["GOOGLE_API_KEY"] = provider_config["api_key"]

                logger.info(f"å·²é…ç½®summeryanyfile Google/Gemini API: model={provider_config.get('model')}")

            elif current_provider == "ollama":
                # è®¾ç½®Ollama APIé…ç½®
                if provider_config.get("base_url"):
                    os.environ["OLLAMA_BASE_URL"] = provider_config["base_url"]

                logger.info(f"å·²é…ç½®summeryanyfile Ollama API: model={provider_config.get('model')}, base_url={provider_config.get('base_url')}")

            logger.info(f"å·²é…ç½®summeryanyfileé€šç”¨å‚æ•°: max_tokens={provider_config.get('max_tokens')}, temperature={provider_config.get('temperature')}")

        except Exception as e:
            logger.warning(f"é…ç½®summeryanyfile APIæ—¶å‡ºé”™: {e}")

    def get_cache_stats(self) -> Dict[str, Any]:
        """
        èŽ·å–æ–‡ä»¶ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯

        Returns:
            ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        if self.file_cache_manager:
            return self.file_cache_manager.get_cache_stats()
        else:
            return {"error": "ç¼“å­˜ç®¡ç†å™¨æœªåˆå§‹åŒ–"}

    def cleanup_cache(self):
        """æ¸…ç†è¿‡æœŸçš„ç¼“å­˜æ¡ç›®"""
        # æ¸…ç†summeryanyfileç¼“å­˜
        if self.file_cache_manager:
            try:
                self.file_cache_manager.cleanup_expired_cache()
                logger.info("summeryanyfileç¼“å­˜æ¸…ç†å®Œæˆ")
            except Exception as e:
                logger.error(f"summeryanyfileç¼“å­˜æ¸…ç†å¤±è´¥: {e}")

        # æ¸…ç†è®¾è®¡åŸºå› ç¼“å­˜
        self._cleanup_style_genes_cache()

        # æ¸…ç†å†…å­˜ç¼“å­˜
        if hasattr(self, '_cached_style_genes'):
            self._cached_style_genes.clear()
            logger.info("å†…å­˜ä¸­çš„è®¾è®¡åŸºå› ç¼“å­˜å·²æ¸…ç†")

    def _cleanup_style_genes_cache(self, max_age_days: int = 7):
        """æ¸…ç†è¿‡æœŸçš„è®¾è®¡åŸºå› ç¼“å­˜æ–‡ä»¶"""
        if not hasattr(self, 'cache_dirs') or not self.cache_dirs:
            return

        try:
            import json
            import time
            from pathlib import Path

            cache_dir = self.cache_dirs['style_genes']
            if not cache_dir.exists():
                return

            current_time = time.time()
            max_age_seconds = max_age_days * 24 * 3600
            cleaned_count = 0

            for cache_file in cache_dir.glob("*_style_genes.json"):
                try:
                    with open(cache_file, 'r', encoding='utf-8') as f:
                        cache_data = json.load(f)
                        created_at = cache_data.get('created_at', 0)

                    if current_time - created_at > max_age_seconds:
                        cache_file.unlink()
                        cleaned_count += 1
                        logger.debug(f"åˆ é™¤è¿‡æœŸçš„è®¾è®¡åŸºå› ç¼“å­˜æ–‡ä»¶: {cache_file.name}")

                except Exception as e:
                    logger.warning(f"å¤„ç†ç¼“å­˜æ–‡ä»¶ {cache_file} æ—¶å‡ºé”™: {e}")

            if cleaned_count > 0:
                logger.info(f"è®¾è®¡åŸºå› ç¼“å­˜æ¸…ç†å®Œæˆï¼Œåˆ é™¤äº† {cleaned_count} ä¸ªè¿‡æœŸæ–‡ä»¶")
            else:
                logger.info("è®¾è®¡åŸºå› ç¼“å­˜æ¸…ç†å®Œæˆï¼Œæ²¡æœ‰è¿‡æœŸæ–‡ä»¶éœ€è¦åˆ é™¤")

        except Exception as e:
            logger.error(f"è®¾è®¡åŸºå› ç¼“å­˜æ¸…ç†å¤±è´¥: {e}")

    async def generate_outline(self, request: PPTGenerationRequest, page_count_settings: Dict[str, Any] = None) -> PPTOutline:
        """Generate PPT outline using real AI with optional DEEP research and page count settings"""
        try:
            research_context = ""
            research_report = None

            # Check if network mode is enabled and research service is available
            if request.network_mode:
                # Try enhanced research service first, fallback to legacy
                if hasattr(self, 'enhanced_research_service') and self.enhanced_research_service.is_available():
                    logger.info(f"Starting Enhanced research for topic: {request.topic}")
                    try:
                        # Conduct enhanced research
                        enhanced_report = await self.enhanced_research_service.conduct_enhanced_research(
                            topic=request.topic,
                            language=request.language
                        )

                        # Convert enhanced report to legacy format for compatibility
                        research_report = self._convert_enhanced_to_legacy_report(enhanced_report)

                        # Save enhanced report
                        if hasattr(self, 'enhanced_report_generator'):
                            try:
                                report_path = self.enhanced_report_generator.save_report_to_file(enhanced_report)
                                logger.info(f"Enhanced research report saved to: {report_path}")
                            except Exception as save_error:
                                logger.warning(f"Failed to save enhanced research report: {save_error}")

                    except Exception as e:
                        logger.error(f"Enhanced research failed: {e}")
                        research_report = None

                elif self.research_service and self.research_service.is_available():
                    logger.info(f"Starting DEEP research for topic: {request.topic}")
                    try:
                        # Conduct DEEP research
                        research_report = await self.research_service.conduct_deep_research(
                            topic=request.topic,
                            language=request.language
                        )

                        # Generate research context for outline generation
                        research_context = self._create_research_context(research_report)
                        logger.info("DEEP research completed successfully")

                        # Save research report if generator is available
                        if self.report_generator:
                            try:
                                report_path = self.report_generator.save_report_to_file(research_report)
                                logger.info(f"Research report saved to: {report_path}")
                            except Exception as save_error:
                                logger.warning(f"Failed to save research report: {save_error}")

                    except Exception as research_error:
                        logger.warning(f"DEEP research failed, proceeding without research context: {research_error}")
                        research_context = ""
                else:
                    logger.info("Network mode enabled but no research services available")

            # Create AI prompt for outline generation (with or without research context and page count settings)
            prompt = self._create_outline_prompt(request, research_context, page_count_settings)

            # Generate outline using AI
            response = await self.ai_provider.text_completion(
                prompt=prompt,
                max_tokens=ai_config.max_tokens,
                temperature=ai_config.temperature
            )

            # Parse AI response to create structured outline
            outline = self._parse_ai_outline(response.content, request)

            # Add research metadata if available
            if research_report:
                outline.metadata["research_enhanced"] = True
                outline.metadata["research_duration"] = research_report.total_duration
                outline.metadata["research_sources"] = len(research_report.sources)

            # Add page count settings to metadata
            if page_count_settings:
                outline.metadata["page_count_settings"] = page_count_settings

            return outline

        except Exception as e:
            logger.error(f"Error generating AI outline: {str(e)}")
            # Fallback to original method
            return await super().generate_outline(request)
    
    async def generate_slide_content(self, slide_title: str, scenario: str, topic: str, language: str = "zh") -> str:
        """Generate slide content using AI"""
        try:
            prompt = self._create_slide_content_prompt(slide_title, scenario, topic, language)
            
            response = await self.ai_provider.text_completion(
                prompt=prompt,
                max_tokens=ai_config.max_tokens,  # Use smaller limit for slide content
                temperature=ai_config.temperature
            )
            
            return response.content.strip()
            
        except Exception as e:
            logger.error(f"Error generating slide content: {str(e)}")
            # Fallback to original method
            return self._generate_slide_content(topic, slide_title, scenario, language)
    
    async def enhance_content_with_ai(self, content: str, scenario: str, language: str = "zh") -> str:
        """Enhance existing content using AI"""
        try:
            prompt = self._create_enhancement_prompt(content, scenario, language)
            
            response = await self.ai_provider.text_completion(
                prompt=prompt,
                max_tokens=ai_config.max_tokens,  # Use smaller limit for content enhancement
                temperature=max(ai_config.temperature - 0.1, 0.1)  # Slightly lower temperature for enhancement
            )
            
            return response.content.strip()
            
        except Exception as e:
            logger.error(f"Error enhancing content: {str(e)}")
            return content  # Return original content if enhancement fails
    
    def _create_research_context(self, research_report) -> str:
        """Create comprehensive structured Markdown research context for outline generation"""
        if not research_report:
            return ""

        # æž„å»ºè¯¦ç»†çš„ç»“æž„åŒ–Markdownç ”ç©¶æŠ¥å‘Šå†…å®¹
        markdown_content = []

        # æ ‡é¢˜å’ŒåŸºæœ¬ä¿¡æ¯
        markdown_content.append(f"# {research_report.topic} - æ·±åº¦ç ”ç©¶æŠ¥å‘Š")
        markdown_content.append("")
        markdown_content.append("---")
        markdown_content.append("")

        # æŠ¥å‘Šå…ƒä¿¡æ¯
        markdown_content.append("## ðŸ“Š æŠ¥å‘Šä¿¡æ¯")
        markdown_content.append("")
        markdown_content.append(f"- **ç ”ç©¶ä¸»é¢˜**: {research_report.topic}")
        markdown_content.append(f"- **æŠ¥å‘Šè¯­è¨€**: {research_report.language}")
        markdown_content.append(f"- **ç”Ÿæˆæ—¶é—´**: {research_report.created_at.strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}")
        markdown_content.append(f"- **ç ”ç©¶è€—æ—¶**: {research_report.total_duration:.2f} ç§’")
        markdown_content.append(f"- **ç ”ç©¶æ­¥éª¤**: {len(research_report.steps)} ä¸ª")
        markdown_content.append(f"- **ä¿¡æ¯æ¥æº**: {len(research_report.sources)} ä¸ª")
        markdown_content.append("")

        # æ‰§è¡Œæ‘˜è¦
        if research_report.executive_summary:
            markdown_content.append("## ðŸ“‹ æ‰§è¡Œæ‘˜è¦")
            markdown_content.append("")
            markdown_content.append(research_report.executive_summary)
            markdown_content.append("")

        # å…³é”®å‘çŽ°
        if research_report.key_findings:
            markdown_content.append("## ðŸ” å…³é”®å‘çŽ°")
            markdown_content.append("")
            for i, finding in enumerate(research_report.key_findings, 1):
                markdown_content.append(f"### {i}. {finding}")
                markdown_content.append("")
            markdown_content.append("")

        # å»ºè®®ä¸ŽæŽ¨è
        if research_report.recommendations:
            markdown_content.append("## ðŸ’¡ å»ºè®®ä¸ŽæŽ¨è")
            markdown_content.append("")
            for i, recommendation in enumerate(research_report.recommendations, 1):
                markdown_content.append(f"### {i}. {recommendation}")
                markdown_content.append("")
            markdown_content.append("")

        # è¯¦ç»†ç ”ç©¶è¿‡ç¨‹å’Œåˆ†æž
        if research_report.steps:
            markdown_content.append("## ðŸ”¬ è¯¦ç»†ç ”ç©¶è¿‡ç¨‹")
            markdown_content.append("")
            markdown_content.append("æœ¬èŠ‚åŒ…å«äº†å®Œæ•´çš„ç ”ç©¶è¿‡ç¨‹ï¼Œæ¯ä¸ªæ­¥éª¤éƒ½åŒ…å«äº†æ·±å…¥çš„åˆ†æžå’Œæƒå¨çš„ä¿¡æ¯æ¥æºã€‚")
            markdown_content.append("")

            for step_num, step in enumerate(research_report.steps, 1):
                if step.completed and step.analysis:
                    markdown_content.append(f"### æ­¥éª¤ {step_num}: {step.description}")
                    markdown_content.append("")
                    markdown_content.append(f"**ðŸŽ¯ ç ”ç©¶ç›®æ ‡**: {step.description}")
                    markdown_content.append("")
                    markdown_content.append(f"**ðŸ” æœç´¢æŸ¥è¯¢**: `{step.query}`")
                    markdown_content.append("")
                    markdown_content.append("**ðŸ“Š ç ”ç©¶çŠ¶æ€**: âœ… å·²å®Œæˆ")
                    markdown_content.append("")

                    # è¯¦ç»†åˆ†æžç»“æžœ
                    markdown_content.append("#### ðŸ“ æ·±åº¦åˆ†æž")
                    markdown_content.append("")
                    markdown_content.append(step.analysis)
                    markdown_content.append("")

                    # è¯¦ç»†çš„ä¿¡æ¯æºåˆ—è¡¨
                    if step.results:
                        markdown_content.append("#### ðŸ“š æƒå¨ä¿¡æ¯æº")
                        markdown_content.append("")
                        markdown_content.append("ä»¥ä¸‹æ˜¯æœ¬ç ”ç©¶æ­¥éª¤ä¸­ä½¿ç”¨çš„ä¸»è¦ä¿¡æ¯æºï¼ŒæŒ‰ç›¸å…³æ€§æŽ’åºï¼š")
                        markdown_content.append("")

                        for i, result in enumerate(step.results[:5], 1):  # æ˜¾ç¤ºå‰5ä¸ªæ¥æº
                            title = result.get('title', 'æœªçŸ¥æ ‡é¢˜')
                            url = result.get('url', '#')
                            content = result.get('content', '')
                            score = result.get('score', 0)
                            published_date = result.get('published_date', '')

                            markdown_content.append(f"**{i}. [{title}]({url})**")
                            if published_date:
                                markdown_content.append(f"   - å‘å¸ƒæ—¶é—´: {published_date}")
                            if score:
                                markdown_content.append(f"   - ç›¸å…³æ€§è¯„åˆ†: {score:.2f}")
                            if content:
                                # æ˜¾ç¤ºå†…å®¹æ‘˜è¦ï¼ˆå‰300å­—ç¬¦ï¼‰
                                content_preview = content[:300] + "..." if len(content) > 300 else content
                                markdown_content.append(f"   - å†…å®¹æ‘˜è¦: {content_preview}")
                            markdown_content.append("")

                        # å¦‚æžœè¿˜æœ‰æ›´å¤šæ¥æºï¼Œæ˜¾ç¤ºç»Ÿè®¡
                        if len(step.results) > 5:
                            markdown_content.append(f"*æ³¨ï¼šæœ¬æ­¥éª¤å…±æ‰¾åˆ° {len(step.results)} ä¸ªç›¸å…³ä¿¡æ¯æºï¼Œä»¥ä¸Šæ˜¾ç¤ºå‰5ä¸ªæœ€ç›¸å…³çš„æ¥æºã€‚*")
                            markdown_content.append("")

                    markdown_content.append("---")
                    markdown_content.append("")

        # ç»¼åˆåˆ†æžå’Œç»“è®º
        markdown_content.append("## ðŸŽ¯ ç»¼åˆåˆ†æž")
        markdown_content.append("")
        markdown_content.append("åŸºäºŽä»¥ä¸Šå¤šç»´åº¦çš„æ·±åº¦ç ”ç©¶ï¼Œæˆ‘ä»¬å¯ä»¥å¾—å‡ºä»¥ä¸‹ç»¼åˆæ€§åˆ†æžï¼š")
        markdown_content.append("")

        # é‡æ–°æ•´ç†å…³é”®å‘çŽ°ä½œä¸ºç»¼åˆåˆ†æžçš„ä¸€éƒ¨åˆ†
        if research_report.key_findings:
            markdown_content.append("### æ ¸å¿ƒæ´žå¯Ÿ")
            markdown_content.append("")
            for finding in research_report.key_findings:
                markdown_content.append(f"- {finding}")
            markdown_content.append("")

        # é‡æ–°æ•´ç†å»ºè®®ä½œä¸ºè¡ŒåŠ¨æŒ‡å—
        if research_report.recommendations:
            markdown_content.append("### è¡ŒåŠ¨æŒ‡å—")
            markdown_content.append("")
            for recommendation in research_report.recommendations:
                markdown_content.append(f"- {recommendation}")
            markdown_content.append("")

        # å®Œæ•´çš„ä¿¡æ¯æºåˆ—è¡¨
        if research_report.sources:
            markdown_content.append("## ðŸ“– å®Œæ•´ä¿¡æ¯æºåˆ—è¡¨")
            markdown_content.append("")
            markdown_content.append("ä»¥ä¸‹æ˜¯æœ¬ç ”ç©¶ä¸­ä½¿ç”¨çš„æ‰€æœ‰ä¿¡æ¯æºï¼š")
            markdown_content.append("")
            for i, source in enumerate(research_report.sources, 1):
                markdown_content.append(f"{i}. {source}")
            markdown_content.append("")

        # ç ”ç©¶æ–¹æ³•è¯´æ˜Ž
        markdown_content.append("## ðŸ”¬ ç ”ç©¶æ–¹æ³•è¯´æ˜Ž")
        markdown_content.append("")
        markdown_content.append("æœ¬ç ”ç©¶é‡‡ç”¨DEEPç ”ç©¶æ–¹æ³•è®ºï¼š")
        markdown_content.append("")
        markdown_content.append("- **D (Define)**: å®šä¹‰ç ”ç©¶ç›®æ ‡å’ŒèŒƒå›´")
        markdown_content.append("- **E (Explore)**: æŽ¢ç´¢å¤šä¸ªä¿¡æ¯ç»´åº¦å’Œè§†è§’")
        markdown_content.append("- **E (Evaluate)**: è¯„ä¼°ä¿¡æ¯æºçš„æƒå¨æ€§å’Œå¯é æ€§")
        markdown_content.append("- **P (Present)**: å‘ˆçŽ°ç»“æž„åŒ–çš„ç ”ç©¶å‘çŽ°")
        markdown_content.append("")
        markdown_content.append(f"é€šè¿‡ {len(research_report.steps)} ä¸ªç ”ç©¶æ­¥éª¤ï¼Œä»Ž {len(research_report.sources)} ä¸ªæƒå¨ä¿¡æ¯æºä¸­")
        markdown_content.append(f"æ”¶é›†å’Œåˆ†æžäº†ç›¸å…³ä¿¡æ¯ï¼Œè€—æ—¶ {research_report.total_duration:.2f} ç§’å®Œæˆäº†è¿™ä»½ç»¼åˆæ€§ç ”ç©¶æŠ¥å‘Šã€‚")
        markdown_content.append("")

        # ç»“å°¾
        markdown_content.append("---")
        markdown_content.append("")
        markdown_content.append("*æœ¬æŠ¥å‘Šç”± LandPPT DEEP Research ç³»ç»Ÿè‡ªåŠ¨ç”Ÿæˆï¼ŒåŸºäºŽå¤šä¸ªæƒå¨ä¿¡æ¯æºçš„æ·±åº¦åˆ†æžã€‚*")
        markdown_content.append("")
        markdown_content.append(f"*ç”Ÿæˆæ—¶é—´: {research_report.created_at.strftime('%Y-%m-%d %H:%M:%S')}*")

        return "\n".join(markdown_content)


    def _create_outline_prompt(self, request: PPTGenerationRequest, research_context: str = "", page_count_settings: Dict[str, Any] = None) -> str:
        """Create prompt for AI outline generation - Enhanced with professional templates"""
        scenario_descriptions = {
            "general": "é€šç”¨æ¼”ç¤º",
            "tourism": "æ—…æ¸¸è§‚å…‰ä»‹ç»",
            "education": "å„¿ç«¥ç§‘æ™®æ•™è‚²",
            "analysis": "æ·±å…¥æ•°æ®åˆ†æž",
            "history": "åŽ†å²æ–‡åŒ–ä¸»é¢˜",
            "technology": "ç§‘æŠ€æŠ€æœ¯å±•ç¤º",
            "business": "æ–¹æ¡ˆæ±‡æŠ¥"
        }

        scenario_desc = scenario_descriptions.get(request.scenario, "é€šç”¨æ¼”ç¤º")

        # Handle page count requirements
        page_count_instruction = ""
        expected_page_count = 10  # Default page count

        if page_count_settings:
            page_count_mode = page_count_settings.get('mode', 'ai_decide')

            if page_count_mode == 'custom_range':
                min_pages = page_count_settings.get('min_pages', 8)
                max_pages = page_count_settings.get('max_pages', 15)
                page_count_instruction = f"- é¡µæ•°è¦æ±‚ï¼šå¿…é¡»ä¸¥æ ¼ç”Ÿæˆ{min_pages}-{max_pages}é¡µçš„PPTï¼Œç¡®ä¿é¡µæ•°åœ¨æ­¤èŒƒå›´å†…"
                expected_page_count = max_pages  # Use max for template
            elif page_count_mode == 'fixed':
                fixed_pages = page_count_settings.get('fixed_pages', 10)
                page_count_instruction = f"- é¡µæ•°è¦æ±‚ï¼šå¿…é¡»ç”Ÿæˆæ°å¥½{fixed_pages}é¡µçš„PPT"
                expected_page_count = fixed_pages
            else:
                page_count_instruction = "- é¡µæ•°è¦æ±‚ï¼šæ ¹æ®å†…å®¹å¤æ‚åº¦è‡ªä¸»å†³å®šåˆé€‚çš„é¡µæ•°"
                expected_page_count = 12  # Default for AI decide
        else:
            page_count_instruction = "- é¡µæ•°è¦æ±‚ï¼šæ ¹æ®å†…å®¹å¤æ‚åº¦è‡ªä¸»å†³å®šåˆé€‚çš„é¡µæ•°"
            expected_page_count = 12
        logger.debug(f"Page count instruction: {page_count_instruction}")

        # Add research context if available
        research_section = ""
        if research_context:
            research_section = f"""

åŸºäºŽæ·±åº¦ç ”ç©¶çš„èƒŒæ™¯ä¿¡æ¯ï¼š
{research_context}

è¯·å……åˆ†åˆ©ç”¨ä»¥ä¸Šç ”ç©¶ä¿¡æ¯æ¥ä¸°å¯ŒPPTå†…å®¹ï¼Œç¡®ä¿ä¿¡æ¯å‡†ç¡®ã€æƒå¨ã€å…·æœ‰æ·±åº¦ã€‚"""

        # Get target audience and style information
        target_audience = getattr(request, 'target_audience', None) or 'æ™®é€šå¤§ä¼—'
        ppt_style = getattr(request, 'ppt_style', None) or 'general'
        custom_style_prompt = getattr(request, 'custom_style_prompt', None)
        description = getattr(request, 'description', None)
        language = getattr(request, 'language', None)

        # Create style description
        style_descriptions = {
            "general": "é€šç”¨é£Žæ ¼ï¼Œè¯¦ç»†ä¸“ä¸š",
            "conference": "å­¦æœ¯ä¼šè®®é£Žæ ¼ï¼Œä¸¥è°¨æ­£å¼",
            "custom": custom_style_prompt or "è‡ªå®šä¹‰é£Žæ ¼"
        }
        style_desc = style_descriptions.get(ppt_style, "é€šç”¨é£Žæ ¼")

        # Add custom style prompt if provided (regardless of ppt_style)
        if custom_style_prompt and ppt_style != "custom":
            style_desc += f"ï¼Œ{custom_style_prompt}"

        # Use the new prompts module
        if request.language == "zh":
            return prompts_manager.get_outline_prompt_zh(
                topic=request.topic,
                scenario_desc=scenario_desc,
                target_audience=target_audience,
                style_desc=style_desc,
                requirements=request.requirements or '',
                description=description or '',
                research_section=research_section,
                page_count_instruction=page_count_instruction,
                expected_page_count=expected_page_count,
                language=language or 'zh'
            )
        else:
            return prompts_manager.get_outline_prompt_en(
                topic=request.topic,
                scenario_desc=scenario_desc,
                target_audience=target_audience,
                style_desc=style_desc,
                requirements=request.requirements or '',
                description=description or '',
                research_section=research_section,
                page_count_instruction=page_count_instruction,
                expected_page_count=expected_page_count,
                language=language or 'en'
            )
    
    def _create_slide_content_prompt(self, slide_title: str, scenario: str, topic: str, language: str) -> str:
        """Create prompt for slide content generation"""
        if language == "zh":
            return prompts_manager.get_slide_content_prompt_zh(slide_title, scenario, topic)
        else:
            return prompts_manager.get_slide_content_prompt_en(slide_title, scenario, topic)
    
    def _create_enhancement_prompt(self, content: str, scenario: str, language: str) -> str:
        """Create prompt for content enhancement"""
        if language == "zh":
            return prompts_manager.get_enhancement_prompt_zh(content, scenario)
        else:
            return prompts_manager.get_enhancement_prompt_en(content, scenario)
    
    def _parse_ai_outline(self, ai_response: str, request: PPTGenerationRequest) -> PPTOutline:
        """Parse AI response to create structured outline"""
        try:
            import json
            import re

            # é¦–å…ˆå°è¯•è§£æžJSONæ ¼å¼çš„å“åº”
            json_str = None

            # æ–¹æ³•1: å°è¯•æå–```json```ä»£ç å—ä¸­çš„å†…å®¹
            json_block_match = re.search(r'```json\s*(\{.*?\})\s*```', ai_response, re.DOTALL)
            if json_block_match:
                json_str = json_block_match.group(1)
                logger.info("ä»Ž```json```ä»£ç å—ä¸­æå–å¤§çº²JSON")
            else:
                # æ–¹æ³•2: å°è¯•æå–```ä»£ç å—ä¸­çš„å†…å®¹ï¼ˆä¸å¸¦jsonæ ‡è¯†ï¼‰
                code_block_match = re.search(r'```\s*(\{.*?\})\s*```', ai_response, re.DOTALL)
                if code_block_match:
                    json_str = code_block_match.group(1)
                    logger.info("ä»Ž```ä»£ç å—ä¸­æå–å¤§çº²JSON")
                else:
                    # æ–¹æ³•3: å°è¯•æå–å®Œæ•´çš„JSONå¯¹è±¡
                    json_match = re.search(r'\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\}', ai_response, re.DOTALL)
                    if json_match:
                        json_str = json_match.group()
                        logger.info("ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–å¤§çº²JSON")

            if json_str:
                try:
                    # æ¸…ç†JSONå­—ç¬¦ä¸²
                    json_str = json_str.strip()
                    json_str = re.sub(r',\s*}', '}', json_str)  # ç§»é™¤}å‰çš„å¤šä½™é€—å·
                    json_str = re.sub(r',\s*]', ']', json_str)  # ç§»é™¤]å‰çš„å¤šä½™é€—å·

                    json_data = json.loads(json_str)
                    if 'slides' in json_data:
                        logger.info(f"Successfully parsed JSON outline with {len(json_data['slides'])} slides")

                        # æ ‡å‡†åŒ–slidesæ ¼å¼ä»¥ç¡®ä¿å…¼å®¹æ€§
                        standardized_data = self._standardize_outline_format(json_data)

                        # ç¡®ä¿metadataåŒ…å«å¿…è¦å­—æ®µ
                        metadata = standardized_data.get("metadata", {})
                        metadata.update({
                            "scenario": request.scenario,
                            "language": request.language,
                            "total_slides": len(standardized_data.get("slides", [])),
                            "generated_with_ai": True,
                            "ai_provider": self.provider_name
                        })

                        return PPTOutline(
                            title=standardized_data.get("title", request.topic),
                            slides=standardized_data.get("slides", []),
                            metadata=metadata
                        )
                except json.JSONDecodeError as e:
                    logger.warning(f"Failed to parse extracted JSON: {e}")
                    pass

            # Fallback: è§£æžæ–‡æœ¬æ ¼å¼çš„å¤§çº²
            logger.info("JSONè§£æžå¤±è´¥ï¼Œä½¿ç”¨æ–‡æœ¬è§£æžæ–¹å¼")
            lines = ai_response.strip().split('\n')
            title = request.topic
            slides = []

            # Extract title if present
            for line in lines:
                if line.startswith('æ ‡é¢˜ï¼š') or line.startswith('Title:'):
                    title = line.split('ï¼š', 1)[-1].split(':', 1)[-1].strip()
                    break

            # Parse slide structure
            page_number = 1

            for line in lines:
                line = line.strip()
                if not line:
                    continue

                # Look for numbered items (slide structure)
                if re.match(r'^\d+\.', line):
                    # Extract slide title and description
                    parts = line.split(' - ', 1)
                    if len(parts) == 2:
                        slide_title = parts[0].split('.', 1)[1].strip()
                        slide_desc = parts[1].strip()
                    else:
                        slide_title = line.split('.', 1)[1].strip()
                        slide_desc = ""

                    # Determine slide type
                    slide_type = "content"
                    if "å°é¢" in slide_title or "title" in slide_title.lower():
                        slide_type = "title"
                    elif "ç›®å½•" in slide_title or "agenda" in slide_title.lower():
                        slide_type = "agenda"
                    elif "è°¢è°¢" in slide_title or "thank" in slide_title.lower():
                        slide_type = "thankyou"

                    # ä½¿ç”¨ä¸Žæ–‡ä»¶ç”Ÿæˆä¸€è‡´çš„æ ¼å¼
                    slides.append({
                        "page_number": page_number,
                        "title": slide_title,
                        "content_points": [slide_desc] if slide_desc else ["å†…å®¹è¦ç‚¹"],
                        "slide_type": slide_type,
                        "type": slide_type,  # æ·»åŠ typeå­—æ®µä»¥å…¼å®¹ä¸åŒçš„è®¿é—®æ–¹å¼
                        "description": slide_desc
                    })

                    page_number += 1

            # If no slides were parsed, create default structure
            if not slides:
                slides = self._create_default_slides_compatible(title, request)

            return PPTOutline(
                title=title,
                slides=slides,
                metadata={
                    "scenario": request.scenario,
                    "language": request.language,
                    "total_slides": len(slides),
                    "generated_with_ai": True,
                    "ai_provider": self.provider_name
                }
            )

        except Exception as e:
            logger.error(f"Error parsing AI outline: {str(e)}")
            # Fallback to default structure
            return self._create_default_outline(request)
    
    def _create_default_slides(self, title: str, request: PPTGenerationRequest) -> List[Dict[str, Any]]:
        """Create default slide structure when AI parsing fails (legacy format)"""
        return [
            {
                "id": 1,
                "type": "title",
                "title": title,
                "subtitle": "ä¸“ä¸šæ¼”ç¤º" if request.language == "zh" else "Professional Presentation",
                "content": ""
            },
            {
                "id": 2,
                "type": "agenda",
                "title": "ç›®å½•" if request.language == "zh" else "Agenda",
                "subtitle": "",
                "content": "â€¢ ä¸»è¦å†…å®¹æ¦‚è§ˆ\nâ€¢ æ ¸å¿ƒè¦ç‚¹åˆ†æž\nâ€¢ æ€»ç»“ä¸Žå±•æœ›"
            },
            {
                "id": 3,
                "type": "content",
                "title": "ä¸»è¦å†…å®¹" if request.language == "zh" else "Main Content",
                "subtitle": "",
                "content": f"â€¢ å…³äºŽ{title}çš„æ ¸å¿ƒè¦ç‚¹\nâ€¢ è¯¦ç»†åˆ†æžå’Œè¯´æ˜Ž\nâ€¢ å®žé™…åº”ç”¨æ¡ˆä¾‹"
            },
            {
                "id": 4,
                "type": "thankyou",
                "title": "è°¢è°¢" if request.language == "zh" else "Thank You",
                "subtitle": "æ„Ÿè°¢è†å¬" if request.language == "zh" else "Thank you for your attention",
                "content": ""
            }
        ]

    def _create_default_slides_compatible(self, title: str, request: PPTGenerationRequest) -> List[Dict[str, Any]]:
        """Create default slide structure compatible with file generation format"""
        return [
            {
                "page_number": 1,
                "title": title,
                "content_points": ["ä¸“ä¸šæ¼”ç¤º" if request.language == "zh" else "Professional Presentation"],
                "slide_type": "title",
                "type": "title",
                "description": "PPTæ ‡é¢˜é¡µ"
            },
            {
                "page_number": 2,
                "title": "ç›®å½•" if request.language == "zh" else "Agenda",
                "content_points": ["ä¸»è¦å†…å®¹æ¦‚è§ˆ", "æ ¸å¿ƒè¦ç‚¹åˆ†æž", "æ€»ç»“ä¸Žå±•æœ›"],
                "slide_type": "agenda",
                "type": "agenda",
                "description": "PPTç›®å½•é¡µ"
            },
            {
                "page_number": 3,
                "title": "ä¸»è¦å†…å®¹" if request.language == "zh" else "Main Content",
                "content_points": [f"å…³äºŽ{title}çš„æ ¸å¿ƒè¦ç‚¹", "è¯¦ç»†åˆ†æžå’Œè¯´æ˜Ž", "å®žé™…åº”ç”¨æ¡ˆä¾‹"],
                "slide_type": "content",
                "type": "content",
                "description": "ä¸»è¦å†…å®¹é¡µ"
            },
            {
                "page_number": 4,
                "title": "è°¢è°¢" if request.language == "zh" else "Thank You",
                "content_points": ["æ„Ÿè°¢è†å¬" if request.language == "zh" else "Thank you for your attention"],
                "slide_type": "thankyou",
                "type": "thankyou",
                "description": "PPTç»“æŸé¡µ"
            }
        ]
    
    def _create_default_outline(self, request: PPTGenerationRequest) -> PPTOutline:
        """Create default outline when AI generation fails"""
        slides = self._create_default_slides(request.topic, request)
        
        return PPTOutline(
            title=request.topic,
            slides=slides,
            metadata={
                "scenario": request.scenario,
                "language": request.language,
                "total_slides": len(slides),
                "generated_with_ai": False,
                "fallback_used": True
            }
        )

    # New project-based methods
    async def create_project_with_workflow(self, request: PPTGenerationRequest) -> PPTProject:
        """Create a new project with complete TODO workflow"""
        try:
            # Create project with TODO board
            project = await self.project_manager.create_project(request)

            # Start the workflow
            await self._execute_project_workflow(project.project_id, request)

            return project

        except Exception as e:
            logger.error(f"Error creating project with workflow: {str(e)}")
            raise

    async def _execute_project_workflow(self, project_id: str, request: PPTGenerationRequest):
        """Execute the complete project workflow with sequential subtask processing"""
        try:
            # Get project to check if requirements are confirmed
            project = await self.project_manager.get_project(project_id)
            if not project:
                raise ValueError("Project not found")

            # Only execute if requirements are confirmed
            if not project.confirmed_requirements:
                logger.info(f"Project {project_id} workflow waiting for requirements confirmation")
                return

            # Get TODO board to access stages and subtasks
            todo_board = await self.project_manager.get_todo_board(project_id)
            if not todo_board:
                raise ValueError("TODO board not found for project")

            # Process each stage sequentially (skip requirements confirmation stage)
            for stage_index, stage in enumerate(todo_board.stages):
                # Skip requirements confirmation stage as it's already done
                if stage.id == "requirements_confirmation":
                    continue

                logger.info(f"Starting stage {stage_index + 1}: {stage.name}")

                # Mark stage as running
                await self.project_manager.update_stage_status(
                    project_id, stage.id, "running", 0.0
                )

                # Execute the complete stage as a single task
                try:
                    stage_result = await self._execute_complete_stage(project_id, stage.id, request)
                except Exception as e:
                    logger.error(f"Error executing stage '{stage.name}': {str(e)}")
                    # Mark stage as failed but continue with next stage
                    await self.project_manager.update_stage_status(
                        project_id, stage.id, "failed", 0.0, {"error": str(e)}
                    )
                    continue
                # Wrap string result in dictionary for proper serialization
                result_dict = {"message": stage_result} if isinstance(stage_result, str) else stage_result
                await self.project_manager.update_stage_status(
                    project_id, stage.id, "completed", 100.0, result_dict
                )

                logger.info(f"Completed stage: {stage.name}")

            # Mark project as completed
            await self.project_manager.update_project_status(project_id, "completed")
            logger.info(f"Project workflow completed: {project_id}")

        except Exception as e:
            logger.error(f"Error in project workflow: {str(e)}")
            # Mark current stage as failed
            todo_board = await self.project_manager.get_todo_board(project_id)
            if todo_board and todo_board.current_stage_index < len(todo_board.stages):
                current_stage = todo_board.stages[todo_board.current_stage_index]
                await self.project_manager.update_stage_status(
                    project_id, current_stage.id, "failed", 0.0,
                    {"error": str(e)}
                )

    async def _execute_complete_stage(self, project_id: str, stage_id: str, request: PPTGenerationRequest):
        """Execute a complete stage as a single task"""
        try:
            logger.info(f"Executing complete stage: {stage_id}")

            # Get project and confirmed requirements
            project = await self.project_manager.get_project(project_id)
            if not project or not project.confirmed_requirements:
                raise ValueError("Project or confirmed requirements not found")

            confirmed_requirements = project.confirmed_requirements

            # Execute based on stage type
            if stage_id == "outline_generation":
                return await self._execute_outline_generation(project_id, confirmed_requirements, self._load_prompts_md_system_prompt())
            elif stage_id == "ppt_creation":
                return await self._execute_ppt_creation(project_id, confirmed_requirements, self._load_prompts_md_system_prompt())
            else:
                # Fallback for other stages
                return await self._execute_general_stage(project_id, stage_id, confirmed_requirements)

        except Exception as e:
            logger.error(f"Error executing complete stage '{stage_id}': {str(e)}")
            raise

    async def _execute_general_stage(self, project_id: str, stage_id: str, confirmed_requirements: Dict[str, Any]):
        """Execute a general stage task"""
        try:
            system_prompt = self._load_prompts_md_system_prompt()

            context = f"""
é¡¹ç›®ä¿¡æ¯ï¼š
- ä¸»é¢˜ï¼š{confirmed_requirements['topic']}
- ç±»åž‹ï¼š{confirmed_requirements['type']}
- å…¶ä»–è¯´æ˜Žï¼š{confirmed_requirements.get('description', 'æ— ')}

å½“å‰é˜¶æ®µï¼š{stage_id}

è¯·æ ¹æ®ä»¥ä¸Šä¿¡æ¯å®Œæˆå½“å‰é˜¶æ®µçš„ä»»åŠ¡ã€‚
"""

            response = await self.ai_provider.text_completion(
                prompt=context,
                system_prompt=system_prompt,
                max_tokens=ai_config.max_tokens,
                temperature=ai_config.temperature
            )

            return {"message": response.content}

        except Exception as e:
            logger.error(f"Error executing general stage '{stage_id}': {str(e)}")
            raise

    async def _complete_stage(self, project_id: str, stage_id: str,
                            request: PPTGenerationRequest) -> Dict[str, Any]:
        """Complete a stage and return its result"""
        try:
            if stage_id == "outline_generation":
                outline = await self.generate_outline(request)
                return {"outline": outline.dict()}

            elif stage_id == "theme_design":
                theme_config = await self._design_theme(request.scenario, request.language)
                return {"theme_config": theme_config}

            elif stage_id == "content_generation":
                # Get outline from previous stage
                project = await self.project_manager.get_project(project_id)
                if project and project.outline:
                    enhanced_slides = await self._generate_enhanced_content(project.outline, request)
                    return {"enhanced_slides": [slide.dict() for slide in enhanced_slides]}
                else:
                    # Fallback: generate basic outline first
                    outline = await self.generate_outline(request)
                    enhanced_slides = await self._generate_enhanced_content(outline, request)
                    return {"enhanced_slides": [slide.dict() for slide in enhanced_slides]}

            elif stage_id == "layout_verification":
                # Get slides from previous stage
                todo_board = await self.project_manager.get_todo_board(project_id)
                if todo_board:
                    for stage in todo_board.stages:
                        if stage.id == "content_generation" and stage.result:
                            slides_data = stage.result.get("enhanced_slides", [])
                            slides = [SlideContent(**slide_data) for slide_data in slides_data]
                            theme_config = {}
                            for s in todo_board.stages:
                                if s.id == "theme_design" and s.result:
                                    theme_config = s.result.get("theme_config", {})
                                    break
                            verified_slides = await self._verify_layout(slides, theme_config)
                            return {"verified_slides": [slide.dict() for slide in verified_slides]}
                return {"verified_slides": []}

            elif stage_id == "export_output":
                # Get verified slides and generate HTML
                todo_board = await self.project_manager.get_todo_board(project_id)
                if todo_board:
                    slides_data = []
                    theme_config = {}

                    for stage in todo_board.stages:
                        if stage.id == "layout_verification" and stage.result:
                            slides_data = stage.result.get("verified_slides", [])
                        elif stage.id == "theme_design" and stage.result:
                            theme_config = stage.result.get("theme_config", {})

                    if slides_data:
                        slides = [SlideContent(**slide_data) for slide_data in slides_data]
                        html_content = await self._generate_html_output(slides, theme_config)

                        # Update project with final results
                        project = await self.project_manager.get_project(project_id)
                        if project:
                            project.slides_html = html_content

                            # Save version
                            await self.project_manager.save_project_version(
                                project_id,
                                {
                                    "slides_html": html_content,
                                    "theme_config": theme_config
                                }
                            )

                        return {"html_content": html_content}

                return {"html_content": ""}

            else:
                return {"message": f"Stage {stage_id} completed"}

        except Exception as e:
            logger.error(f"Error completing stage '{stage_id}': {str(e)}")
            return {"error": str(e)}

    async def generate_outline_streaming(self, project_id: str):
        """Generate outline with streaming output"""
        try:
            project = await self.project_manager.get_project(project_id)
            if not project:
                raise ValueError("Project not found")

            # æ£€æŸ¥æ˜¯å¦å·²ç»æœ‰ä»Žæ–‡ä»¶ç”Ÿæˆçš„å¤§çº²
            file_generated_outline = None
            if project.confirmed_requirements and project.confirmed_requirements.get('file_generated_outline'):
                file_generated_outline = project.confirmed_requirements['file_generated_outline']
                logger.info(f"Project {project_id} has file-generated outline, using it")
            elif project.outline and project.outline.get('slides') and project.outline.get('metadata', {}).get('generated_with_summeryfile'):
                file_generated_outline = project.outline
                logger.info(f"Project {project_id} already has outline generated from file, using existing outline")

            if file_generated_outline:
                # ç›´æŽ¥æµå¼è¾“å‡ºå·²æœ‰çš„å¤§çº²
                import json
                existing_outline = {
                    "title": file_generated_outline.get('title', project.topic),
                    "slides": file_generated_outline.get('slides', []),
                    "metadata": file_generated_outline.get('metadata', {})
                }

                # ç¡®ä¿å…ƒæ•°æ®åŒ…å«æ­£ç¡®çš„æ ‡è¯†
                if 'metadata' not in existing_outline:
                    existing_outline['metadata'] = {}
                existing_outline['metadata']['generated_with_summeryfile'] = True
                existing_outline['metadata']['generated_at'] = time.time()

                formatted_json = json.dumps(existing_outline, ensure_ascii=False, indent=2)

                # Stream the existing outline
                for i, char in enumerate(formatted_json):
                    yield f"data: {json.dumps({'content': char})}\n\n"
                    if i % 10 == 0:
                        await asyncio.sleep(0.02)  # Faster streaming for existing content

                # ä¿å­˜å¤§çº²åˆ°é¡¹ç›®ä¸­ - ç›´æŽ¥ä¿å­˜ç»“æž„åŒ–æ•°æ®
                project.outline = existing_outline  # ç›´æŽ¥ä¿å­˜ç»“æž„åŒ–æ•°æ®ï¼Œè€Œä¸æ˜¯åŒ…è£…æ ¼å¼
                project.updated_at = time.time()

                # ç«‹å³ä¿å­˜åˆ°æ•°æ®åº“
                try:
                    from .db_project_manager import DatabaseProjectManager
                    db_manager = DatabaseProjectManager()
                    save_success = await db_manager.save_project_outline(project_id, project.outline)

                    if save_success:
                        logger.info(f"âœ… Successfully saved file-generated outline to database for project {project_id}")
                        # åŒæ—¶æ›´æ–°å†…å­˜ä¸­çš„é¡¹ç›®ç®¡ç†å™¨
                        self.project_manager.projects[project_id] = project
                    else:
                        logger.error(f"âŒ Failed to save file-generated outline to database for project {project_id}")

                except Exception as save_error:
                    logger.error(f"âŒ Exception while saving file-generated outline: {str(save_error)}")
                    import traceback
                    traceback.print_exc()

                # Update stage status
                await self._update_outline_generation_stage(project_id, existing_outline)
              # Send completion signal
                yield f"data: {json.dumps({'done': True})}\n\n"
                return

            # Update project status to in_progress
            await self.project_manager.update_project_status(project_id, "in_progress")

            # Update TODO board stage status
            if project.todo_board:
                for stage in project.todo_board.stages:
                    if stage.id == "outline_generation":
                        stage.status = "running"
                        break

            import json
            # time æ¨¡å—å·²ç»åœ¨æ–‡ä»¶é¡¶éƒ¨å¯¼å…¥ï¼Œä¸éœ€è¦é‡å¤å¯¼å…¥

            # æž„å»ºåŸºäºŽç¡®è®¤éœ€æ±‚çš„æç¤ºè¯
            confirmed_requirements = project.confirmed_requirements or {}

            # æ£€æŸ¥æ˜¯å¦å¯ç”¨äº†è”ç½‘æ¨¡å¼å¹¶è¿›è¡ŒDEEP research
            research_context = ""
            network_mode = False
            if project.project_metadata and isinstance(project.project_metadata, dict):
                network_mode = project.project_metadata.get("network_mode", False)

            if network_mode and self.research_service and self.research_service.is_available():
                logger.info(f"ðŸ” Project {project_id} has network mode enabled, starting DEEP research for topic: {project.topic}")
                try:
                    # Conduct DEEP research
                    research_report = await self.research_service.conduct_deep_research(
                        topic=project.topic,
                        language="zh"  # Default to Chinese for now
                    )

                    # Generate structured Markdown research context
                    research_context = self._create_research_context(research_report)
                    logger.info(f"âœ… DEEP research completed successfully for project {project_id}")

                    # Save research report if generator is available
                    if self.report_generator:
                        try:
                            report_path = self.report_generator.save_report_to_file(research_report)
                            logger.info(f"ðŸ“„ Research report saved to: {report_path}")
                        except Exception as save_error:
                            logger.warning(f"Failed to save research report: {save_error}")

                    # å¦‚æžœæœ‰ç ”ç©¶å†…å®¹ï¼Œä¿å­˜ä¸ºä¸´æ—¶æ–‡ä»¶å¹¶ä½¿ç”¨çŽ°æœ‰çš„æ–‡ä»¶å¤„ç†æµç¨‹
                    if research_context:
                        logger.info(f"ðŸŽ¯ Using research-based outline generation via file processing for project {project_id}")

                        # åœ¨çº¿ç¨‹æ± ä¸­ä¿å­˜ç ”ç©¶å†…å®¹ä¸ºä¸´æ—¶Markdownæ–‡ä»¶
                        temp_research_file = await run_blocking_io(
                            self._save_research_to_temp_file, research_context
                        )

                        logger.info(f"ðŸ“„ Research content saved to temporary file: {temp_research_file}")
                        logger.info(f"ðŸ“Š Research content stats: {len(research_context)} chars, {len(research_context.split())} words")

                        try:
                            # åˆ›å»ºæ–‡ä»¶å¤§çº²ç”Ÿæˆè¯·æ±‚ï¼Œä½¿ç”¨çŽ°æœ‰çš„generate_outline_from_fileæ–¹æ³•
                            from ..api.models import FileOutlineGenerationRequest

                            file_request = FileOutlineGenerationRequest(
                                file_path=temp_research_file,
                                filename=f"research_{project.topic}.md",
                                topic=confirmed_requirements.get('topic', project.topic),
                                scenario=confirmed_requirements.get('type', project.scenario),
                                requirements=confirmed_requirements.get('requirements', project.requirements),
                                language="zh",
                                page_count_mode=confirmed_requirements.get('page_count_settings', {}).get('mode', 'ai_decide'),
                                min_pages=confirmed_requirements.get('page_count_settings', {}).get('min_pages', 8),
                                max_pages=confirmed_requirements.get('page_count_settings', {}).get('max_pages', 15),
                                fixed_pages=confirmed_requirements.get('page_count_settings', {}).get('fixed_pages', 10),
                                ppt_style=confirmed_requirements.get('ppt_style', 'general'),
                                custom_style_prompt=confirmed_requirements.get('custom_style_prompt'),
                                target_audience=confirmed_requirements.get('target_audience', 'æ™®é€šå¤§ä¼—'),
                                custom_audience=confirmed_requirements.get('custom_audience'),
                                file_processing_mode="markitdown",  # ä½¿ç”¨markitdownå¤„ç†Markdownæ–‡ä»¶
                                content_analysis_depth="fast"  # ä½¿ç”¨å¿«é€Ÿåˆ†æžç­–ç•¥ï¼Œé€‚åˆç ”ç©¶æŠ¥å‘Šå¤„ç†
                            )

                            # ä½¿ç”¨çŽ°æœ‰çš„æ–‡ä»¶å¤„ç†æ–¹æ³•ç”Ÿæˆå¤§çº²ï¼ˆé‡‡ç”¨å¿«é€Ÿåˆ†å—ç­–ç•¥ï¼‰
                            logger.info(f"ðŸš€ Using fast chunking strategy for research-based outline generation")
                            logger.info(f"ðŸ“Š File processing config: mode={file_request.file_processing_mode}, depth={file_request.content_analysis_depth}")

                            outline_response = await self.generate_outline_from_file(file_request)

                            if outline_response.success and outline_response.outline:
                                structured_outline = outline_response.outline

                                # æ·»åŠ ç ”ç©¶å¢žå¼ºæ ‡è¯†
                                if 'metadata' not in structured_outline:
                                    structured_outline['metadata'] = {}
                                structured_outline['metadata']['research_enhanced'] = True
                                structured_outline['metadata']['research_duration'] = research_report.total_duration
                                structured_outline['metadata']['research_sources'] = len(research_report.sources)
                                structured_outline['metadata']['generated_from_research_file'] = True
                                structured_outline['metadata']['generated_at'] = time.time()

                                # æµå¼è¾“å‡ºç ”ç©¶å¢žå¼ºçš„å¤§çº²
                                formatted_json = json.dumps(structured_outline, ensure_ascii=False, indent=2)
                                for i, char in enumerate(formatted_json):
                                    yield f"data: {json.dumps({'content': char})}\n\n"
                                    if i % 10 == 0:
                                        await asyncio.sleep(0.05)

                                # ä¿å­˜å¤§çº²
                                project.outline = structured_outline
                                project.updated_at = time.time()

                                # ä¿å­˜åˆ°æ•°æ®åº“
                                try:
                                    from .db_project_manager import DatabaseProjectManager
                                    db_manager = DatabaseProjectManager()
                                    save_success = await db_manager.save_project_outline(project_id, project.outline)
                                    if save_success:
                                        logger.info(f"âœ… Successfully saved research-enhanced outline to database for project {project_id}")
                                        self.project_manager.projects[project_id] = project
                                    else:
                                        logger.error(f"âŒ Failed to save research-enhanced outline to database for project {project_id}")
                                except Exception as save_error:
                                    logger.error(f"âŒ Exception while saving research-enhanced outline: {str(save_error)}")

                                # æ›´æ–°é˜¶æ®µçŠ¶æ€
                                await self._update_outline_generation_stage(project_id, structured_outline)

                                # å‘é€å®Œæˆä¿¡å·
                                yield f"data: {json.dumps({'done': True})}\n\n"
                                return
                            else:
                                logger.warning(f"Failed to generate outline from research file, falling back to normal generation")

                        finally:
                            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                            try:
                                # åœ¨çº¿ç¨‹æ± ä¸­æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                                await run_blocking_io(self._cleanup_temp_file, temp_research_file)
                                logger.info(f"Cleaned up temporary research file: {temp_research_file}")
                            except Exception as cleanup_error:
                                logger.warning(f"Failed to cleanup temporary research file: {cleanup_error}")

                except Exception as research_error:
                    logger.warning(f"DEEP research failed for project {project_id}, proceeding without research context: {research_error}")
                    research_context = ""
            else:
                if network_mode:
                    logger.warning(f"Project {project_id} has network mode enabled but research service is not available")
                else:
                    logger.info(f"Project {project_id} does not have network mode enabled")

            # å¤„ç†é¡µæ•°è®¾ç½®
            page_count_settings = confirmed_requirements.get('page_count_settings', {})
            page_count_mode = page_count_settings.get('mode', 'ai_decide')

            page_count_instruction = ""
            if page_count_mode == 'custom_range':
                min_pages = page_count_settings.get('min_pages', 8)
                max_pages = page_count_settings.get('max_pages', 15)
                page_count_instruction = f"- é¡µæ•°è¦æ±‚ï¼šå¿…é¡»ä¸¥æ ¼ç”Ÿæˆ{min_pages}-{max_pages}é¡µçš„PPTï¼Œç¡®ä¿é¡µæ•°åœ¨æ­¤èŒƒå›´å†…"
            elif page_count_mode == 'fixed':
                fixed_pages = page_count_settings.get('fixed_pages', 10)
                page_count_instruction = f"- é¡µæ•°è¦æ±‚ï¼šå¿…é¡»ç”Ÿæˆæ°å¥½{fixed_pages}é¡µçš„PPT"
            else:
                page_count_instruction = "- é¡µæ•°è¦æ±‚ï¼šæ ¹æ®å†…å®¹å¤æ‚åº¦è‡ªä¸»å†³å®šåˆé€‚çš„é¡µæ•°ï¼ˆå»ºè®®8-15é¡µï¼‰"

            # Generate outline using AI - ä½¿ç”¨å­—ç¬¦ä¸²æ‹¼æŽ¥é¿å…f-stringä¸­çš„èŠ±æ‹¬å·å†²çª
            topic = confirmed_requirements.get('topic', project.topic)
            target_audience = confirmed_requirements.get('target_audience', 'æ™®é€šå¤§ä¼—')
            ppt_style = confirmed_requirements.get('ppt_style', 'general')

            # Add research context if available
            research_section = ""
            if research_context:
                research_section = """

åŸºäºŽæ·±åº¦ç ”ç©¶çš„èƒŒæ™¯ä¿¡æ¯ï¼š
""" + research_context + """

è¯·å……åˆ†åˆ©ç”¨ä»¥ä¸Šç ”ç©¶ä¿¡æ¯æ¥ä¸°å¯ŒPPTå†…å®¹ï¼Œç¡®ä¿ä¿¡æ¯å‡†ç¡®ã€æƒå¨ã€å…·æœ‰æ·±åº¦ã€‚"""

            # ä½¿ç”¨æ–°çš„æç¤ºè¯æ¨¡å—
            prompt = prompts_manager.get_streaming_outline_prompt(
                topic=topic,
                target_audience=target_audience,
                ppt_style=ppt_style,
                page_count_instruction=page_count_instruction,
                research_section=research_section
            )

            # Generate outline content directly without initial message
            response = await self.ai_provider.text_completion(
                prompt=prompt,
                max_tokens=ai_config.max_tokens,
                temperature=ai_config.temperature
            )

            # Get the AI response content
            content = response.content.strip()

            # Import re for regex operations
            import re

            # åˆå§‹åŒ–structured_outlineå˜é‡
            structured_outline = None

            # Try to parse as JSON first with validation and repair
            try:
                # Extract JSON from response if it contains extra text
                json_match = re.search(r'\{.*\}', content, re.DOTALL)
                if json_match:
                    json_str = json_match.group()
                    structured_outline = json.loads(json_str)
                else:
                    structured_outline = json.loads(content)

                # Validate and repair the JSON structure
                structured_outline = await self._validate_and_repair_outline_json(structured_outline, confirmed_requirements)

                # éªŒè¯é¡µæ•°æ˜¯å¦ç¬¦åˆè¦æ±‚
                actual_page_count = len(structured_outline.get('slides', []))
                if page_count_mode == 'custom_range':
                    min_pages = page_count_settings.get('min_pages', 8)
                    max_pages = page_count_settings.get('max_pages', 15)
                    if actual_page_count < min_pages or actual_page_count > max_pages:
                        logger.warning(f"Generated outline has {actual_page_count} pages, but expected {min_pages}-{max_pages} pages")
                        # å¯ä»¥é€‰æ‹©é‡æ–°ç”Ÿæˆæˆ–è°ƒæ•´ï¼Œè¿™é‡Œå…ˆè®°å½•è­¦å‘Š
                elif page_count_mode == 'fixed':
                    fixed_pages = page_count_settings.get('fixed_pages', 10)
                    if actual_page_count != fixed_pages:
                        logger.warning(f"Generated outline has {actual_page_count} pages, but expected exactly {fixed_pages} pages")

                # æ·»åŠ å…ƒæ•°æ®
                structured_outline['metadata'] = {
                    'generated_with_summeryfile': False,
                    'page_count_settings': page_count_settings,
                    'actual_page_count': actual_page_count,
                    'generated_at': time.time()
                }

                # Format the JSON for display
                formatted_json = json.dumps(structured_outline, ensure_ascii=False, indent=2)

                # Stream the formatted JSON character by character
                for i, char in enumerate(formatted_json):
                    yield f"data: {json.dumps({'content': char})}\n\n"

                    # Add small delay for streaming effect
                    if i % 10 == 0:  # Every 10 characters
                        await asyncio.sleep(0.05)

                # Store the structured data directly
                project.outline = structured_outline  # ç›´æŽ¥ä¿å­˜ç»“æž„åŒ–æ•°æ®
                project.updated_at = time.time()

                # ç«‹å³ä¿å­˜åˆ°æ•°æ®åº“
                try:
                    from .db_project_manager import DatabaseProjectManager
                    db_manager = DatabaseProjectManager()
                    save_success = await db_manager.save_project_outline(project_id, project.outline)

                    if save_success:
                        logger.info(f"âœ… Successfully saved outline to database during streaming for project {project_id}")
                        # åŒæ—¶æ›´æ–°å†…å­˜ä¸­çš„é¡¹ç›®ç®¡ç†å™¨
                        self.project_manager.projects[project_id] = project
                    else:
                        logger.error(f"âŒ Failed to save outline to database during streaming for project {project_id}")

                except Exception as save_error:
                    logger.error(f"âŒ Exception while saving outline during streaming: {str(save_error)}")
                    import traceback
                    traceback.print_exc()

                # å¤§çº²ç”Ÿæˆå®ŒæˆåŽï¼Œç«‹å³ç”Ÿæˆæ¯ç‰ˆæ¨¡æ¿ï¼ˆJSONè§£æžæˆåŠŸçš„æƒ…å†µï¼‰
                await self._update_outline_generation_stage(project_id, structured_outline)

            except Exception as parse_error:
                logger.warning(f"Failed to parse AI response as JSON: {parse_error}")

                # Fallback: parse text-based outline and convert to JSON
                structured_outline = self._parse_outline_content(content, project)

                # éªŒè¯å’Œä¿®å¤fallbackç”Ÿæˆçš„å¤§çº²
                structured_outline = await self._validate_and_repair_outline_json(structured_outline, confirmed_requirements)

                # æ·»åŠ å…ƒæ•°æ®
                structured_outline['metadata'] = {
                    'generated_with_summeryfile': False,
                    'page_count_settings': page_count_settings,
                    'actual_page_count': len(structured_outline.get('slides', [])),
                    'generated_at': time.time()
                }

                formatted_json = json.dumps(structured_outline, ensure_ascii=False, indent=2)

                # Stream the formatted JSON
                for i, char in enumerate(formatted_json):
                    yield f"data: {json.dumps({'content': char})}\n\n"

                    if i % 10 == 0:
                        await asyncio.sleep(0.05)

                # Store the structured data
                project.outline = structured_outline  # ç›´æŽ¥ä¿å­˜ç»“æž„åŒ–æ•°æ®
                project.updated_at = time.time()

                # ç«‹å³ä¿å­˜åˆ°æ•°æ®åº“
                try:
                    from .db_project_manager import DatabaseProjectManager
                    db_manager = DatabaseProjectManager()
                    save_success = await db_manager.save_project_outline(project_id, project.outline)

                    if save_success:
                        logger.info(f"âœ… Successfully saved fallback outline to database during streaming for project {project_id}")
                        # åŒæ—¶æ›´æ–°å†…å­˜ä¸­çš„é¡¹ç›®ç®¡ç†å™¨
                        self.project_manager.projects[project_id] = project
                    else:
                        logger.error(f"âŒ Failed to save fallback outline to database during streaming for project {project_id}")

                except Exception as save_error:
                    logger.error(f"âŒ Exception while saving fallback outline during streaming: {str(save_error)}")
                    import traceback
                    traceback.print_exc()

                # Update stage status - ç¡®ä¿structured_outlineå·²å®šä¹‰
                if structured_outline is not None:
                    await self._update_outline_generation_stage(project_id, structured_outline)

                    # æ£€æŸ¥æ˜¯å¦å·²é€‰æ‹©å…¨å±€æ¯ç‰ˆï¼Œå¦‚æžœæ²¡æœ‰åˆ™ä½¿ç”¨é»˜è®¤æ¯ç‰ˆ
                    logger.info(f"ðŸŽ¨ æ£€æŸ¥é¡¹ç›® {project_id} çš„å…¨å±€æ¯ç‰ˆé€‰æ‹©")
                    selected_template = await self._ensure_global_master_template_selected(project_id)

                    if selected_template:
                        logger.info(f"âœ… é¡¹ç›® {project_id} å·²é€‰æ‹©å…¨å±€æ¯ç‰ˆ: {selected_template['template_name']}")
                    else:
                        logger.warning(f"âš ï¸ é¡¹ç›® {project_id} æœªæ‰¾åˆ°å¯ç”¨çš„å…¨å±€æ¯ç‰ˆï¼Œå°†ä½¿ç”¨å¤‡ç”¨æ¨¡æ¿")
                    
                else:
                    # å¦‚æžœstructured_outlineæœªå®šä¹‰ï¼Œä½¿ç”¨é¡¹ç›®å¤§çº²æ•°æ®
                    if project.outline and project.outline.get('slides'):
                        outline_data = {
                            "title": project.outline.get("title", project.topic),
                            "slides": project.outline.get("slides", [])
                        }
                        await self._update_outline_generation_stage(project_id, outline_data)

                    else:
                        # åˆ›å»ºé»˜è®¤çš„å¤§çº²æ•°æ®
                        default_outline = {
                            "title": project.topic,
                            "slides": [
                                {
                                    "page_number": 1,
                                    "title": project.topic,
                                    "content_points": ["é¡¹ç›®ä»‹ç»"],
                                    "slide_type": "title"
                                }
                            ]
                        }
                        await self._update_outline_generation_stage(project_id, default_outline)
                # Send completion signal without message
                yield f"data: {json.dumps({'done': True})}\n\n"

        except Exception as e:
            logger.error(f"Error in outline streaming generation: {str(e)}")
            error_message = f'ç”Ÿæˆå¤§çº²æ—¶å‡ºçŽ°é”™è¯¯ï¼š{str(e)}'
            yield f"data: {json.dumps({'error': error_message})}\n\n"

    async def _validate_and_repair_outline_json(self, outline_data: Dict[str, Any], confirmed_requirements: Dict[str, Any]) -> Dict[str, Any]:
        """éªŒè¯å¤§çº²JSONæ•°æ®çš„æ­£ç¡®æ€§ï¼Œå¦‚æžœæœ‰é”™è¯¯åˆ™è°ƒç”¨AIä¿®å¤ï¼Œæœ€å¤šä¿®å¤10æ¬¡"""
        try:
            # ç¬¬ä¸€æ­¥ï¼šåŸºæœ¬ç»“æž„éªŒè¯
            logger.info(f"outline_data: {outline_data}")
            validation_errors = self._validate_outline_structure(outline_data, confirmed_requirements)

            if not validation_errors:
                logger.info("å¤§çº²JSONéªŒè¯é€šè¿‡ï¼Œæ— éœ€ä¿®å¤")
                return outline_data

            logger.warning(f"å¤§çº²JSONéªŒè¯å‘çŽ° {len(validation_errors)} ä¸ªé”™è¯¯ï¼Œå¼€å§‹AIä¿®å¤")

            # ç¬¬äºŒæ­¥ï¼šè°ƒç”¨AIä¿®å¤ï¼Œæœ€å¤šä¿®å¤10æ¬¡
            max_repair_attempts = 10
            current_attempt = 1

            while current_attempt <= max_repair_attempts:
                logger.info(f"ç¬¬ {current_attempt} æ¬¡AIä¿®å¤å°è¯•")

                try:
                    repaired_outline = await self._repair_outline_with_ai(outline_data, validation_errors, confirmed_requirements)

                    # éªŒè¯ä¿®å¤åŽçš„ç»“æžœ
                    repair_validation_errors = self._validate_outline_structure(repaired_outline, confirmed_requirements)

                    if not repair_validation_errors:
                        logger.info(f"AIä¿®å¤æˆåŠŸï¼Œç¬¬ {current_attempt} æ¬¡å°è¯•é€šè¿‡éªŒè¯")
                        return repaired_outline
                    else:
                        logger.warning(f"ç¬¬ {current_attempt} æ¬¡AIä¿®å¤åŽä»æœ‰ {len(repair_validation_errors)} ä¸ªé”™è¯¯")
                        validation_errors = repair_validation_errors
                        outline_data = repaired_outline

                except Exception as repair_error:
                    logger.error(f"ç¬¬ {current_attempt} æ¬¡AIä¿®å¤å¤±è´¥: {str(repair_error)}")

                current_attempt += 1

            # å¦‚æžœ10æ¬¡ä¿®å¤éƒ½å¤±è´¥ï¼Œç›´æŽ¥è¾“å‡ºJSON
            logger.warning("AIä¿®å¤è¾¾åˆ°æœ€å¤§å°è¯•æ¬¡æ•°(10æ¬¡)ï¼Œç›´æŽ¥è¾“å‡ºå½“å‰JSON")
            return outline_data

        except Exception as e:
            logger.error(f"éªŒè¯å’Œä¿®å¤è¿‡ç¨‹å‡ºé”™: {str(e)}")
            # å¦‚æžœéªŒè¯ä¿®å¤è¿‡ç¨‹å‡ºé”™ï¼Œç›´æŽ¥è¾“å‡ºåŽŸå§‹JSON
            return outline_data

    def _validate_outline_structure(self, outline_data: Dict[str, Any], confirmed_requirements: Dict[str, Any]) -> List[str]:
        """éªŒè¯å¤§çº²ç»“æž„ï¼Œè¿”å›žé”™è¯¯åˆ—è¡¨"""
        errors = []

        try:
            # 1. æ£€æŸ¥å¿…éœ€å­—æ®µ
            if not isinstance(outline_data, dict):
                errors.append("å¤§çº²æ•°æ®å¿…é¡»æ˜¯å­—å…¸æ ¼å¼")
                return errors

            if 'slides' not in outline_data:
                errors.append("ç¼ºå°‘å¿…éœ€å­—æ®µ: slides")
                return errors

            if 'title' not in outline_data:
                errors.append("ç¼ºå°‘å¿…éœ€å­—æ®µ: title")

            # 2. æ£€æŸ¥slideså­—æ®µ
            slides = outline_data.get('slides', [])
            if not isinstance(slides, list):
                errors.append("slideså­—æ®µå¿…é¡»æ˜¯åˆ—è¡¨æ ¼å¼")
                return errors

            if len(slides) == 0:
                errors.append("slidesåˆ—è¡¨ä¸èƒ½ä¸ºç©º")
                return errors

            # 3. æ£€æŸ¥é¡µæ•°è¦æ±‚
            page_count_settings = confirmed_requirements.get('page_count_settings', {})
            page_count_mode = page_count_settings.get('mode', 'ai_decide')
            actual_page_count = len(slides)

            if page_count_mode == 'custom_range':
                min_pages = page_count_settings.get('min_pages', 8)
                max_pages = page_count_settings.get('max_pages', 15)
                if actual_page_count < min_pages:
                    errors.append(f"é¡µæ•°ä¸è¶³ï¼šå½“å‰{actual_page_count}é¡µï¼Œè¦æ±‚è‡³å°‘{min_pages}é¡µ")
                elif actual_page_count > max_pages:
                    errors.append(f"é¡µæ•°è¿‡å¤šï¼šå½“å‰{actual_page_count}é¡µï¼Œè¦æ±‚æœ€å¤š{max_pages}é¡µ")
            elif page_count_mode == 'fixed':
                fixed_pages = page_count_settings.get('fixed_pages', 10)
                if actual_page_count != fixed_pages:
                    errors.append(f"é¡µæ•°ä¸åŒ¹é…ï¼šå½“å‰{actual_page_count}é¡µï¼Œè¦æ±‚æ°å¥½{fixed_pages}é¡µ")

            # 4. æ£€æŸ¥æ¯ä¸ªslideçš„ç»“æž„
            for i, slide in enumerate(slides):
                slide_errors = self._validate_slide_structure(slide, i + 1)
                errors.extend(slide_errors)

            # 5. æ£€æŸ¥é¡µç è¿žç»­æ€§
            page_numbers = [slide.get('page_number', 0) for slide in slides]
            expected_numbers = list(range(1, len(slides) + 1))
            if page_numbers != expected_numbers:
                expected_str = ', '.join(map(str, expected_numbers))
                actual_str = ', '.join(map(str, page_numbers))
                errors.append(f"é¡µç ä¸è¿žç»­ï¼šæœŸæœ›[{expected_str}]ï¼Œå®žé™…[{actual_str}]")

            return errors

        except Exception as e:
            errors.append(f"éªŒè¯è¿‡ç¨‹å‡ºé”™: {str(e)}")
            return errors

    def _validate_slide_structure(self, slide: Dict[str, Any], slide_index: int) -> List[str]:
        """éªŒè¯å•ä¸ªslideçš„ç»“æž„"""
        errors = []

        try:
            if not isinstance(slide, dict):
                errors.append(f"ç¬¬{slide_index}é¡µï¼šslideå¿…é¡»æ˜¯å­—å…¸æ ¼å¼")
                return errors

            # æ£€æŸ¥å¿…éœ€å­—æ®µ
            required_fields = ['page_number', 'title', 'content_points', 'slide_type']
            for field in required_fields:
                if field not in slide:
                    errors.append(f"ç¬¬{slide_index}é¡µï¼šç¼ºå°‘å¿…éœ€å­—æ®µ {field}")

            # æ£€æŸ¥å­—æ®µç±»åž‹å’Œå€¼
            if 'page_number' in slide:
                page_num = slide['page_number']
                if not isinstance(page_num, int) or page_num != slide_index:
                    errors.append(f"ç¬¬{slide_index}é¡µï¼špage_numberåº”ä¸º{slide_index}ï¼Œå®žé™…ä¸º{page_num}")

            if 'title' in slide:
                title = slide['title']
                if not isinstance(title, str) or not title.strip():
                    errors.append(f"ç¬¬{slide_index}é¡µï¼štitleå¿…é¡»æ˜¯éžç©ºå­—ç¬¦ä¸²")

            if 'content_points' in slide:
                content_points = slide['content_points']
                if not isinstance(content_points, list):
                    errors.append(f"ç¬¬{slide_index}é¡µï¼šcontent_pointså¿…é¡»æ˜¯åˆ—è¡¨æ ¼å¼")
                elif len(content_points) == 0:
                    errors.append(f"ç¬¬{slide_index}é¡µï¼šcontent_pointsä¸èƒ½ä¸ºç©º")
                else:
                    for j, point in enumerate(content_points):
                        if not isinstance(point, str) or not point.strip():
                            errors.append(f"ç¬¬{slide_index}é¡µï¼šcontent_points[{j}]å¿…é¡»æ˜¯éžç©ºå­—ç¬¦ä¸²")

            if 'slide_type' in slide:
                slide_type = slide['slide_type']
                valid_types = ['title', 'content', 'agenda', 'thankyou']
                if slide_type not in valid_types:
                    valid_types_str = ', '.join(valid_types)
                    errors.append(f"ç¬¬{slide_index}é¡µï¼šslide_typeå¿…é¡»æ˜¯{valid_types_str}ä¸­çš„ä¸€ä¸ªï¼Œå®žé™…ä¸º{slide_type}")

            return errors

        except Exception as e:
            errors.append(f"ç¬¬{slide_index}é¡µéªŒè¯å‡ºé”™: {str(e)}")
            return errors

    async def _repair_outline_with_ai(self, outline_data: Dict[str, Any], validation_errors: List[str], confirmed_requirements: Dict[str, Any]) -> Dict[str, Any]:
        """ä½¿ç”¨AIä¿®å¤å¤§çº²JSONæ•°æ®"""
        try:
            # æž„å»ºä¿®å¤æç¤ºè¯
            repair_prompt = self._build_repair_prompt(outline_data, validation_errors, confirmed_requirements)

            # è°ƒç”¨AIè¿›è¡Œä¿®å¤
            response = await self.ai_provider.text_completion(
                prompt=repair_prompt,
                max_tokens=ai_config.max_tokens,
                temperature=0.3  # ä½¿ç”¨è¾ƒä½Žçš„æ¸©åº¦ä»¥ç¡®ä¿æ›´å‡†ç¡®çš„ä¿®å¤
            )

            # è§£æžAIè¿”å›žçš„ä¿®å¤ç»“æžœ
            repaired_content = response.content.strip()

            # æå–JSON - æ”¹è¿›çš„æå–é€»è¾‘
            import re
            json_str = None

            # æ–¹æ³•1: å°è¯•æå–```json```ä»£ç å—ä¸­çš„å†…å®¹
            json_block_match = re.search(r'```json\s*(\{.*?\})\s*```', repaired_content, re.DOTALL)
            if json_block_match:
                json_str = json_block_match.group(1)
                logger.info("ä»Ž```json```ä»£ç å—ä¸­æå–JSON")
            else:
                # æ–¹æ³•2: å°è¯•æå–```ä»£ç å—ä¸­çš„å†…å®¹ï¼ˆä¸å¸¦jsonæ ‡è¯†ï¼‰
                code_block_match = re.search(r'```\s*(\{.*?\})\s*```', repaired_content, re.DOTALL)
                if code_block_match:
                    json_str = code_block_match.group(1)
                    logger.info("ä»Ž```ä»£ç å—ä¸­æå–JSON")
                else:
                    # æ–¹æ³•3: å°è¯•æå–å®Œæ•´çš„JSONå¯¹è±¡ï¼ˆéžè´ªå©ªåŒ¹é…ï¼‰
                    json_match = re.search(r'\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\}', repaired_content, re.DOTALL)
                    if json_match:
                        json_str = json_match.group()
                        logger.info("ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–JSON")
                    else:
                        # æ–¹æ³•4: å‡è®¾æ•´ä¸ªå†…å®¹å°±æ˜¯JSON
                        json_str = repaired_content
                        logger.info("å°†æ•´ä¸ªå“åº”å†…å®¹ä½œä¸ºJSONå¤„ç†")

            # æ¸…ç†JSONå­—ç¬¦ä¸²ä¸­çš„å¸¸è§é—®é¢˜
            if json_str:
                # ç§»é™¤å¯èƒ½çš„å‰åŽç©ºç™½å’Œæ¢è¡Œ
                json_str = json_str.strip()
                # ä¿®å¤å¸¸è§çš„JSONæ ¼å¼é—®é¢˜
                json_str = re.sub(r',\s*}', '}', json_str)  # ç§»é™¤}å‰çš„å¤šä½™é€—å·
                json_str = re.sub(r',\s*]', ']', json_str)  # ç§»é™¤]å‰çš„å¤šä½™é€—å·

            repaired_outline = json.loads(json_str)

            logger.info("AIä¿®å¤å®Œæˆï¼Œè¿”å›žä¿®å¤åŽçš„å¤§çº²")
            return repaired_outline

        except Exception as e:
            logger.error(f"AIä¿®å¤è¿‡ç¨‹å‡ºé”™: {str(e)}")
            # å¦‚æžœAIä¿®å¤å¤±è´¥ï¼Œç›´æŽ¥è¿”å›žåŽŸå§‹æ•°æ®
            return outline_data

    def _build_repair_prompt(self, outline_data: Dict[str, Any], validation_errors: List[str], confirmed_requirements: Dict[str, Any]) -> str:
        """æž„å»ºAIä¿®å¤æç¤ºè¯"""
        return prompts_manager.get_repair_prompt(outline_data, validation_errors, confirmed_requirements)




    async def _update_outline_generation_stage(self, project_id: str, outline_data: Dict[str, Any]):
        """Update outline generation stage status and save to database"""
        try:
            # ä¿å­˜å¤§çº²åˆ°æ•°æ®åº“
            from .db_project_manager import DatabaseProjectManager
            db_manager = DatabaseProjectManager()

            project = await self.project_manager.get_project(project_id)
            if not project:
                logger.error(f"âŒ Project not found in memory for project {project_id}")
                return

            # ç¡®ä¿é¡¹ç›®æœ‰outlineæ•°æ®ï¼Œå¦‚æžœæ²¡æœ‰åˆ™ä½¿ç”¨ä¼ å…¥çš„outline_data
            if not project.outline:
                logger.info(f"Project outline is None, setting outline from outline_data")
                project.outline = outline_data
                project.updated_at = time.time()

            # ä¿å­˜å¤§çº²åˆ°æ•°æ®åº“ - ä½¿ç”¨outline_dataè€Œä¸æ˜¯project.outline
            save_success = await db_manager.save_project_outline(project_id, outline_data)

            if save_success:
                logger.info(f"âœ… Successfully saved outline to database for project {project_id}")

                # éªŒè¯ä¿å­˜æ˜¯å¦æˆåŠŸ
                saved_project = await db_manager.get_project(project_id)
                if saved_project and saved_project.outline:
                    saved_slides_count = len(saved_project.outline.get('slides', []))
                    logger.info(f"âœ… Verified: outline saved with {saved_slides_count} slides")

                    # ç¡®ä¿å†…å­˜ä¸­çš„é¡¹ç›®æ•°æ®ä¹Ÿæ˜¯æœ€æ–°çš„
                    project.outline = saved_project.outline
                    project.updated_at = saved_project.updated_at
                    logger.info(f"âœ… Updated memory project with database outline")
                else:
                    logger.error(f"âŒ Verification failed: outline not found in database")
            else:
                logger.error(f"âŒ Failed to save outline to database for project {project_id}")

            # Update project manager
            await self.project_manager.update_project_status(project_id, "in_progress")

            # Update TODO board stage status
            if project.todo_board:
                for stage in project.todo_board.stages:
                    if stage.id == "outline_generation":
                        stage.status = "completed"
                        stage.result = {"outline_data": outline_data}
                        break

                # Update the project in project manager
                await self.project_manager.update_stage_status(
                    project_id, "outline_generation", "completed",
                    progress=100.0, result={"outline_data": outline_data}
                )

        except Exception as e:
            logger.error(f"Error updating outline generation stage: {str(e)}")
            import traceback
            traceback.print_exc()

    def _parse_outline_content(self, content: str, project: PPTProject) -> Dict[str, Any]:
        """Parse outline content to extract structured data for PPT generation"""
        try:
            import re
            import json

            # First try to parse the entire content as JSON
            try:
                json_data = json.loads(content)
                if isinstance(json_data, dict) and 'slides' in json_data:
                    logger.info(f"Successfully parsed complete JSON outline with {len(json_data['slides'])} slides")
                    # æ ‡å‡†åŒ–slidesæ ¼å¼ä»¥ç¡®ä¿å…¼å®¹æ€§
                    standardized_data = self._standardize_outline_format(json_data)
                    return standardized_data
            except json.JSONDecodeError:
                pass

            # æ”¹è¿›çš„JSONæå–é€»è¾‘
            json_str = None

            # æ–¹æ³•1: å°è¯•æå–```json```ä»£ç å—ä¸­çš„å†…å®¹
            json_block_match = re.search(r'```json\s*(\{.*?\})\s*```', content, re.DOTALL)
            if json_block_match:
                json_str = json_block_match.group(1)
                logger.info("ä»Ž```json```ä»£ç å—ä¸­æå–JSON")
            else:
                # æ–¹æ³•2: å°è¯•æå–```ä»£ç å—ä¸­çš„å†…å®¹ï¼ˆä¸å¸¦jsonæ ‡è¯†ï¼‰
                code_block_match = re.search(r'```\s*(\{.*?\})\s*```', content, re.DOTALL)
                if code_block_match:
                    json_str = code_block_match.group(1)
                    logger.info("ä»Ž```ä»£ç å—ä¸­æå–JSON")
                else:
                    # æ–¹æ³•3: å°è¯•æå–å®Œæ•´çš„JSONå¯¹è±¡
                    json_match = re.search(r'\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\}', content, re.DOTALL)
                    if json_match:
                        json_str = json_match.group()
                        logger.info("ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–JSON")

            if json_str:
                try:
                    # æ¸…ç†JSONå­—ç¬¦ä¸²
                    json_str = json_str.strip()
                    json_str = re.sub(r',\s*}', '}', json_str)  # ç§»é™¤}å‰çš„å¤šä½™é€—å·
                    json_str = re.sub(r',\s*]', ']', json_str)  # ç§»é™¤]å‰çš„å¤šä½™é€—å·

                    json_data = json.loads(json_str)
                    if 'slides' in json_data:
                        logger.info(f"Successfully extracted JSON from content with {len(json_data['slides'])} slides")
                        # æ ‡å‡†åŒ–slidesæ ¼å¼ä»¥ç¡®ä¿å…¼å®¹æ€§
                        standardized_data = self._standardize_outline_format(json_data)
                        return standardized_data
                except json.JSONDecodeError as e:
                    logger.warning(f"Failed to parse extracted JSON: {e}")
                    pass

            # Fallback: parse text-based outline
            lines = content.split('\n')
            slides = []
            current_slide = None
            slide_number = 1

            for line in lines:
                line = line.strip()
                if not line:
                    continue

                # Check for slide titles (various formats)
                if (line.startswith('#') or
                    line.startswith('ç¬¬') and ('é¡µ' in line or 'ç« ' in line) or
                    line.startswith('Page') or
                    re.match(r'^\d+[\.\)]\s*', line) or
                    line.endswith('ï¼š') or line.endswith(':')):

                    # Save previous slide
                    if current_slide:
                        slides.append(current_slide)

                    # Clean title
                    title = re.sub(r'^#+\s*', '', line)  # Remove markdown headers
                    title = re.sub(r'^ç¬¬\d+[é¡µç« ]\s*[ï¼š:]\s*', '', title)  # Remove "ç¬¬Xé¡µï¼š"
                    title = re.sub(r'^Page\s*\d+\s*[ï¼š:]\s*', '', title, flags=re.IGNORECASE)  # Remove "Page X:"
                    title = re.sub(r'^\d+[\.\)]\s*', '', title)  # Remove "1. " or "1) "
                    title = title.rstrip('ï¼š:')  # Remove trailing colons

                    # Determine slide type
                    slide_type = "content"
                    if slide_number == 1 or 'æ ‡é¢˜' in title or 'Title' in title or 'å°é¢' in title:
                        slide_type = "title"
                    elif 'è°¢è°¢' in title or 'Thank' in title or 'ç»“æŸ' in title or 'æ€»ç»“' in title:
                        slide_type = "thankyou"
                    elif 'ç›®å½•' in title or 'Agenda' in title or 'å¤§çº²' in title:
                        slide_type = "agenda"

                    current_slide = {
                        "page_number": slide_number,
                        "title": title or f"ç¬¬{slide_number}é¡µ",
                        "content_points": [],
                        "slide_type": slide_type
                    }
                    slide_number += 1

                elif current_slide and (line.startswith('-') or line.startswith('â€¢') or
                                      line.startswith('*') or re.match(r'^\d+[\.\)]\s*', line)):
                    # Content point
                    point = re.sub(r'^[-â€¢*]\s*', '', line)
                    point = re.sub(r'^\d+[\.\)]\s*', '', point)
                    if point:
                        current_slide["content_points"].append(point)

                elif current_slide and line and not line.startswith('#'):
                    # Regular content line
                    current_slide["content_points"].append(line)

            # Add the last slide
            if current_slide:
                slides.append(current_slide)

            # If no slides were parsed, create a default structure
            if not slides:
                slides = self._create_default_slides_from_content(content, project)

            return {
                "title": project.topic,
                "slides": slides
            }

        except Exception as e:
            logger.error(f"Error parsing outline content: {str(e)}")
            # Return default structure
            return {
                "title": project.topic,
                "slides": self._create_default_slides_from_content(content, project)
            }

    def _standardize_outline_format(self, outline_data: Dict[str, Any]) -> Dict[str, Any]:
        """æ ‡å‡†åŒ–å¤§çº²æ ¼å¼ï¼Œç¡®ä¿slideså­—æ®µçš„å…¼å®¹æ€§"""
        try:
            import re

            # ç¡®ä¿æœ‰åŸºæœ¬ç»“æž„
            if not isinstance(outline_data, dict):
                raise ValueError("Outline data must be a dictionary")

            title = outline_data.get("title", "PPTå¤§çº²")
            slides_data = outline_data.get("slides", [])
            metadata = outline_data.get("metadata", {})

            if not isinstance(slides_data, list):
                raise ValueError("Slides data must be a list")

            # æ ‡å‡†åŒ–æ¯ä¸ªslideçš„æ ¼å¼
            standardized_slides = []

            for i, slide in enumerate(slides_data):
                if not isinstance(slide, dict):
                    continue

                # æå–åŸºæœ¬ä¿¡æ¯
                page_number = slide.get("page_number", i + 1)
                title_text = slide.get("title", f"ç¬¬{page_number}é¡µ")

                # å¤„ç†content_pointså­—æ®µ
                content_points = slide.get("content_points", [])
                if not isinstance(content_points, list):
                    content_points = []

                # å¦‚æžœæ²¡æœ‰content_pointsï¼Œå°è¯•ä»Žå…¶ä»–å­—æ®µæå–
                if not content_points:
                    # å°è¯•ä»Žcontentå­—æ®µæå–
                    content = slide.get("content", "")
                    if content:
                        lines = content.split('\n')
                        for line in lines:
                            line = line.strip()
                            if line:
                                # ç§»é™¤bullet pointç¬¦å·
                                line = re.sub(r'^[â€¢\-\*]\s*', '', line)
                                if line:
                                    content_points.append(line)

                    # å¦‚æžœä»ç„¶æ²¡æœ‰ï¼Œä½¿ç”¨é»˜è®¤å€¼
                    if not content_points:
                        content_points = ["å†…å®¹è¦ç‚¹"]

                # å¤„ç†slide_typeå­—æ®µ
                slide_type = slide.get("slide_type", slide.get("type", "content"))

                # æ™ºèƒ½è¯†åˆ«slideç±»åž‹
                title_lower = title_text.lower()
                if page_number == 1 or "æ ‡é¢˜" in title_lower or "title" in title_lower:
                    slide_type = "title"
                elif "ç›®å½•" in title_lower or "agenda" in title_lower or "å¤§çº²" in title_lower:
                    slide_type = "agenda"
                elif "è°¢è°¢" in title_lower or "thank" in title_lower or "è‡´è°¢" in title_lower:
                    slide_type = "thankyou"
                elif "æ€»ç»“" in title_lower or "ç»“è®º" in title_lower or "conclusion" in title_lower:
                    slide_type = "conclusion"
                elif slide_type not in ["title", "content", "agenda", "thankyou", "conclusion"]:
                    slide_type = "content"

                # æž„å»ºæ ‡å‡†åŒ–çš„slide
                standardized_slide = {
                    "page_number": page_number,
                    "title": title_text,
                    "content_points": content_points,
                    "slide_type": slide_type,
                    "type": slide_type,  # æ·»åŠ typeå­—æ®µä»¥å…¼å®¹ä¸åŒçš„è®¿é—®æ–¹å¼
                    "description": slide.get("description", "")
                }

                # ä¿ç•™chart_configå¦‚æžœå­˜åœ¨
                if "chart_config" in slide and slide["chart_config"]:
                    standardized_slide["chart_config"] = slide["chart_config"]

                standardized_slides.append(standardized_slide)

            # æž„å»ºæ ‡å‡†åŒ–çš„å¤§çº²
            standardized_outline = {
                "title": title,
                "slides": standardized_slides,
                "metadata": metadata
            }

            logger.info(f"Successfully standardized outline format: {title}, {len(standardized_slides)} slides")
            return standardized_outline

        except Exception as e:
            logger.error(f"Error standardizing outline format: {str(e)}")
            # è¿”å›žåŽŸå§‹æ•°æ®æˆ–é»˜è®¤ç»“æž„
            if isinstance(outline_data, dict) and "slides" in outline_data:
                return outline_data
            else:
                return {
                    "title": "PPTå¤§çº²",
                    "slides": [
                        {
                            "page_number": 1,
                            "title": "æ ‡é¢˜é¡µ",
                            "content_points": ["æ¼”ç¤ºæ ‡é¢˜"],
                            "slide_type": "title",
                            "type": "title",
                            "description": "PPTæ ‡é¢˜é¡µ"
                        }
                    ],
                    "metadata": {}
                }

    def _create_default_slides_from_content(self, content: str, project: PPTProject) -> List[Dict[str, Any]]:
        """Create default slides structure from content"""
        slides = [
            {
                "page_number": 1,
                "title": project.topic,
                "content_points": ["é¡¹ç›®ä»‹ç»", "ä¸»è¦å†…å®¹", "æ ¸å¿ƒç‰¹ç‚¹"],
                "slide_type": "title"
            },
            {
                "page_number": 2,
                "title": "ä¸»è¦å†…å®¹",
                "content_points": content.split('\n')[:5] if content else ["å†…å®¹è¦ç‚¹1", "å†…å®¹è¦ç‚¹2", "å†…å®¹è¦ç‚¹3"],
                "slide_type": "content"
            },
            {
                "page_number": 3,
                "title": "è°¢è°¢",
                "content_points": ["æ„Ÿè°¢è†å¬"],
                "slide_type": "thankyou"
            }
        ]
        return slides

    async def update_project_outline(self, project_id: str, outline_content: str) -> bool:
        """Update project outline content (expects JSON format)"""
        try:
            project = await self.project_manager.get_project(project_id)
            if not project:
                return False

            import json

            # Try to parse the content as JSON
            try:
                structured_outline = json.loads(outline_content)

                # Validate the JSON structure
                if 'slides' not in structured_outline:
                    raise ValueError("Invalid JSON structure: missing 'slides'")

                # æ ‡å‡†åŒ–å¤§çº²æ ¼å¼ä»¥ç¡®ä¿å…¼å®¹æ€§
                structured_outline = self._standardize_outline_format(structured_outline)

                # Format the JSON for consistent display
                formatted_json = json.dumps(structured_outline, ensure_ascii=False, indent=2)

            except json.JSONDecodeError:
                # If not valid JSON, try to parse as text and convert to JSON
                structured_outline = self._parse_outline_content(outline_content, project)
                formatted_json = json.dumps(structured_outline, ensure_ascii=False, indent=2)

            # Update outline in the correct field
            if not project.outline:
                project.outline = {}
            project.outline["content"] = formatted_json  # Store formatted JSON
            project.outline["title"] = structured_outline.get("title", project.topic)
            project.outline["slides"] = structured_outline.get("slides", [])
            project.outline["updated_at"] = time.time()

            # ä¿å­˜æ›´æ–°çš„å¤§çº²åˆ°æ•°æ®åº“
            try:
                from .db_project_manager import DatabaseProjectManager
                db_manager = DatabaseProjectManager()
                save_success = await db_manager.save_project_outline(project_id, project.outline)

                if save_success:
                    logger.info(f"âœ… Successfully saved updated outline to database for project {project_id}")
                else:
                    logger.error(f"âŒ Failed to save updated outline to database for project {project_id}")

            except Exception as save_error:
                logger.error(f"âŒ Exception while saving updated outline to database: {str(save_error)}")

            # Update TODO board stage result
            if project.todo_board:
                for stage in project.todo_board.stages:
                    if stage.id == "outline_generation":
                        if not stage.result:
                            stage.result = {}
                        stage.result["outline_content"] = formatted_json
                        break

            return True

        except Exception as e:
            logger.error(f"Error updating project outline: {str(e)}")
            return False

    async def confirm_project_outline(self, project_id: str) -> bool:
        """Confirm project outline and enable PPT generation"""
        try:
            project = await self.project_manager.get_project(project_id)
            if not project:
                return False

            # ç¡®ä¿å¤§çº²æ•°æ®å­˜åœ¨
            if not project.outline:
                logger.error(f"No outline found for project {project_id}")
                return False

            # æ£€æŸ¥å¤§çº²æ˜¯å¦åŒ…å«slidesæ•°æ®
            if not project.outline.get('slides'):
                logger.error(f"No slides found in outline for project {project_id}")

                # é¦–å…ˆå°è¯•ä»Žconfirmed_requirementsä¸­çš„file_generated_outlineæ¢å¤
                if (project.confirmed_requirements and
                    project.confirmed_requirements.get('file_generated_outline') and
                    isinstance(project.confirmed_requirements['file_generated_outline'], dict)):

                    file_outline = project.confirmed_requirements['file_generated_outline']
                    if file_outline.get('slides'):
                        logger.info(f"Restoring outline from file_generated_outline with {len(file_outline['slides'])} slides")
                        # æ¢å¤å®Œæ•´çš„å¤§çº²æ•°æ®ï¼Œä¿ç•™ç¡®è®¤çŠ¶æ€
                        project.outline = file_outline.copy()
                        project.outline["confirmed"] = True
                        project.outline["confirmed_at"] = time.time()
                    else:
                        logger.error(f"file_generated_outline does not contain slides data")
                        return False
                else:
                    # å°è¯•ä»Žæ•°æ®åº“é‡æ–°åŠ è½½å¤§çº²
                    try:
                        from .db_project_manager import DatabaseProjectManager
                        db_manager = DatabaseProjectManager()
                        db_project = await db_manager.get_project(project_id)
                        if db_project and db_project.outline and db_project.outline.get('slides'):
                            project.outline = db_project.outline
                            logger.info(f"Reloaded outline from database for project {project_id}")
                        else:
                            logger.error(f"No valid outline found in database for project {project_id}")
                            return False
                    except Exception as reload_error:
                        logger.error(f"Failed to reload outline from database: {reload_error}")
                        return False

            # ä¿ç•™åŽŸæœ‰çš„å¤§çº²æ•°æ®ï¼Œåªæ·»åŠ ç¡®è®¤çŠ¶æ€
            project.outline["confirmed"] = True
            project.outline["confirmed_at"] = time.time()

            # ä¿å­˜ç¡®è®¤çŠ¶æ€åˆ°æ•°æ®åº“
            try:
                from .db_project_manager import DatabaseProjectManager
                db_manager = DatabaseProjectManager()
                save_success = await db_manager.save_project_outline(project_id, project.outline)

                if save_success:
                    logger.info(f"âœ… Successfully saved outline confirmation to database for project {project_id}")
                else:
                    logger.error(f"âŒ Failed to save outline confirmation to database for project {project_id}")

            except Exception as save_error:
                logger.error(f"âŒ Exception while saving outline confirmation to database: {save_error}")

            # Update TODO board - mark outline as confirmed and enable PPT creation
            if project.todo_board:
                for stage in project.todo_board.stages:
                    if stage.id == "outline_generation":
                        stage.status = "completed"
                        if not stage.result:
                            stage.result = {}
                        stage.result["confirmed"] = True
                    elif stage.id == "ppt_creation":
                        stage.status = "pending"  # Enable PPT creation
                        break

            # Update project manager
            await self.project_manager.update_stage_status(
                project_id, "outline_generation", "completed",
                progress=100.0, result={"confirmed": True}
            )

            return True

        except Exception as e:
            logger.error(f"Error confirming project outline: {e}")
            return False

    def _get_default_suggestions(self, project: PPTProject) -> Dict[str, Any]:
        """Get default suggestions when AI generation fails"""
        # Generate basic suggestions based on project scenario
        scenario_types = {
            "general": ["é€šç”¨å±•ç¤º", "ç»¼åˆä»‹ç»", "æ¦‚è¿°æŠ¥å‘Š", "åŸºç¡€å±•ç¤º"],
            "tourism": ["æ—…æ¸¸æŽ¨ä»‹", "æ™¯ç‚¹ä»‹ç»", "æ–‡åŒ–å±•ç¤º", "æ—…è¡Œè§„åˆ’"],
            "education": ["æ•™å­¦è¯¾ä»¶", "å­¦æœ¯æŠ¥å‘Š", "çŸ¥è¯†åˆ†äº«", "åŸ¹è®­ææ–™"],
            "analysis": ["æ•°æ®åˆ†æž", "ç ”ç©¶æŠ¥å‘Š", "åˆ†æžæ€»ç»“", "è°ƒç ”å±•ç¤º"],
            "history": ["åŽ†å²å›žé¡¾", "æ–‡åŒ–ä¼ æ‰¿", "æ—¶ä»£å˜è¿", "åŽ†å²æ•™è‚²"],
            "technology": ["æŠ€æœ¯åˆ†äº«", "äº§å“ä»‹ç»", "åˆ›æ–°å±•ç¤º", "æŠ€æœ¯æ–¹æ¡ˆ"],
            "business": ["å•†ä¸šè®¡åˆ’", "é¡¹ç›®æ±‡æŠ¥", "ä¸šåŠ¡ä»‹ç»", "ä¼ä¸šå±•ç¤º"]
        }

        # Get type options based on scenario
        type_options = scenario_types.get(project.scenario, scenario_types["general"])

        # Generate suggested topic based on original topic
        suggested_topic = f"{project.topic} - ä¸“ä¸šå±•ç¤º"

        return {
            "suggested_topic": suggested_topic,
            "type_options": type_options
        }

    def _get_default_todo_structure(self, confirmed_requirements: Dict[str, Any]) -> Dict[str, Any]:
        """Get default TODO structure based on confirmed requirements"""
        return {
            "stages": [
                {
                    "id": "outline_generation",
                    "name": "ç”ŸæˆPPTå¤§çº²",
                    "description": "è®¾è®¡PPTæ•´ä½“ç»“æž„ä¸Žæ¡†æž¶ï¼Œè§„åˆ’å„ç« èŠ‚å†…å®¹ä¸Žå…³é”®ç‚¹ï¼Œç¡®å®šæ ¸å¿ƒä¼˜åŠ¿å’Œåˆ›æ–°ç‚¹çš„å±•ç¤ºæ–¹å¼",
                    "subtasks": ["ç”ŸæˆPPTå¤§çº²"]  # Single task, description is explanatory
                },
                {
                    "id": "ppt_creation",
                    "name": "åˆ¶ä½œPPT",
                    "description": "è®¾è®¡PPTå°é¢ä¸Žå¯¼èˆªé¡µï¼Œæ ¹æ®å¤§çº²åˆ¶ä½œå„ç« èŠ‚å†…å®¹é¡µé¢ï¼Œæ·»åŠ è§†è§‰å…ƒç´ å’Œå›¾è¡¨ç¾ŽåŒ–PPT",
                    "subtasks": ["åˆ¶ä½œPPT"]  # Single task, description is explanatory
                }
            ]
        }

    async def _update_project_todo_board(self, project_id: str, todo_data: Dict[str, Any],
                                       confirmed_requirements: Dict[str, Any]):
        """Update project TODO board with custom stages (including requirements confirmation)"""
        try:
            from ..api.models import TodoStage, TodoBoard
            import time

            # Create complete stages including requirements confirmation
            stages = [
                TodoStage(
                    id="requirements_confirmation",
                    name="éœ€æ±‚ç¡®è®¤",
                    description="AIæ ¹æ®ç”¨æˆ·è®¾å®šçš„åœºæ™¯å’Œä¸Šä¼ çš„æ–‡ä»¶å†…å®¹æä¾›è¡¥å……ä¿¡æ¯ç”¨æ¥ç¡®è®¤ç”¨æˆ·çš„ä»»åŠ¡éœ€æ±‚",
                    status="completed",  # This stage is completed when requirements are confirmed
                    progress=100.0,
                    subtasks=["éœ€æ±‚ç¡®è®¤å®Œæˆ"]
                )
            ]

            # Add custom stages from AI generation
            for stage_data in todo_data.get("stages", []):
                stage = TodoStage(
                    id=stage_data["id"],
                    name=stage_data["name"],
                    description=stage_data["description"],
                    subtasks=stage_data["subtasks"],
                    status="pending",  # Start as pending
                    progress=0.0
                )
                stages.append(stage)

            # Create custom TODO board
            todo_board = TodoBoard(
                task_id=project_id,
                title=confirmed_requirements['topic'],
                stages=stages
            )

            # Calculate correct overall progress
            completed_stages = sum(1 for s in stages if s.status == "completed")
            todo_board.overall_progress = (completed_stages / len(stages)) * 100

            # Set current stage index to the first non-completed stage
            todo_board.current_stage_index = 0
            for i, stage in enumerate(stages):
                if stage.status != "completed":
                    todo_board.current_stage_index = i
                    break

            # Update project manager
            self.project_manager.todo_boards[project_id] = todo_board

            # Update project with confirmed requirements
            project = await self.project_manager.get_project(project_id)
            if project:
                project.topic = confirmed_requirements['topic']
                project.requirements = f"""
ç±»åž‹ï¼š{confirmed_requirements['type']}
å…¶ä»–è¯´æ˜Žï¼š{confirmed_requirements.get('description', 'æ— ')}
"""
                project.updated_at = time.time()

        except Exception as e:
            logger.error(f"Error updating project TODO board: {e}")
            raise

    async def confirm_requirements_and_update_workflow(self, project_id: str, confirmed_requirements: Dict[str, Any]) -> bool:
        """Confirm requirements and update the TODO board with complete workflow"""
        try:
            project = await self.project_manager.get_project(project_id)
            if not project:
                return False

            # Store confirmed requirements
            project.confirmed_requirements = confirmed_requirements
            project.status = "in_progress"
            project.updated_at = time.time()

            # å¦‚æžœæœ‰æ–‡ä»¶ç”Ÿæˆçš„å¤§çº²ï¼Œç›´æŽ¥è®¾ç½®åˆ°é¡¹ç›®çš„outlineå­—æ®µä¸­
            file_generated_outline = confirmed_requirements.get('file_generated_outline')
            if file_generated_outline and isinstance(file_generated_outline, dict):
                logger.info(f"Setting file-generated outline to project {project_id}")
                project.outline = file_generated_outline
                project.updated_at = time.time()

            # Save confirmed requirements to database
            try:
                from .db_project_manager import DatabaseProjectManager
                db_manager = DatabaseProjectManager()

                # Update project status
                await db_manager.update_project_status(project_id, "in_progress")
                logger.info(f"Successfully updated project status in database for project {project_id}")

                # Save confirmed requirements to database
                await db_manager.save_confirmed_requirements(project_id, confirmed_requirements)
                logger.info(f"Successfully saved confirmed requirements to database for project {project_id}")

                # å¦‚æžœæœ‰æ–‡ä»¶ç”Ÿæˆçš„å¤§çº²ï¼Œä¹Ÿä¿å­˜åˆ°æ•°æ®åº“
                if file_generated_outline:
                    save_success = await db_manager.save_project_outline(project_id, file_generated_outline)
                    if save_success:
                        logger.info(f"âœ… Successfully saved file-generated outline to database for project {project_id}")
                    else:
                        logger.error(f"âŒ Failed to save file-generated outline to database for project {project_id}")

                # Update requirements confirmation stage to completed
                await db_manager.update_stage_status(
                    project_id,
                    "requirements_confirmation",
                    "completed",
                    100.0,
                    {"confirmed_at": time.time(), "requirements": confirmed_requirements}
                )
                logger.info(f"Successfully updated requirements confirmation stage to completed for project {project_id}")

            except Exception as save_error:
                logger.error(f"Failed to update project status or save requirements in database: {save_error}")
                import traceback
                traceback.print_exc()

            # Update TODO board with default workflow (æ— éœ€AIç”Ÿæˆ) - ä¿®å¤ï¼šæ·»åŠ await
            success = await self.project_manager.update_todo_board_with_confirmed_requirements(
                project_id, confirmed_requirements
            )

            # ä¸å†å¯åŠ¨åŽå°å·¥ä½œæµï¼Œè®©å‰ç«¯ç›´æŽ¥æŽ§åˆ¶å¤§çº²ç”Ÿæˆ
            return success

        except Exception as e:
            logger.error(f"Error confirming requirements: {e}")
            return False

    def _load_prompts_md_system_prompt(self) -> str:
        """Load system prompt from prompts.md file"""
        return prompts_manager.load_prompts_md_system_prompt()

    def _load_keynote_style_prompt(self) -> str:
        """Load keynote style prompt from keynote_style_prompt.md file"""
        return prompts_manager.get_keynote_style_prompt()

    def _get_style_prompt(self, confirmed_requirements: Dict[str, Any]) -> str:
        """Get style prompt based on confirmed requirements"""
        if not confirmed_requirements:
            return self._load_prompts_md_system_prompt()

        ppt_style = confirmed_requirements.get('ppt_style', 'general')

        if ppt_style == 'keynote':
            return self._load_keynote_style_prompt()
        elif ppt_style == 'custom':
            custom_prompt = confirmed_requirements.get('custom_style_prompt', '')
            if custom_prompt:
                return prompts_manager.get_custom_style_prompt(custom_prompt)
            else:
                return self._load_prompts_md_system_prompt()
        else:
            # Default to general style (prompts.md)
            return self._load_prompts_md_system_prompt()

    def _get_default_ppt_system_prompt(self) -> str:
        """Get default PPT generation system prompt"""
        return prompts_manager.get_default_ppt_system_prompt()

    async def _execute_outline_generation(self, project_id: str, confirmed_requirements: Dict[str, Any], system_prompt: str) -> str:
        """Execute outline generation as a complete task"""
        try:
            # å¤„ç†é¡µæ•°è®¾ç½®
            page_count_settings = confirmed_requirements.get('page_count_settings', {})
            page_count_mode = page_count_settings.get('mode', 'ai_decide')

            page_count_instruction = ""
            expected_page_count = None  # Track expected page count for validation

            if page_count_mode == 'custom_range':
                min_pages = page_count_settings.get('min_pages', 8)
                max_pages = page_count_settings.get('max_pages', 15)
                # æ›´å¼ºè°ƒé¡µæ•°è¦æ±‚
                page_count_instruction = f"- é¡µæ•°è¦æ±‚ï¼šå¿…é¡»ä¸¥æ ¼ç”Ÿæˆ{min_pages}-{max_pages}é¡µçš„PPTã€‚è¯·ç¡®ä¿ç”Ÿæˆçš„å¹»ç¯ç‰‡æ•°é‡åœ¨æ­¤èŒƒå›´å†…ï¼Œä¸èƒ½è¶…å‡ºæˆ–ä¸è¶³ã€‚"
                expected_page_count = {"min": min_pages, "max": max_pages, "mode": "range"}
                logger.info(f"Custom page count range set: {min_pages}-{max_pages} pages")
            else:
                # AIå†³å®šæ¨¡å¼ï¼šä¸ç»™å‡ºå…·ä½“é¡µæ•°é™åˆ¶ï¼Œè®©AIè‡ªè¡Œåˆ¤æ–­
                page_count_instruction = "- é¡µæ•°è¦æ±‚ï¼šè¯·æ ¹æ®ä¸»é¢˜å†…å®¹çš„å¤æ‚åº¦ã€æ·±åº¦å’Œé€»è¾‘ç»“æž„ï¼Œè‡ªä¸»å†³å®šæœ€åˆé€‚çš„é¡µæ•°ï¼Œç¡®ä¿å†…å®¹å……å®žä¸”é€»è¾‘æ¸…æ™°"
                expected_page_count = {"mode": "ai_decide"}
                logger.info("AI decide mode set for page count")

            # ä½¿ç”¨å­—ç¬¦ä¸²æ‹¼æŽ¥é¿å…f-stringä¸­çš„èŠ±æ‹¬å·å†²çª
            topic = confirmed_requirements['topic']
            target_audience = confirmed_requirements.get('target_audience', 'æ™®é€šå¤§ä¼—')
            ppt_style = confirmed_requirements.get('ppt_style', 'general')
            custom_style = confirmed_requirements.get('custom_style_prompt', 'æ— ')
            description = confirmed_requirements.get('description', 'æ— ')

            # ä½¿ç”¨æ–°çš„æç¤ºè¯æ¨¡å—
            context = prompts_manager.get_outline_generation_context(
                topic=topic,
                target_audience=target_audience,
                page_count_instruction=page_count_instruction,
                ppt_style=ppt_style,
                custom_style=custom_style,
                description=description,
                page_count_mode=page_count_mode
            )

            response = await self.ai_provider.text_completion(
                prompt=context,
                system_prompt=system_prompt,
                max_tokens=ai_config.max_tokens,
                temperature=ai_config.temperature
            )

            # Try to parse and store the outline
            import json
            import re

            try:
                # Extract JSON from the response content
                content = response.content.strip()

                # æ”¹è¿›çš„JSONæå–æ–¹æ³•
                json_str = None

                # æ–¹æ³•1: å°è¯•æå–```json```ä»£ç å—ä¸­çš„å†…å®¹
                json_block_match = re.search(r'```json\s*(\{.*?\})\s*```', content, re.DOTALL)
                if json_block_match:
                    json_str = json_block_match.group(1)
                    logger.info("ä»Ž```json```ä»£ç å—ä¸­æå–JSON")
                else:
                    # æ–¹æ³•2: å°è¯•æå–```ä»£ç å—ä¸­çš„å†…å®¹ï¼ˆä¸å¸¦jsonæ ‡è¯†ï¼‰
                    code_block_match = re.search(r'```\s*(\{.*?\})\s*```', content, re.DOTALL)
                    if code_block_match:
                        json_str = code_block_match.group(1)
                        logger.info("ä»Ž```ä»£ç å—ä¸­æå–JSON")
                    else:
                        # æ–¹æ³•3: å°è¯•æå–å®Œæ•´çš„JSONå¯¹è±¡ï¼ˆæ”¹è¿›çš„æ­£åˆ™è¡¨è¾¾å¼ï¼‰
                        json_match = re.search(r'\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\}', content, re.DOTALL)
                        if json_match:
                            json_str = json_match.group()
                            logger.info("ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–JSON")
                        else:
                            # æ–¹æ³•4: å‡è®¾æ•´ä¸ªå†…å®¹å°±æ˜¯JSON
                            json_str = content
                            logger.info("å°†æ•´ä¸ªå“åº”å†…å®¹ä½œä¸ºJSONå¤„ç†")

                # æ¸…ç†JSONå­—ç¬¦ä¸²ä¸­çš„å¸¸è§é—®é¢˜
                if json_str:
                    # ç§»é™¤å¯èƒ½çš„å‰åŽç©ºç™½å’Œæ¢è¡Œ
                    json_str = json_str.strip()
                    # ä¿®å¤å¸¸è§çš„JSONæ ¼å¼é—®é¢˜
                    json_str = re.sub(r',\s*}', '}', json_str)  # ç§»é™¤}å‰çš„å¤šä½™é€—å·
                    json_str = re.sub(r',\s*]', ']', json_str)  # ç§»é™¤]å‰çš„å¤šä½™é€—å·

                outline_data = json.loads(json_str)

                # éªŒè¯å’Œä¿®å¤JSONæ•°æ®
                outline_data = await self._validate_and_repair_outline_json(outline_data, confirmed_requirements)

                # éªŒè¯é¡µæ•°æ˜¯å¦ç¬¦åˆè¦æ±‚
                if expected_page_count and "slides" in outline_data:
                    actual_page_count = len(outline_data["slides"])
                    logger.info(f"Generated outline has {actual_page_count} pages")

                    if expected_page_count["mode"] == "range":
                        min_pages = expected_page_count["min"]
                        max_pages = expected_page_count["max"]

                        if actual_page_count < min_pages or actual_page_count > max_pages:
                            logger.warning(f"Generated outline has {actual_page_count} pages, but expected {min_pages}-{max_pages} pages. Adjusting...")
                            # å¼ºåˆ¶è°ƒæ•´é¡µæ•°
                            outline_data = await self._adjust_outline_page_count(outline_data, min_pages, max_pages, confirmed_requirements)

                            # éªŒè¯è°ƒæ•´åŽçš„é¡µæ•°
                            adjusted_page_count = len(outline_data.get("slides", []))
                            logger.info(f"Adjusted outline to {adjusted_page_count} pages")

                            if adjusted_page_count < min_pages or adjusted_page_count > max_pages:
                                logger.error(f"Failed to adjust page count to required range {min_pages}-{max_pages}")
                                # å¦‚æžœè°ƒæ•´å¤±è´¥ï¼Œå¼ºåˆ¶è®¾ç½®ä¸ºä¸­é—´å€¼
                                target_pages = (min_pages + max_pages) // 2
                                outline_data = await self._force_page_count(outline_data, target_pages, confirmed_requirements)
                        else:
                            logger.info(f"Page count {actual_page_count} is within required range {min_pages}-{max_pages}")

                    # æ·»åŠ é¡µæ•°ä¿¡æ¯åˆ°å¤§çº²å…ƒæ•°æ®
                    if "metadata" not in outline_data:
                        outline_data["metadata"] = {}
                    outline_data["metadata"]["page_count_settings"] = expected_page_count
                    outline_data["metadata"]["actual_page_count"] = len(outline_data.get("slides", []))

                # Store outline in project (å†…å­˜ä¸­)
                project = await self.project_manager.get_project(project_id)
                if project:
                    project.outline = outline_data
                    project.updated_at = time.time()
                    logger.info(f"Successfully saved outline to memory for project {project_id}")

                # Save outline to database (æ•°æ®åº“ä¸­) - è¿™æ˜¯å…³é”®æ­¥éª¤
                try:
                    from .db_project_manager import DatabaseProjectManager
                    db_manager = DatabaseProjectManager()
                    save_success = await db_manager.save_project_outline(project_id, outline_data)

                    if save_success:
                        logger.info(f"âœ… Successfully saved outline to database for project {project_id}")

                        # éªŒè¯ä¿å­˜æ˜¯å¦æˆåŠŸ
                        saved_project = await db_manager.get_project(project_id)
                        if saved_project and saved_project.outline:
                            saved_slides_count = len(saved_project.outline.get('slides', []))
                            logger.info(f"âœ… Verified: outline saved with {saved_slides_count} slides")
                        else:
                            logger.error(f"âŒ Verification failed: outline not found in database")
                            return f"âŒ å¤§çº²ä¿å­˜å¤±è´¥ï¼šæ•°æ®åº“éªŒè¯å¤±è´¥"
                    else:
                        logger.error(f"âŒ Failed to save outline to database for project {project_id}")
                        return f"âŒ å¤§çº²ä¿å­˜å¤±è´¥ï¼šæ•°æ®åº“å†™å…¥å¤±è´¥"

                except Exception as save_error:
                    logger.error(f"âŒ Exception while saving outline to database: {save_error}")
                    import traceback
                    traceback.print_exc()
                    return f"âŒ å¤§çº²ä¿å­˜å¤±è´¥ï¼š{str(save_error)}"

                # æ›´æ–°å¤§çº²ç”Ÿæˆé˜¶æ®µçŠ¶æ€ä¸ºå®Œæˆ
                try:
                    from .db_project_manager import DatabaseProjectManager
                    db_manager = DatabaseProjectManager()

                    await db_manager.update_stage_status(
                        project_id,
                        "outline_generation",
                        "completed",
                        100.0,
                        {
                            "outline_title": outline_data.get('title', 'æœªçŸ¥'),
                            "slides_count": len(outline_data.get('slides', [])),
                            "completed_at": time.time()
                        }
                    )
                    logger.info(f"Successfully updated outline generation stage to completed for project {project_id}")

                except Exception as stage_error:
                    logger.error(f"Failed to update outline generation stage status: {stage_error}")

                final_page_count = len(outline_data.get('slides', []))
                return f"âœ… PPTå¤§çº²ç”Ÿæˆå®Œæˆï¼\n\næ ‡é¢˜ï¼š{outline_data.get('title', 'æœªçŸ¥')}\né¡µæ•°ï¼š{final_page_count}é¡µ\nå·²ä¿å­˜åˆ°æ•°æ®åº“\n\n{response.content}"

            except Exception as e:
                logger.error(f"Error parsing outline JSON: {e}")
                logger.error(f"Response content: {response.content[:500]}...")

                # Try to create a basic outline structure from the response
                try:
                    # Create a fallback outline structure
                    fallback_outline = {
                        "title": confirmed_requirements.get('topic', 'AIç”Ÿæˆçš„PPTå¤§çº²'),
                        "slides": [
                            {
                                "page_number": 1,
                                "title": confirmed_requirements.get('topic', 'æ ‡é¢˜é¡µ'),
                                "content_points": ["é¡¹ç›®ä»‹ç»", "ä¸»è¦å†…å®¹", "æ ¸å¿ƒä»·å€¼"],
                                "slide_type": "title"
                            },
                            {
                                "page_number": 2,
                                "title": "ä¸»è¦å†…å®¹",
                                "content_points": ["å†…å®¹è¦ç‚¹1", "å†…å®¹è¦ç‚¹2", "å†…å®¹è¦ç‚¹3"],
                                "slide_type": "content"
                            },
                            {
                                "page_number": 3,
                                "title": "è°¢è°¢è§‚çœ‹",
                                "content_points": ["æ„Ÿè°¢è†å¬", "æ¬¢è¿Žæé—®"],
                                "slide_type": "thankyou"
                            }
                        ]
                    }

                    # éªŒè¯å’Œä¿®å¤fallbackå¤§çº²
                    fallback_outline = await self._validate_and_repair_outline_json(fallback_outline, confirmed_requirements)

                    # Store fallback outline in project
                    project = await self.project_manager.get_project(project_id)
                    if project:
                        project.outline = fallback_outline
                        project.updated_at = time.time()
                        logger.info(f"Saved fallback outline for project {project_id}")

                    # Save to database
                    try:
                        from .db_project_manager import DatabaseProjectManager
                        db_manager = DatabaseProjectManager()
                        save_success = await db_manager.save_project_outline(project_id, fallback_outline)

                        if save_success:
                            logger.info(f"Successfully saved fallback outline to database for project {project_id}")
                        else:
                            logger.error(f"Failed to save fallback outline to database for project {project_id}")
                    except Exception as save_error:
                        logger.error(f"Exception while saving fallback outline to database: {save_error}")

                    final_page_count = len(fallback_outline.get('slides', []))
                    return f"âœ… PPTå¤§çº²ç”Ÿæˆå®Œæˆï¼ï¼ˆä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆï¼‰\n\næ ‡é¢˜ï¼š{fallback_outline.get('title', 'æœªçŸ¥')}\né¡µæ•°ï¼š{final_page_count}é¡µ\nå·²ä¿å­˜åˆ°æ•°æ®åº“"

                except Exception as fallback_error:
                    logger.error(f"Error creating fallback outline: {fallback_error}")
                    return f"âŒ å¤§çº²ç”Ÿæˆå¤±è´¥ï¼š{str(e)}\n\n{response.content}"

        except Exception as e:
            logger.error(f"Error in outline generation: {e}")
            raise

    async def _adjust_outline_page_count(self, outline_data: Dict[str, Any], min_pages: int, max_pages: int, confirmed_requirements: Dict[str, Any]) -> Dict[str, Any]:
        """Adjust outline page count to meet requirements"""
        try:
            current_slides = outline_data.get("slides", [])
            current_count = len(current_slides)

            if current_count < min_pages:
                # Need to add more slides
                logger.info(f"Adding slides to meet minimum requirement: {current_count} -> {min_pages}")
                outline_data = await self._expand_outline(outline_data, min_pages, confirmed_requirements)
            elif current_count > max_pages:
                # Need to reduce slides
                logger.info(f"Reducing slides to meet maximum requirement: {current_count} -> {max_pages}")
                outline_data = await self._condense_outline(outline_data, max_pages)

            return outline_data

        except Exception as e:
            logger.error(f"Error adjusting outline page count: {e}")
            return outline_data  # Return original if adjustment fails

    async def _expand_outline(self, outline_data: Dict[str, Any], target_pages: int, confirmed_requirements: Dict[str, Any]) -> Dict[str, Any]:
        """Expand outline to reach target page count"""
        try:
            slides = outline_data.get("slides", [])
            current_count = len(slides)
            needed_slides = target_pages - current_count

            # Generate additional slides based on content
            topic = confirmed_requirements.get('topic', outline_data.get('title', ''))
            focus_content = confirmed_requirements.get('focus_content', [])

            # Add content slides before the conclusion
            conclusion_slide = None
            if slides and slides[-1].get('slide_type') in ['thankyou', 'conclusion']:
                conclusion_slide = slides.pop()

            for i in range(needed_slides):
                page_number = len(slides) + 1
                if i < len(focus_content):
                    # Use focus content for new slides
                    new_slide = {
                        "page_number": page_number,
                        "title": focus_content[i],
                        "content_points": [f"{focus_content[i]}çš„è¯¦ç»†ä»‹ç»", "æ ¸å¿ƒè¦ç‚¹", "å®žé™…åº”ç”¨"],
                        "slide_type": "content",
                        "description": f"è¯¦ç»†ä»‹ç»{focus_content[i]}ç›¸å…³å†…å®¹"
                    }
                else:
                    # Generate generic content slides
                    new_slide = {
                        "page_number": page_number,
                        "title": f"{topic} - è¡¥å……å†…å®¹ {i+1}",
                        "content_points": ["è¡¥å……è¦ç‚¹1", "è¡¥å……è¦ç‚¹2", "è¡¥å……è¦ç‚¹3"],
                        "slide_type": "content",
                        "description": f"å…³äºŽ{topic}çš„è¡¥å……å†…å®¹"
                    }
                slides.append(new_slide)

            # Re-add conclusion slide if it existed
            if conclusion_slide:
                conclusion_slide["page_number"] = len(slides) + 1
                slides.append(conclusion_slide)

            # Update page numbers
            for i, slide in enumerate(slides):
                slide["page_number"] = i + 1

            outline_data["slides"] = slides
            return outline_data

        except Exception as e:
            logger.error(f"Error expanding outline: {e}")
            return outline_data

    async def _condense_outline(self, outline_data: Dict[str, Any], target_pages: int) -> Dict[str, Any]:
        """Condense outline to reach target page count"""
        try:
            slides = outline_data.get("slides", [])
            current_count = len(slides)

            if current_count <= target_pages:
                return outline_data

            # Keep title and conclusion slides, condense content slides
            title_slides = [s for s in slides if s.get('slide_type') in ['title', 'cover']]
            conclusion_slides = [s for s in slides if s.get('slide_type') in ['thankyou', 'conclusion']]
            content_slides = [s for s in slides if s.get('slide_type') not in ['title', 'cover', 'thankyou', 'conclusion']]

            # Calculate how many content slides we can keep
            reserved_slots = len(title_slides) + len(conclusion_slides)
            available_content_slots = target_pages - reserved_slots

            if available_content_slots > 0 and len(content_slides) > available_content_slots:
                # Keep the most important content slides
                content_slides = content_slides[:available_content_slots]

            # Rebuild slides list
            new_slides = title_slides + content_slides + conclusion_slides

            # Update page numbers
            for i, slide in enumerate(new_slides):
                slide["page_number"] = i + 1

            outline_data["slides"] = new_slides
            return outline_data

        except Exception as e:
            logger.error(f"Error condensing outline: {e}")
            return outline_data

    async def _force_page_count(self, outline_data: Dict[str, Any], target_pages: int, confirmed_requirements: Dict[str, Any]) -> Dict[str, Any]:
        """Force outline to exact page count"""
        try:
            slides = outline_data.get("slides", [])
            current_count = len(slides)

            logger.info(f"Forcing page count from {current_count} to {target_pages}")

            if current_count == target_pages:
                return outline_data

            # Keep title and conclusion slides
            title_slides = [s for s in slides if s.get('slide_type') in ['title', 'cover']]
            conclusion_slides = [s for s in slides if s.get('slide_type') in ['thankyou', 'conclusion']]
            content_slides = [s for s in slides if s.get('slide_type') not in ['title', 'cover', 'thankyou', 'conclusion']]

            # Calculate content slots needed
            reserved_slots = len(title_slides) + len(conclusion_slides)
            content_slots_needed = target_pages - reserved_slots

            if content_slots_needed <= 0:
                # Only keep title slide if no room for content
                new_slides = title_slides[:1] if title_slides else []
            else:
                if len(content_slides) > content_slots_needed:
                    # Reduce content slides
                    content_slides = content_slides[:content_slots_needed]
                elif len(content_slides) < content_slots_needed:
                    # Add more content slides
                    topic = confirmed_requirements.get('topic', outline_data.get('title', ''))
                    focus_content = confirmed_requirements.get('focus_content', [])

                    for i in range(content_slots_needed - len(content_slides)):
                        page_number = len(content_slides) + i + 1
                        if i < len(focus_content):
                            new_slide = {
                                "page_number": page_number,
                                "title": focus_content[i],
                                "content_points": [f"{focus_content[i]}çš„è¯¦ç»†ä»‹ç»", "æ ¸å¿ƒè¦ç‚¹", "å®žé™…åº”ç”¨"],
                                "slide_type": "content",
                                "description": f"è¯¦ç»†ä»‹ç»{focus_content[i]}ç›¸å…³å†…å®¹"
                            }
                        else:
                            new_slide = {
                                "page_number": page_number,
                                "title": f"{topic} - å†…å®¹ {i+1}",
                                "content_points": ["è¦ç‚¹1", "è¦ç‚¹2", "è¦ç‚¹3"],
                                "slide_type": "content",
                                "description": f"å…³äºŽ{topic}çš„å†…å®¹"
                            }
                        content_slides.append(new_slide)

                # Rebuild slides list
                new_slides = title_slides + content_slides + conclusion_slides

            # Update page numbers
            for i, slide in enumerate(new_slides):
                slide["page_number"] = i + 1

            outline_data["slides"] = new_slides
            logger.info(f"Successfully forced page count to {len(new_slides)} pages")
            return outline_data

        except Exception as e:
            logger.error(f"Error forcing page count: {e}")
            return outline_data

    async def _execute_ppt_creation(self, project_id: str, confirmed_requirements: Dict[str, Any], system_prompt: str) -> str:
        """Execute PPT creation by generating HTML pages individually with streaming"""
        try:
            project = await self.project_manager.get_project(project_id)
            if not project or not project.outline:
                return "âŒ é”™è¯¯ï¼šæœªæ‰¾åˆ°PPTå¤§çº²ï¼Œè¯·å…ˆå®Œæˆå¤§çº²ç”Ÿæˆæ­¥éª¤"

            outline = project.outline
            slides = outline.get('slides', [])

            if not slides:
                return "âŒ é”™è¯¯ï¼šå¤§çº²ä¸­æ²¡æœ‰å¹»ç¯ç‰‡ä¿¡æ¯"

            # éªŒè¯å¤§çº²é¡µæ•°ä¸Žéœ€æ±‚ä¸€è‡´æ€§
            if project.confirmed_requirements:
                page_count_settings = project.confirmed_requirements.get('page_count_settings', {})
                if page_count_settings.get('mode') == 'custom_range':
                    min_pages = page_count_settings.get('min_pages', 8)
                    max_pages = page_count_settings.get('max_pages', 15)
                    actual_pages = len(slides)

                    if actual_pages < min_pages or actual_pages > max_pages:
                        logger.warning(f"Outline has {actual_pages} pages, but requirements specify {min_pages}-{max_pages} pages")
                        return f"âš ï¸ é”™è¯¯ï¼šå¤§çº²æœ‰{actual_pages}é¡µï¼Œä½†éœ€æ±‚è¦æ±‚{min_pages}-{max_pages}é¡µã€‚è¯·é‡æ–°ç”Ÿæˆå¤§çº²ä»¥ç¬¦åˆé¡µæ•°è¦æ±‚ã€‚"

            # Initialize slides data - ç¡®ä¿ä¸Žå¤§çº²é¡µæ•°å®Œå…¨ä¸€è‡´
            project.slides_data = []
            project.updated_at = time.time()

            # ç¡®ä¿confirmed_requirementsåŒ…å«é¡¹ç›®IDï¼Œç”¨äºŽæ¨¡æ¿é€‰æ‹©
            if confirmed_requirements:
                confirmed_requirements['project_id'] = project_id

            # éªŒè¯slidesæ•°æ®ç»“æž„
            if not slides or len(slides) == 0:
                return "âŒ é”™è¯¯ï¼šå¤§çº²ä¸­æ²¡æœ‰æœ‰æ•ˆçš„å¹»ç¯ç‰‡æ•°æ®"

            logger.info(f"Starting PPT generation for {len(slides)} slides based on outline")

            # ç¡®ä¿æ¯ä¸ªslideéƒ½æœ‰å¿…è¦çš„å­—æ®µ
            for i, slide in enumerate(slides):
                if not slide.get('title'):
                    slide['title'] = f"å¹»ç¯ç‰‡ {i+1}"
                if not slide.get('page_number'):
                    slide['page_number'] = i + 1

            return f"ðŸš€ å¼€å§‹PPTåˆ¶ä½œ...\n\nå°†ä¸¥æ ¼æŒ‰ç…§å¤§çº²ä¸º {len(slides)} é¡µå¹»ç¯ç‰‡é€é¡µç”ŸæˆHTMLå†…å®¹\nå¤§çº²é¡µæ•°ï¼š{len(slides)}é¡µ\nè¯·åœ¨ç¼–è¾‘å™¨ä¸­æŸ¥çœ‹å®žæ—¶ç”Ÿæˆè¿‡ç¨‹"

        except Exception as e:
            logger.error(f"Error in PPT creation: {e}")
            raise

    async def generate_slides_streaming(self, project_id: str):
        """Generate slides with streaming output for real-time display"""
        try:
            import json
            import time

            project = await self.project_manager.get_project(project_id)
            if not project:
                error_data = {'error': 'é¡¹ç›®æœªæ‰¾åˆ°'}
                yield f"data: {json.dumps(error_data)}\n\n"
                return

            # æ£€æŸ¥å¹¶ç¡®ä¿å¤§çº²æ•°æ®æ­£ç¡®
            outline = None
            slides = []

            # é¦–å…ˆå°è¯•ä»Žé¡¹ç›®ä¸­èŽ·å–å¤§çº²
            if project.outline and isinstance(project.outline, dict):
                outline = project.outline
                slides = outline.get('slides', [])
                logger.info(f"Found outline in project with {len(slides)} slides")

            # å¦‚æžœæ²¡æœ‰slidesæˆ–slidesä¸ºç©ºï¼Œå°è¯•ä»Žæ•°æ®åº“é‡æ–°åŠ è½½
            if not slides:
                logger.info(f"No slides found in project outline, attempting to reload from database")
                logger.error(f"DEBUG: Full outline structure for project {project_id}:")
                logger.error(f"Outline type: {type(project.outline)}")
                if project.outline:
                    logger.error(f"Outline keys: {list(project.outline.keys()) if isinstance(project.outline, dict) else 'Not a dict'}")
                    if isinstance(project.outline, dict) and 'slides' in project.outline:
                        logger.error(f"Slides type: {type(project.outline['slides'])}, content: {project.outline['slides']}")

                try:
                    from .db_project_manager import DatabaseProjectManager
                    db_manager = DatabaseProjectManager()

                    # é‡æ–°ä»Žæ•°æ®åº“èŽ·å–é¡¹ç›®æ•°æ®
                    fresh_project = await db_manager.get_project(project_id)
                    if fresh_project and fresh_project.outline:
                        outline = fresh_project.outline
                        slides = outline.get('slides', [])
                        logger.info(f"Reloaded outline from database with {len(slides)} slides")

                        # æ›´æ–°å†…å­˜ä¸­çš„é¡¹ç›®æ•°æ®
                        project.outline = outline
                    else:
                        logger.error(f"Failed to reload project from database or outline is None")
                        if fresh_project:
                            logger.error(f"Fresh project outline type: {type(fresh_project.outline)}")

                except Exception as db_error:
                    logger.error(f"Failed to reload outline from database: {db_error}")
                    import traceback
                    logger.error(f"Database reload traceback: {traceback.format_exc()}")

            # å¦‚æžœä»ç„¶æ²¡æœ‰slidesï¼Œæ£€æŸ¥æ˜¯å¦æœ‰å¤§çº²å†…å®¹éœ€è¦è§£æž
            if not slides and outline and 'content' in outline:
                logger.info(f"Found outline content, attempting to parse slides")
                try:
                    # å°è¯•è§£æžå¤§çº²å†…å®¹
                    parsed_outline = self._parse_outline_content(outline['content'], project)
                    slides = parsed_outline.get('slides', [])
                    logger.info(f"Parsed {len(slides)} slides from outline content")

                    # æ›´æ–°å¤§çº²æ•°æ®
                    outline['slides'] = slides
                    project.outline = outline

                except Exception as parse_error:
                    logger.error(f"Failed to parse outline content: {parse_error}")

            # ç‰¹æ®Šå¤„ç†ï¼šå¦‚æžœoutlineç›´æŽ¥åŒ…å«slidesæ•°ç»„ä½†ä¸ºç©ºï¼Œå°è¯•ä»Žcontentå­—æ®µè§£æž
            if not slides and outline and isinstance(outline, dict):
                # æ£€æŸ¥æ˜¯å¦æœ‰contentå­—æ®µåŒ…å«JSONæ ¼å¼çš„å¤§çº²
                content_field = outline.get('content', '')
                if content_field and isinstance(content_field, str):
                    logger.info(f"Attempting to parse slides from content field")
                    try:
                        import json
                        # å°è¯•è§£æžcontentå­—æ®µä¸­çš„JSON
                        content_data = json.loads(content_field)
                        if isinstance(content_data, dict) and 'slides' in content_data:
                            slides = content_data['slides']
                            logger.info(f"Successfully parsed {len(slides)} slides from content JSON")

                            # æ›´æ–°outlineä¸­çš„slides
                            outline['slides'] = slides
                            project.outline = outline
                    except json.JSONDecodeError as json_error:
                        logger.error(f"Failed to parse content as JSON: {json_error}")
                    except Exception as content_error:
                        logger.error(f"Failed to extract slides from content: {content_error}")

            # æœ€åŽå°è¯•ï¼šå¦‚æžœoutlineæœ¬èº«å°±æ˜¯å®Œæ•´çš„å¤§çº²æ•°æ®ï¼ˆåŒ…å«titleå’Œslidesï¼‰
            if not slides and outline and isinstance(outline, dict):
                # æ£€æŸ¥outlineæ˜¯å¦ç›´æŽ¥åŒ…å«slidesæ•°ç»„
                direct_slides = outline.get('slides', [])
                if direct_slides and isinstance(direct_slides, list):
                    slides = direct_slides
                    logger.info(f"Found {len(slides)} slides directly in outline")
                # æˆ–è€…æ£€æŸ¥æ˜¯å¦æœ‰åµŒå¥—çš„å¤§çº²ç»“æž„
                elif 'outline' in outline and isinstance(outline['outline'], dict):
                    nested_slides = outline['outline'].get('slides', [])
                    if nested_slides and isinstance(nested_slides, list):
                        slides = nested_slides
                        logger.info(f"Found {len(slides)} slides in nested outline structure")

            # é¢å¤–è°ƒè¯•ï¼šæ‰“å°outlineç»“æž„ä»¥ä¾¿è¯Šæ–­
            if not slides:
                logger.error(f"DEBUG: Full outline structure for project {project_id}:")
                logger.error(f"Outline type: {type(outline)}")
                if outline:
                    logger.error(f"Outline keys: {list(outline.keys()) if isinstance(outline, dict) else 'Not a dict'}")
                    if isinstance(outline, dict):
                        for key, value in outline.items():
                            logger.error(f"  {key}: {type(value)} - {len(value) if isinstance(value, (list, dict, str)) else value}")
                            if key == 'slides' and isinstance(value, list):
                                logger.error(f"    Slides count: {len(value)}")
                                if value:
                                    logger.error(f"    First slide: {value[0] if len(value) > 0 else 'None'}")
                            elif key == 'content' and isinstance(value, str):
                                logger.error(f"    Content preview: {value[:200]}...")

                # å°è¯•ç›´æŽ¥ä»Žoutlineä¸­æå–slidesï¼Œä¸ç®¡ç»“æž„å¦‚ä½•
                if isinstance(outline, dict):
                    # é€’å½’æœç´¢slideså­—æ®µ
                    def find_slides_recursive(obj, path=""):
                        if isinstance(obj, dict):
                            for k, v in obj.items():
                                current_path = f"{path}.{k}" if path else k
                                if k == 'slides' and isinstance(v, list) and v:
                                    logger.info(f"Found slides at path: {current_path} with {len(v)} items")
                                    return v
                                elif isinstance(v, (dict, list)):
                                    result = find_slides_recursive(v, current_path)
                                    if result:
                                        return result
                        elif isinstance(obj, list):
                            for i, item in enumerate(obj):
                                current_path = f"{path}[{i}]" if path else f"[{i}]"
                                if isinstance(item, (dict, list)):
                                    result = find_slides_recursive(item, current_path)
                                    if result:
                                        return result
                        return None

                    found_slides = find_slides_recursive(outline)
                    if found_slides:
                        slides = found_slides
                        logger.info(f"Successfully found {len(slides)} slides through recursive search")

            # æœ€åŽçš„fallbackï¼šå¦‚æžœä»ç„¶æ²¡æœ‰slidesï¼Œè¿”å›žé”™è¯¯è€Œä¸æ˜¯ç”Ÿæˆé»˜è®¤å¤§çº²
            if not slides:
                error_message = "âŒ é”™è¯¯ï¼šæœªæ‰¾åˆ°PPTå¤§çº²æ•°æ®ï¼Œè¯·å…ˆå®Œæˆå¤§çº²ç”Ÿæˆæ­¥éª¤"
                logger.error(f"No slides found for project {project_id}")
                logger.error(f"Project outline structure: {type(project.outline)}")
                if project.outline:
                    logger.error(f"Outline keys: {list(project.outline.keys()) if isinstance(project.outline, dict) else 'Not a dict'}")
                    if isinstance(project.outline, dict) and 'slides' in project.outline:
                        logger.error(f"Slides type: {type(project.outline['slides'])}, length: {len(project.outline['slides']) if isinstance(project.outline['slides'], list) else 'Not a list'}")
                error_data = {'error': error_message}
                yield f"data: {json.dumps(error_data)}\n\n"
                return

            # å¦‚æžœæ²¡æœ‰ç¡®è®¤éœ€æ±‚ï¼Œä½¿ç”¨é»˜è®¤éœ€æ±‚é…ç½®
            if not project.confirmed_requirements:
                logger.info(f"Project {project_id} has no confirmed requirements, using default configuration")
                confirmed_requirements = {
                    "topic": project.topic,
                    "target_audience": "æ™®é€šå¤§ä¼—",
                    "focus_content": ["æ ¸å¿ƒæ¦‚å¿µ", "ä¸»è¦ç‰¹ç‚¹"],
                    "tech_highlights": ["æŠ€æœ¯è¦ç‚¹", "å®žè·µåº”ç”¨"],
                    "page_count_settings": {"mode": "ai_decide"},
                    "ppt_style": "general",
                    "description": f"åŸºäºŽä¸»é¢˜ '{project.topic}' çš„PPTæ¼”ç¤º"
                }
            else:
                confirmed_requirements = project.confirmed_requirements

            # ç¡®ä¿æˆ‘ä»¬æœ‰æœ‰æ•ˆçš„å¤§çº²å’Œslidesæ•°æ®
            if not outline:
                outline = project.outline

            if not slides:
                slides = outline.get('slides', []) if outline else []

            # æœ€ç»ˆæ£€æŸ¥ï¼šå¦‚æžœä»ç„¶æ²¡æœ‰slidesï¼Œè¿”å›žé”™è¯¯
            if not slides:
                error_message = "âŒ é”™è¯¯ï¼šå¤§çº²ä¸­æ²¡æœ‰å¹»ç¯ç‰‡ä¿¡æ¯ï¼Œè¯·æ£€æŸ¥å¤§çº²ç”Ÿæˆæ˜¯å¦å®Œæˆ"
                logger.error(f"No slides found after all attempts for project {project_id}")
                error_data = {'error': error_message}
                yield f"data: {json.dumps(error_data)}\n\n"
                return

            logger.info(f"Starting PPT generation for project {project_id} with {len(slides)} slides")

            # Load system prompt
            system_prompt = self._load_prompts_md_system_prompt()

            # Initialize slides data if not exists
            if not project.slides_data:
                project.slides_data = []

            # Generate each slide individually
            for i, slide in enumerate(slides):
                try:
                    # Check if slide already exists
                    existing_slide = None
                    if project.slides_data and i < len(project.slides_data):
                        existing_slide = project.slides_data[i]

                    # If slide exists and has content (either user-edited or AI-generated), skip generation
                    if existing_slide and existing_slide.get('html_content'):
                        if existing_slide.get('is_user_edited', False):
                            logger.info(f"Skipping slide {i+1} generation - user has edited this slide")
                            skip_message = f'ç¬¬{i+1}é¡µå·²è¢«ç”¨æˆ·ç¼–è¾‘ï¼Œè·³è¿‡é‡æ–°ç”Ÿæˆ'
                        else:
                            logger.info(f"Skipping slide {i+1} generation - slide already exists")
                            skip_message = f'ç¬¬{i+1}é¡µå·²å­˜åœ¨ï¼Œè·³è¿‡ç”Ÿæˆ'

                        # Send skip message
                        skip_data = {
                            'type': 'slide_skipped',
                            'current': i + 1,
                            'total': len(slides),
                            'message': skip_message,
                            'slide_data': existing_slide
                        }
                        yield f"data: {json.dumps(skip_data)}\n\n"
                        continue

                    # Send progress update
                    slide_title = slide.get('title', '')
                    progress_data = {
                        'type': 'progress',
                        'current': i + 1,
                        'total': len(slides),
                        'message': f'æ­£åœ¨ç”Ÿæˆç¬¬{i+1}é¡µï¼š{slide_title}...'
                    }
                    yield f"data: {json.dumps(progress_data)}\n\n"
                    logger.info(f"Generating slide {i+1}/{len(slides)}: {slide_title}")

                    # Generate HTML for this slide with context
                    html_content = await self._generate_single_slide_html_with_prompts(
                        slide, confirmed_requirements, system_prompt, i + 1, len(slides), slides, project.slides_data, project_id
                    )
                    logger.debug(f"Successfully generated slide {i+1}/{len(slides)}: {html_content}")

                    # Create slide data
                    slide_data = {
                        "page_number": i + 1,
                        "title": slide.get('title', f'ç¬¬{i+1}é¡µ'),
                        "html_content": html_content,
                        "is_user_edited": False  # Mark as AI-generated
                    }

                    # Update project slides data
                    while len(project.slides_data) <= i:
                        project.slides_data.append(None)
                    project.slides_data[i] = slide_data

                    # ç«‹å³ä¿å­˜å½“å‰é¡µé¢åˆ°æ•°æ®åº“ï¼Œç¡®ä¿å®žæ—¶åŒæ­¥å’Œç‹¬ç«‹çš„åˆ›å»ºæ—¶é—´
                    try:
                        from .db_project_manager import DatabaseProjectManager
                        db_manager = DatabaseProjectManager()

                        # æ›´æ–°é¡¹ç›®çš„slides_dataå’Œupdated_at
                        project.updated_at = time.time()

                        # ä¿å­˜å•ä¸ªslideåˆ°æ•°æ®åº“ï¼Œä¿æŒç‹¬ç«‹çš„åˆ›å»ºæ—¶é—´
                        await db_manager.save_single_slide(project_id, i, slide_data)
                        logger.info(f"Successfully saved slide {i+1} to database for project {project_id}")
                    except Exception as save_error:
                        logger.error(f"Failed to save slide {i+1} to database: {save_error}")
                        # ç»§ç»­ç”Ÿæˆï¼Œä¸å› ä¿å­˜å¤±è´¥è€Œä¸­æ–­

                    # Send slide data
                    slide_response = {'type': 'slide', 'slide_data': slide_data}
                    yield f"data: {json.dumps(slide_response)}\n\n"

                except Exception as e:
                    logger.error(f"Error generating slide {i+1}: {e}")
                    # Send error for this slide
                    error_slide = {
                        "page_number": i + 1,
                        "title": slide.get('title', f'ç¬¬{i+1}é¡µ'),
                        "html_content": f"<div style='padding: 50px; text-align: center; color: red;'>ç”Ÿæˆå¤±è´¥ï¼š{str(e)}</div>"
                    }

                    while len(project.slides_data) <= i:
                        project.slides_data.append(None)
                    project.slides_data[i] = error_slide

                    error_response = {'type': 'slide', 'slide_data': error_slide}
                    yield f"data: {json.dumps(error_response)}\n\n"

            # Generate combined HTML
            project.slides_html = self._combine_slides_to_full_html(
                project.slides_data, outline.get('title', project.title)
            )
            project.status = "completed"
            project.updated_at = time.time()

            # Update project status and stage completion (slides already saved individually)
            try:
                from .db_project_manager import DatabaseProjectManager
                db_manager = DatabaseProjectManager()

                # Update project with final slides_html and slides_data (without recreating individual slides)
                await db_manager.update_project_data(project_id, {
                    "slides_html": project.slides_html,
                    "slides_data": project.slides_data,
                    "status": "completed",
                    "updated_at": time.time()
                })
                logger.info(f"Successfully updated project data for project {project_id}")

                # Update PPT creation stage status to completed
                await db_manager.update_stage_status(
                    project_id,
                    "ppt_creation",
                    "completed",
                    100.0,
                    {"slides_count": len(slides), "completed_at": time.time()}
                )
                logger.info(f"Successfully updated PPT creation stage to completed for project {project_id}")

            except Exception as save_error:
                logger.error(f"Failed to update project status in database: {save_error}")
                # Continue anyway, as the data is still in memory

            # Send completion message
            complete_message = f'âœ… PPTåˆ¶ä½œå®Œæˆï¼æˆåŠŸç”Ÿæˆ {len(slides)} é¡µå¹»ç¯ç‰‡'
            complete_response = {'type': 'complete', 'message': complete_message}
            yield f"data: {json.dumps(complete_response)}\n\n"

        except Exception as e:
            logger.error(f"Error in streaming PPT generation: {e}")
            error_message = f'ç”Ÿæˆè¿‡ç¨‹ä¸­å‡ºçŽ°é”™è¯¯ï¼š{str(e)}'
            error_response = {'type': 'error', 'message': error_message}
            yield f"data: {json.dumps(error_response)}\n\n"

    async def _execute_general_subtask(self, project_id: str, stage, subtask: str, confirmed_requirements: Dict[str, Any], system_prompt: str) -> str:
        """Execute general subtask"""
        # ä½¿ç”¨æ–°çš„æç¤ºè¯æ¨¡å—
        context = prompts_manager.get_general_subtask_prompt(
            confirmed_requirements=confirmed_requirements,
            stage_name=stage.name,
            subtask=subtask
        )

        response = await self.ai_provider.text_completion(
            prompt=context,
            system_prompt=system_prompt,
            max_tokens=ai_config.max_tokens,
            temperature=ai_config.temperature
        )

        return response.content

    async def _generate_single_slide_html_with_prompts(self, slide_data: Dict[str, Any], confirmed_requirements: Dict[str, Any],
                                                     system_prompt: str, page_number: int, total_pages: int,
                                                     all_slides: List[Dict[str, Any]] = None, existing_slides_data: List[Dict[str, Any]] = None, project_id: str = None) -> str:
        """Generate HTML for a single slide using prompts.md and first step information with template selection"""
        try:
            # ä½¿ç”¨ä¼ å…¥çš„é¡¹ç›®IDæˆ–ä»Žconfirmed_requirementsèŽ·å–
            if not project_id:
                project_id = confirmed_requirements.get('project_id')

            selected_template = None

            # å¦‚æžœæœ‰é¡¹ç›®IDï¼Œå°è¯•èŽ·å–é€‰æ‹©çš„å…¨å±€æ¯ç‰ˆæ¨¡æ¿
            if project_id:
                try:
                    selected_template = await self.get_selected_global_template(project_id)
                    if selected_template:
                        logger.info(f"ä¸ºç¬¬{page_number}é¡µä½¿ç”¨å…¨å±€æ¯ç‰ˆ: {selected_template['template_name']}")
                except Exception as e:
                    logger.warning(f"èŽ·å–å…¨å±€æ¯ç‰ˆå¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤ç”Ÿæˆæ–¹å¼: {e}")

            # å¦‚æžœæœ‰é€‰ä¸­çš„å…¨å±€æ¯ç‰ˆï¼Œä½¿ç”¨æ¨¡æ¿ç”Ÿæˆ
            if selected_template:
                return await self._generate_slide_with_template(
                    slide_data, selected_template, page_number, total_pages, confirmed_requirements
                )



            
            template_html = selected_template.get('html_template', '') if selected_template else ""  # èŽ·å–æ¨¡æ¿HTMLä½œä¸ºé£Žæ ¼å‚è€ƒ

            # å¦åˆ™ä½¿ç”¨åŽŸæœ‰çš„ç”Ÿæˆæ–¹å¼ï¼Œä½†åº”ç”¨æ–°çš„è®¾è®¡åŸºå› ç¼“å­˜å’Œç»Ÿä¸€åˆ›æ„æŒ‡å¯¼
            # èŽ·å–æˆ–æå–è®¾è®¡åŸºå› ï¼ˆåªåœ¨ç¬¬ä¸€é¡µæå–ä¸€æ¬¡ï¼‰
            style_genes = await self._get_or_extract_style_genes(project_id, template_html, page_number)

            # æ£€æŸ¥æ˜¯å¦å¯ç”¨å›¾ç‰‡ç”ŸæˆæœåŠ¡å¹¶å¤„ç†å¤šå›¾ç‰‡
            images_collection = await self._process_slide_image(slide_data, confirmed_requirements, page_number, total_pages, template_html)
            if images_collection and images_collection.total_count > 0:
                # å°†å›¾ç‰‡é›†åˆä¿¡æ¯æ·»åŠ åˆ°slide_dataä¸­ï¼Œä¾›åŽç»­ç”Ÿæˆä½¿ç”¨
                slide_data['images_collection'] = images_collection
                slide_data['images_info'] = images_collection.to_dict()
                slide_data['images_summary'] = images_collection.get_summary_for_ai()
                logger.info(f"ä¸ºç¬¬{page_number}é¡µæ·»åŠ {images_collection.total_count}å¼ å›¾ç‰‡: "
                          f"æœ¬åœ°{images_collection.local_count}å¼ , "
                          f"ç½‘ç»œ{images_collection.network_count}å¼ , "
                          f"AIç”Ÿæˆ{images_collection.ai_generated_count}å¼ ")

            # ç”Ÿæˆç»Ÿä¸€çš„åˆ›æ„è®¾è®¡æŒ‡å¯¼
            unified_design_guide = await self._generate_unified_design_guide(slide_data, page_number, total_pages)

            # Build context information for better coherence
            context_info = self._build_slide_context(page_number, total_pages)

            # ä½¿ç”¨æ–°çš„æç¤ºè¯æ¨¡å—ç”Ÿæˆä¸Šä¸‹æ–‡
            context = prompts_manager.get_single_slide_html_prompt(
                slide_data, confirmed_requirements, page_number, total_pages,
                context_info, style_genes, unified_design_guide, template_html
            )

            # Try to generate HTML with retry mechanism for incomplete responses
            html_content = await self._generate_html_with_retry(
                context, system_prompt, slide_data, page_number, total_pages, max_retries=5
            )

            return html_content

        except Exception as e:
            logger.error(f"Error generating single slide HTML with prompts: {e}")
            # Return a fallback HTML
            return self._generate_fallback_slide_html(slide_data, page_number, total_pages)

    async def _process_slide_image(self, slide_data: Dict[str, Any], confirmed_requirements: Dict[str, Any],
                                 page_number: int, total_pages: int, template_html: str = ""):
        """ä½¿ç”¨å›¾ç‰‡å¤„ç†å™¨å¤„ç†å¹»ç¯ç‰‡å¤šå›¾ç‰‡"""
        try:
            # åˆå§‹åŒ–å›¾ç‰‡å¤„ç†å™¨
            from .ppt_image_processor import PPTImageProcessor
            from .models.slide_image_info import SlideImagesCollection

            image_processor = PPTImageProcessor(
                image_service=self.image_service,
                ai_provider=self.ai_provider
            )

            # å¤„ç†å›¾ç‰‡ï¼Œè¿”å›žå›¾ç‰‡é›†åˆ
            return await image_processor.process_slide_image(
                slide_data, confirmed_requirements, page_number, total_pages, template_html
            )

        except Exception as e:
            logger.error(f"å›¾ç‰‡å¤„ç†å™¨å¤„ç†å¤±è´¥: {e}")
            return None



    async def _generate_slide_with_template(self, slide_data: Dict[str, Any], template: Dict[str, Any],
                                          page_number: int, total_pages: int,
                                          confirmed_requirements: Dict[str, Any]) -> str:
        """ä½¿ç”¨é€‰å®šçš„æ¨¡æ¿ç”Ÿæˆå¹»ç¯ç‰‡HTML - AIå‚è€ƒæ¨¡æ¿é£Žæ ¼ç”Ÿæˆæ–°HTML"""
        try:
            # èŽ·å–æ¨¡æ¿HTMLä½œä¸ºé£Žæ ¼å‚è€ƒ
            template_html = template['html_template']
            template_name = template.get('template_name', 'æœªçŸ¥æ¨¡æ¿')

            logger.info(f"ä½¿ç”¨æ¨¡æ¿ {template_name} ä½œä¸ºé£Žæ ¼å‚è€ƒç”Ÿæˆç¬¬{page_number}é¡µ")

            # æž„å»ºåˆ›æ„æ¨¡æ¿å‚è€ƒä¸Šä¸‹æ–‡
            context = await self._build_creative_template_context(
                slide_data, template_html, template_name, page_number, total_pages, confirmed_requirements
            )

            # ä½¿ç”¨AIç”Ÿæˆé£Žæ ¼ä¸€è‡´ä½†å†…å®¹åˆ›æ–°çš„HTML
            system_prompt = self._load_prompts_md_system_prompt()
            html_content = await self._generate_html_with_retry(
                context, system_prompt, slide_data, page_number, total_pages, max_retries=5
            )

            if html_content:
                logger.info(f"æˆåŠŸä½¿ç”¨æ¨¡æ¿ {template_name} é£Žæ ¼ç”Ÿæˆç¬¬{page_number}é¡µ")
                return html_content
            else:
                logger.warning(f"æ¨¡æ¿é£Žæ ¼ç”Ÿæˆå¤±è´¥ï¼Œå›žé€€åˆ°é»˜è®¤ç”Ÿæˆæ–¹å¼")
                # å›žé€€åˆ°åŽŸæœ‰ç”Ÿæˆæ–¹å¼
                return await self._generate_fallback_slide_html(slide_data, page_number, total_pages)

        except Exception as e:
            logger.error(f"ä½¿ç”¨æ¨¡æ¿é£Žæ ¼ç”Ÿæˆå¹»ç¯ç‰‡å¤±è´¥: {e}")
            # å›žé€€åˆ°åŽŸæœ‰ç”Ÿæˆæ–¹å¼
            return await self._generate_fallback_slide_html(slide_data, page_number, total_pages)


    async def _build_creative_template_context(self, slide_data: Dict[str, Any], template_html: str,
                                       template_name: str, page_number: int, total_pages: int,
                                       confirmed_requirements: Dict[str, Any]) -> str:
        """æž„å»ºåˆ›æ„æ¨¡æ¿å‚è€ƒä¸Šä¸‹æ–‡ï¼Œå¹³è¡¡é£Žæ ¼ä¸€è‡´æ€§ä¸Žåˆ›æ„å¤šæ ·æ€§ï¼ˆä¼˜åŒ–ç‰ˆæœ¬ï¼‰"""

        # èŽ·å–é¡¹ç›®IDï¼Œæ£€æŸ¥æ˜¯å¦å·²ç¼“å­˜è®¾è®¡åŸºå› 
        project_id = confirmed_requirements.get('project_id')
        style_genes = None

        # è®¾è®¡åŸºå› åªåœ¨ç¬¬ä¸€é¡µæå–ä¸€æ¬¡ï¼ŒåŽç»­éƒ½ä½¿ç”¨ç¬¬ä¸€é¡µçš„
        style_genes = await self._get_or_extract_style_genes(project_id, template_html, page_number)

        # æ£€æŸ¥æ˜¯å¦å¯ç”¨å›¾ç‰‡ç”ŸæˆæœåŠ¡å¹¶å¤„ç†å¤šå›¾ç‰‡
        images_collection = await self._process_slide_image(slide_data, confirmed_requirements, page_number, total_pages, template_html)
        if images_collection and images_collection.total_count > 0:
            # å°†å›¾ç‰‡é›†åˆä¿¡æ¯æ·»åŠ åˆ°slide_dataä¸­ï¼Œä¾›åŽç»­ç”Ÿæˆä½¿ç”¨
            slide_data['images_collection'] = images_collection
            slide_data['images_info'] = images_collection.to_dict()
            slide_data['images_summary'] = images_collection.get_summary_for_ai()
            logger.info(f"ä¸ºæ¨¡æ¿ç”Ÿæˆçš„ç¬¬{page_number}é¡µæ·»åŠ {images_collection.total_count}å¼ å›¾ç‰‡")

        # ç”Ÿæˆç»Ÿä¸€çš„åˆ›æ„è®¾è®¡æŒ‡å¯¼ï¼ˆåˆå¹¶åˆ›æ„å˜åŒ–æŒ‡å¯¼å’Œå†…å®¹é©±åŠ¨çš„è®¾è®¡å»ºè®®ï¼‰
        unified_design_guide = await self._generate_unified_design_guide(slide_data, page_number, total_pages)

        # èŽ·å–å®žé™…å†…å®¹è¦ç‚¹
        slide_title = slide_data.get('title', f'ç¬¬{page_number}é¡µ')
        slide_type = slide_data.get('slide_type', 'content')

        # Build context information for better coherence
        context_info = self._build_slide_context(page_number, total_pages)

        # èŽ·å–é¡¹ç›®ä¿¡æ¯
        project_topic = confirmed_requirements.get('topic', '')
        project_type = confirmed_requirements.get('type', '')
        project_audience = confirmed_requirements.get('target_audience', '')
        project_style = confirmed_requirements.get('ppt_style', 'general')
        # ä½¿ç”¨æ–°çš„æç¤ºè¯æ¨¡å—
        context = prompts_manager.get_creative_template_context_prompt(
            slide_data=slide_data,
            template_html=template_html,
            slide_title=slide_title,
            slide_type=slide_type,
            page_number=page_number,
            total_pages=total_pages,
            context_info=context_info,
            style_genes=style_genes,
            unified_design_guide=unified_design_guide,
            project_topic=project_topic,
            project_type=project_type,
            project_audience=project_audience,
            project_style=project_style
        )

        return context

    async def _extract_style_genes(self, template_html: str) -> str:
        """ä½¿ç”¨AIä»Žæ¨¡æ¿ä¸­æå–æ ¸å¿ƒè®¾è®¡åŸºå› """
        try:
            # ä½¿ç”¨æ–°çš„æç¤ºè¯æ¨¡å—
            prompt = prompts_manager.get_style_genes_extraction_prompt(template_html)

            # è°ƒç”¨AIåˆ†æž
            response = await self.ai_provider.text_completion(
                prompt=prompt,
                max_tokens=ai_config.max_tokens,
                temperature=0.3
            )

            ai_genes = response.content.strip()

            # å¦‚æžœAIåˆ†æžå¤±è´¥ï¼Œå›žé€€åˆ°åŸºç¡€æå–
            if not ai_genes or len(ai_genes) < 50:
                return self._extract_fallback_style_genes(template_html)

            return ai_genes

        except Exception as e:
            logger.warning(f"AIæå–è®¾è®¡åŸºå› å¤±è´¥: {e}")
            # å›žé€€åˆ°åŸºç¡€æå–
            return self._extract_fallback_style_genes(template_html)

    def _extract_fallback_style_genes(self, template_html: str) -> str:
        """å›žé€€çš„åŸºç¡€è®¾è®¡åŸºå› æå–"""
        import re

        genes = []

        try:
            # æå–ä¸»è¦é¢œè‰²æ–¹æ¡ˆ
            colors = re.findall(r'(?:background|color)[^:]*:\s*([^;]+)', template_html, re.IGNORECASE)
            if colors:
                unique_colors = list(set(colors))[:3]
                genes.append(f"- æ ¸å¿ƒè‰²å½©ï¼š{', '.join(unique_colors)}")

            # æå–å­—ä½“ç³»ç»Ÿ
            fonts = re.findall(r'font-family[^:]*:\s*([^;]+)', template_html, re.IGNORECASE)
            if fonts:
                genes.append(f"- å­—ä½“ç³»ç»Ÿï¼š{fonts[0]}")

            # æå–å¸ƒå±€ç‰¹å¾
            if 'display: flex' in template_html:
                genes.append("- å¸ƒå±€æ–¹å¼ï¼šFlexboxå¼¹æ€§å¸ƒå±€")
            elif 'display: grid' in template_html:
                genes.append("- å¸ƒå±€æ–¹å¼ï¼šGridç½‘æ ¼å¸ƒå±€")

            # æå–è®¾è®¡å…ƒç´ 
            design_elements = []
            if 'border-radius' in template_html:
                design_elements.append("åœ†è§’è®¾è®¡")
            if 'box-shadow' in template_html:
                design_elements.append("é˜´å½±æ•ˆæžœ")
            if 'gradient' in template_html:
                design_elements.append("æ¸å˜èƒŒæ™¯")

            if design_elements:
                genes.append(f"- è®¾è®¡å…ƒç´ ï¼š{', '.join(design_elements)}")

            # æå–é—´è·æ¨¡å¼
            paddings = re.findall(r'padding[^:]*:\s*([^;]+)', template_html, re.IGNORECASE)
            if paddings:
                genes.append(f"- é—´è·æ¨¡å¼ï¼š{paddings[0]}")

        except Exception as e:
            logger.warning(f"åŸºç¡€æå–è®¾è®¡åŸºå› æ—¶å‡ºé”™: {e}")
            genes.append("- ä½¿ç”¨çŽ°ä»£ç®€æ´çš„è®¾è®¡é£Žæ ¼")

        return "\n".join(genes) if genes else "- ä½¿ç”¨çŽ°ä»£ç®€æ´çš„è®¾è®¡é£Žæ ¼"

    async def _get_or_extract_style_genes(self, project_id: str, template_html: str, page_number: int) -> str:
        """èŽ·å–æˆ–æå–è®¾è®¡åŸºå› ï¼Œåªåœ¨ç¬¬ä¸€é¡µæå–ä¸€æ¬¡ï¼ŒåŽç»­å¤ç”¨"""
        import json
        import hashlib
        from pathlib import Path

        # å¦‚æžœæ²¡æœ‰é¡¹ç›®IDï¼Œç›´æŽ¥æå–
        if not project_id:
            if page_number == 1:
                return await self._extract_style_genes(template_html)
            else:
                return "- ä½¿ç”¨çŽ°ä»£ç®€æ´çš„è®¾è®¡é£Žæ ¼\n- ä¿æŒé¡µé¢æ•´ä½“ä¸€è‡´æ€§\n- é‡‡ç”¨æ¸…æ™°çš„è§†è§‰å±‚æ¬¡"

        # æ£€æŸ¥å†…å­˜ç¼“å­˜
        if hasattr(self, '_cached_style_genes') and project_id in self._cached_style_genes:
            logger.info(f"ä»Žå†…å­˜ç¼“å­˜èŽ·å–é¡¹ç›® {project_id} çš„è®¾è®¡åŸºå› ")
            return self._cached_style_genes[project_id]

        # æ£€æŸ¥æ–‡ä»¶ç¼“å­˜ï¼ˆå¦‚æžœæœ‰ç¼“å­˜ç›®å½•é…ç½®ï¼‰
        style_genes = None
        if hasattr(self, 'cache_dirs') and self.cache_dirs:
            cache_file = self.cache_dirs['style_genes'] / f"{project_id}_style_genes.json"
            if cache_file.exists():
                try:
                    with open(cache_file, 'r', encoding='utf-8') as f:
                        cache_data = json.load(f)
                        style_genes = cache_data.get('style_genes')
                        logger.info(f"ä»Žæ–‡ä»¶ç¼“å­˜èŽ·å–é¡¹ç›® {project_id} çš„è®¾è®¡åŸºå› ")
                except Exception as e:
                    logger.warning(f"è¯»å–è®¾è®¡åŸºå› ç¼“å­˜æ–‡ä»¶å¤±è´¥: {e}")

        # å¦‚æžœæ²¡æœ‰ç¼“å­˜ä¸”æ˜¯ç¬¬ä¸€é¡µï¼Œæå–è®¾è®¡åŸºå› 
        if not style_genes and page_number == 1:
            style_genes = await self._extract_style_genes(template_html)

            # ç¼“å­˜åˆ°å†…å­˜
            if not hasattr(self, '_cached_style_genes'):
                self._cached_style_genes = {}
            self._cached_style_genes[project_id] = style_genes

            # ç¼“å­˜åˆ°æ–‡ä»¶ï¼ˆå¦‚æžœæœ‰ç¼“å­˜ç›®å½•é…ç½®ï¼‰
            if hasattr(self, 'cache_dirs') and self.cache_dirs:
                try:
                    cache_file = self.cache_dirs['style_genes'] / f"{project_id}_style_genes.json"
                    cache_data = {
                        'project_id': project_id,
                        'style_genes': style_genes,
                        'created_at': time.time(),
                        'template_hash': hashlib.md5(template_html.encode()).hexdigest()[:8]
                    }
                    with open(cache_file, 'w', encoding='utf-8') as f:
                        json.dump(cache_data, f, ensure_ascii=False, indent=2)
                    logger.info(f"ç¬¬ä¸€é¡µæå–å¹¶ç¼“å­˜é¡¹ç›® {project_id} çš„è®¾è®¡åŸºå› åˆ°æ–‡ä»¶")
                except Exception as e:
                    logger.warning(f"ä¿å­˜è®¾è®¡åŸºå› ç¼“å­˜æ–‡ä»¶å¤±è´¥: {e}")

            logger.info(f"ç¬¬ä¸€é¡µæå–å¹¶ç¼“å­˜é¡¹ç›® {project_id} çš„è®¾è®¡åŸºå› ")

        elif not style_genes and page_number > 1:
            # å¦‚æžœä¸æ˜¯ç¬¬ä¸€é¡µä¸”æ²¡æœ‰ç¼“å­˜çš„è®¾è®¡åŸºå› ï¼Œä½¿ç”¨é»˜è®¤è®¾è®¡åŸºå› 
            style_genes = "- ä½¿ç”¨çŽ°ä»£ç®€æ´çš„è®¾è®¡é£Žæ ¼\n- ä¿æŒé¡µé¢æ•´ä½“ä¸€è‡´æ€§\n- é‡‡ç”¨æ¸…æ™°çš„è§†è§‰å±‚æ¬¡"
            logger.warning(f"ç¬¬{page_number}é¡µæœªæ‰¾åˆ°ç¼“å­˜çš„è®¾è®¡åŸºå› ï¼Œä½¿ç”¨é»˜è®¤è®¾è®¡åŸºå› ï¼ˆè®¾è®¡åŸºå› åº”åœ¨ç¬¬ä¸€é¡µæå–ï¼‰")

        return style_genes or "- ä½¿ç”¨çŽ°ä»£ç®€æ´çš„è®¾è®¡é£Žæ ¼\n- ä¿æŒé¡µé¢æ•´ä½“ä¸€è‡´æ€§\n- é‡‡ç”¨æ¸…æ™°çš„è§†è§‰å±‚æ¬¡"

    async def _generate_unified_design_guide(self, slide_data: Dict[str, Any], page_number: int, total_pages: int) -> str:
        """ç”Ÿæˆç»Ÿä¸€çš„åˆ›æ„è®¾è®¡æŒ‡å¯¼ï¼ˆåˆå¹¶åˆ›æ„å˜åŒ–æŒ‡å¯¼å’Œå†…å®¹é©±åŠ¨çš„è®¾è®¡å»ºè®®ï¼‰"""
        try:
            # ä½¿ç”¨æ–°çš„æç¤ºè¯æ¨¡å—
            prompt = prompts_manager.get_unified_design_guide_prompt(slide_data, page_number, total_pages)

            # è°ƒç”¨AIç”ŸæˆæŒ‡å¯¼
            response = await self.ai_provider.text_completion(
                prompt=prompt,
                max_tokens=ai_config.max_tokens,
                temperature=0.7  # é€‚ä¸­æ¸©åº¦å¹³è¡¡åˆ›æ„æ€§å’Œå®žç”¨æ€§
            )

            ai_guide = response.content.strip()

            # å¦‚æžœAIç”Ÿæˆå¤±è´¥ï¼Œå›žé€€åˆ°åŸºç¡€æŒ‡å¯¼
            if not ai_guide or len(ai_guide) < 50:
                return self._generate_fallback_unified_guide(slide_data, page_number, total_pages)

            return ai_guide

        except Exception as e:
            logger.warning(f"AIç”Ÿæˆç»Ÿä¸€è®¾è®¡æŒ‡å¯¼å¤±è´¥: {e}")
            # å›žé€€åˆ°åŸºç¡€æŒ‡å¯¼
            return self._generate_fallback_unified_guide(slide_data, page_number, total_pages)

    def _generate_fallback_unified_guide(self, slide_data: Dict[str, Any], page_number: int, total_pages: int) -> str:
        """ç”Ÿæˆå›žé€€çš„ç»Ÿä¸€è®¾è®¡æŒ‡å¯¼"""
        slide_type = slide_data.get('slide_type', 'content')
        content_points = slide_data.get('content_points', [])
        title = slide_data.get('title', '')

        guides = []

        # A. é¡µé¢å®šä½ä¸Žåˆ›æ„ç­–ç•¥
        guides.append("**A. é¡µé¢å®šä½ä¸Žåˆ›æ„ç­–ç•¥**")
        if page_number == 1:
            guides.extend([
                "- å¼€åœºé¡µé¢ï¼šå¯ä»¥ä½¿ç”¨å¤§èƒ†çš„è§†è§‰å†²å‡»åŠ›ï¼Œè®¾ç½®æ¼”ç¤ºåŸºè°ƒ",
                "- æ ‡é¢˜æŽ’ç‰ˆï¼šå°è¯•éžå¯¹ç§°å¸ƒå±€ã€åˆ›æ„å­—ä½“å±‚æ¬¡ã€åŠ¨æ€è§†è§‰å…ƒç´ ",
                "- èƒŒæ™¯è‰²ä¿æŒç»Ÿä¸€ï¼šå¯ä»¥å¾®å°è°ƒæ•´èƒŒæ™¯å›¾æ¡ˆæˆ–æ¸å˜æ–¹å‘"
            ])
        elif page_number == total_pages:
            guides.extend([
                "- ç»“å°¾é¡µé¢ï¼šè®¾è®¡æ€»ç»“æ€§è§†è§‰æ¡†æž¶ï¼Œå‘¼åº”å¼€å¤´å…ƒç´ ",
                "- è¡ŒåŠ¨å·å¬ï¼šä½¿ç”¨çªå‡ºçš„è§†è§‰å¼•å¯¼ï¼Œå¦‚æŒ‰é’®ã€ç®­å¤´ç­‰",
                "- è”ç³»ä¿¡æ¯ï¼šåˆ›æ–°çš„ä¿¡æ¯å±•ç¤ºæ–¹å¼"
            ])
        else:
            guides.extend([
                "- å†…å®¹é¡µé¢ï¼šæ ¹æ®ä¿¡æ¯å¯†åº¦è°ƒæ•´å¸ƒå±€å¤æ‚åº¦",
                "- æ¸è¿›å˜åŒ–ï¼šåœ¨ä¿æŒä¸€è‡´æ€§åŸºç¡€ä¸Šé€‚åº¦æ¼”è¿›è§†è§‰é£Žæ ¼",
                "- é‡ç‚¹çªå‡ºï¼šä½¿ç”¨è§†è§‰å±‚æ¬¡å¼ºè°ƒå…³é”®ä¿¡æ¯"
            ])

        # B. å†…å®¹é©±åŠ¨çš„è®¾è®¡å»ºè®®
        guides.append("\n**B. å†…å®¹é©±åŠ¨çš„è®¾è®¡å»ºè®®**")
        if slide_type == 'title':
            guides.extend([
                "- è§†è§‰ç»„ä»¶ï¼šä½¿ç”¨å¤§åž‹æ ‡é¢˜å¡ç‰‡ã€å“ç‰Œæ ‡è¯†ã€è£…é¥°æ€§å›¾å½¢å…ƒç´ ",
                "- å¸ƒå±€å»ºè®®ï¼šé‡‡ç”¨å±…ä¸­å¯¹ç§°å¸ƒå±€ï¼Œçªå‡ºä¸»æ ‡é¢˜çš„é‡è¦æ€§"
            ])
        elif slide_type == 'content':
            if len(content_points) > 5:
                guides.extend([
                    "- è§†è§‰ç»„ä»¶ï¼šè€ƒè™‘åˆ†æ å¸ƒå±€ã€å¡ç‰‡å¼è®¾è®¡æˆ–æŠ˜å å±•ç¤º",
                    "- å¸ƒå±€å»ºè®®ï¼šä½¿ç”¨ç½‘æ ¼å¸ƒå±€æˆ–å¤šåˆ—å¸ƒå±€ä¼˜åŒ–ç©ºé—´åˆ©ç”¨"
                ])
            elif len(content_points) <= 3:
                guides.extend([
                    "- è§†è§‰ç»„ä»¶ï¼šå¯ä»¥ä½¿ç”¨å¤§åž‹å›¾æ ‡ã€æ’å›¾æˆ–å›¾è¡¨å¢žå¼ºè§†è§‰æ•ˆæžœ",
                    "- å¸ƒå±€å»ºè®®ï¼šé‡‡ç”¨å®½æ¾å¸ƒå±€ï¼Œå¢žåŠ å­—ä½“å¤§å°å’Œç•™ç™½ç©ºé—´"
                ])
            guides.append("- å†…å®¹ç»„ç»‡ï¼šå°è¯•æ—¶é—´çº¿ã€æµç¨‹å›¾ã€å¯¹æ¯”è¡¨æ ¼ç­‰åˆ›æ–°æ–¹å¼")

        # C. è§†è§‰å…ƒç´ ä¸Žäº¤äº’ä½“éªŒ
        guides.append("\n**C. è§†è§‰å…ƒç´ ä¸Žäº¤äº’ä½“éªŒ**")
        guides.extend([
            "- è§†è§‰å…ƒç´ ï¼šæ ¹æ®å†…å®¹ä¸»é¢˜é€‰æ‹©åˆé€‚çš„å›¾æ ‡å’Œè‰²å½©æ­é…",
            "- è‰²å½©å»ºè®®ï¼šä¿æŒä¸Žæ•´ä½“è®¾è®¡åŸºå› ä¸€è‡´çš„è‰²å½©æ–¹æ¡ˆ",
            "- äº¤äº’ä½“éªŒï¼šç¡®ä¿ä¿¡æ¯å±‚æ¬¡æ¸…æ™°ï¼Œä¾¿äºŽå¿«é€Ÿé˜…è¯»å’Œç†è§£"
        ])

        # æ ¹æ®æ ‡é¢˜å†…å®¹æ·»åŠ ç‰¹å®šå»ºè®®
        if any(keyword in title.lower() for keyword in ['æ•°æ®', 'ç»Ÿè®¡', 'åˆ†æž', 'data', 'analysis']):
            guides.append("- æ•°æ®å¯è§†åŒ–ï¼šæŽ¨èä½¿ç”¨æŸ±çŠ¶å›¾ã€é¥¼å›¾æˆ–æŠ˜çº¿å›¾å±•ç¤ºæ•°æ®")

        return "\n".join(guides)


    def _build_slide_context(self, page_number: int, total_pages: int) -> str:
        """Build context information for slide generation with style consistency and innovation balance"""
        return prompts_manager.get_slide_context_prompt(page_number, total_pages)

    def _extract_style_template(self, existing_slides: List[Dict[str, Any]]) -> List[str]:
        """Extract a comprehensive style template from existing slides"""
        if not existing_slides:
            return []

        template_parts = []

        # Analyze all existing slides to extract common patterns
        color_schemes = []
        font_families = []
        layout_patterns = []
        design_elements = []

        for slide in existing_slides:
            html_content = slide.get('html_content', '')
            if html_content:
                # Extract style information
                style_info = self._extract_detailed_style_info(html_content)
                if style_info.get('colors'):
                    color_schemes.extend(style_info['colors'])
                if style_info.get('fonts'):
                    font_families.extend(style_info['fonts'])
                if style_info.get('layout'):
                    layout_patterns.append(style_info['layout'])
                if style_info.get('design_elements'):
                    design_elements.extend(style_info['design_elements'])

        # Build style template
        template_parts.append("**æ ¸å¿ƒè®¾è®¡çº¦æŸï¼ˆå¿…é¡»ä¿æŒä¸€è‡´ï¼‰ï¼š**")

        # Color scheme
        if color_schemes:
            unique_colors = list(set(color_schemes))[:5]  # Top 5 colors
            template_parts.append(f"- ä¸»è‰²è°ƒï¼š{', '.join(unique_colors)}")

        # Typography
        if font_families:
            unique_fonts = list(set(font_families))[:3]  # Top 3 fonts
            template_parts.append(f"- å­—ä½“ç³»ç»Ÿï¼š{', '.join(unique_fonts)}")

        # Layout patterns
        if layout_patterns:
            common_layout = self._analyze_common_layout(layout_patterns)
            template_parts.append(f"- å¸ƒå±€æ¨¡å¼ï¼š{common_layout}")

        # Design elements
        if design_elements:
            unique_elements = list(set(design_elements))[:4]  # Top 4 elements
            template_parts.append(f"- è®¾è®¡å…ƒç´ ï¼š{', '.join(unique_elements)}")

        template_parts.append("")
        template_parts.append("**å¯åˆ›æ–°çš„è®¾è®¡ç©ºé—´ï¼š**")
        template_parts.append("- å†…å®¹å¸ƒå±€ç»“æž„ï¼ˆåœ¨ä¿æŒæ•´ä½“é£Žæ ¼ä¸‹å¯è°ƒæ•´ï¼‰")
        template_parts.append("- å›¾æ ‡å’Œè£…é¥°å…ƒç´ çš„é€‰æ‹©å’Œä½ç½®")
        template_parts.append("- åŠ¨ç”»å’Œäº¤äº’æ•ˆæžœçš„åˆ›æ–°")
        template_parts.append("- å†…å®¹å±•ç¤ºæ–¹å¼çš„ä¼˜åŒ–ï¼ˆå›¾è¡¨ã€åˆ—è¡¨ã€å¡ç‰‡ç­‰ï¼‰")
        template_parts.append("- è§†è§‰å±‚æ¬¡çš„é‡æ–°ç»„ç»‡")

        return template_parts

    def _extract_detailed_style_info(self, html_content: str) -> Dict[str, List[str]]:
        """Extract detailed style information from HTML content"""
        import re

        style_info = {
            'colors': [],
            'fonts': [],
            'layout': '',
            'design_elements': []
        }

        try:
            # Extract colors (more comprehensive)
            color_patterns = [
                r'color[^:]*:\s*([^;]+)',
                r'background[^:]*:\s*([^;]+)',
                r'border[^:]*:\s*([^;]+)',
                r'#[0-9a-fA-F]{3,6}',
                r'rgb\([^)]+\)',
                r'rgba\([^)]+\)'
            ]

            for pattern in color_patterns:
                matches = re.findall(pattern, html_content, re.IGNORECASE)
                style_info['colors'].extend([m.strip() for m in matches if m.strip()])

            # Extract fonts
            font_matches = re.findall(r'font-family[^:]*:\s*([^;]+)', html_content, re.IGNORECASE)
            style_info['fonts'] = [f.strip().replace('"', '').replace("'", '') for f in font_matches]

            # Analyze layout
            if 'display: flex' in html_content:
                style_info['layout'] = 'Flexboxå¸ƒå±€'
            elif 'display: grid' in html_content:
                style_info['layout'] = 'Gridå¸ƒå±€'
            elif 'position: absolute' in html_content:
                style_info['layout'] = 'ç»å¯¹å®šä½å¸ƒå±€'
            else:
                style_info['layout'] = 'æµå¼å¸ƒå±€'

            # Extract design elements
            if 'border-radius' in html_content:
                style_info['design_elements'].append('åœ†è§’è®¾è®¡')
            if 'box-shadow' in html_content:
                style_info['design_elements'].append('é˜´å½±æ•ˆæžœ')
            if 'gradient' in html_content:
                style_info['design_elements'].append('æ¸å˜èƒŒæ™¯')
            if 'transform' in html_content:
                style_info['design_elements'].append('å˜æ¢æ•ˆæžœ')
            if 'opacity' in html_content or 'rgba' in html_content:
                style_info['design_elements'].append('é€æ˜Žæ•ˆæžœ')

        except Exception as e:
            logger.warning(f"Error extracting detailed style info: {e}")

        return style_info

    def _analyze_common_layout(self, layout_patterns: List[str]) -> str:
        """Analyze common layout patterns"""
        if not layout_patterns:
            return "æ ‡å‡†æµå¼å¸ƒå±€"

        # Count occurrences
        layout_counts = {}
        for layout in layout_patterns:
            layout_counts[layout] = layout_counts.get(layout, 0) + 1

        # Return most common layout
        return max(layout_counts.items(), key=lambda x: x[1])[0]

    def _get_innovation_guidelines(self, slide_type: str, page_number: int, total_pages: int) -> List[str]:
        """Get innovation guidelines based on slide type and position"""
        guidelines = []

        # Position-based innovation
        if page_number == 1:
            guidelines.extend([
                "- æ ‡é¢˜é¡µï¼šå¯ä»¥åˆ›æ–°çš„å¼€åœºè®¾è®¡ï¼Œå¦‚ç‹¬ç‰¹çš„æ ‡é¢˜æŽ’ç‰ˆã€å¼•äººæ³¨ç›®çš„è§†è§‰å…ƒç´ ",
                "- è€ƒè™‘ä½¿ç”¨å¤§èƒ†çš„è§†è§‰å†²å‡»åŠ›ï¼Œä¸ºæ•´ä¸ªæ¼”ç¤ºå®šä¸‹åŸºè°ƒ"
            ])
        elif page_number == total_pages:
            guidelines.extend([
                "- ç»“å°¾é¡µï¼šå¯ä»¥è®¾è®¡æ€»ç»“æ€§çš„è§†è§‰å…ƒç´ ï¼Œå¦‚å›žé¡¾è¦ç‚¹çš„åˆ›æ–°å¸ƒå±€",
                "- è€ƒè™‘ä½¿ç”¨å‘¼åº”å¼€å¤´çš„è®¾è®¡å…ƒç´ ï¼Œå½¢æˆå®Œæ•´çš„è§†è§‰é—­çŽ¯"
            ])
        else:
            guidelines.extend([
                "- å†…å®¹é¡µï¼šå¯ä»¥æ ¹æ®å†…å®¹ç‰¹ç‚¹é€‰æ‹©æœ€é€‚åˆçš„å±•ç¤ºæ–¹å¼",
                "- è€ƒè™‘ä½¿ç”¨æ¸è¿›å¼çš„è§†è§‰å˜åŒ–ï¼Œä¿æŒè§‚ä¼—çš„æ³¨æ„åŠ›"
            ])

        # Content-based innovation
        content_innovations = {
            'title': [
                "- å¯ä»¥å°è¯•éžå¯¹ç§°å¸ƒå±€ã€åˆ›æ„å­—ä½“æŽ’åˆ—ã€èƒŒæ™¯å›¾æ¡ˆå˜åŒ–",
                "- è€ƒè™‘æ·»åŠ å¾®å¦™çš„åŠ¨ç”»æ•ˆæžœæˆ–è§†è§‰å¼•å¯¼å…ƒç´ "
            ],
            'content': [
                "- å¯ä»¥åˆ›æ–°å†…å®¹ç»„ç»‡æ–¹å¼ï¼šå¡ç‰‡å¼ã€æ—¶é—´çº¿ã€æµç¨‹å›¾ã€å¯¹æ¯”è¡¨æ ¼ç­‰",
                "- è€ƒè™‘ä½¿ç”¨å›¾æ ‡ã€æ’å›¾ã€æ•°æ®å¯è§†åŒ–æ¥å¢žå¼ºä¿¡æ¯ä¼ è¾¾",
                "- å¯ä»¥å°è¯•åˆ†æ å¸ƒå±€ã€é‡ç‚¹çªå‡ºæ¡†ã€å¼•ç”¨æ ·å¼ç­‰"
            ],
            'conclusion': [
                "- å¯ä»¥è®¾è®¡æ€»ç»“æ€§çš„è§†è§‰æ¡†æž¶ï¼šè¦ç‚¹å›žé¡¾ã€è¡ŒåŠ¨å·å¬ã€è”ç³»æ–¹å¼å±•ç¤º",
                "- è€ƒè™‘ä½¿ç”¨è§†è§‰åŒ–çš„æ€»ç»“æ–¹å¼ï¼Œå¦‚æ€ç»´å¯¼å›¾ã€å…³é”®è¯äº‘ç­‰"
            ]
        }

        if slide_type in content_innovations:
            guidelines.extend(content_innovations[slide_type])
        else:
            guidelines.extend(content_innovations['content'])  # Default to content guidelines

        # General innovation principles
        guidelines.extend([
            "",
            "**åˆ›æ–°åŽŸåˆ™ï¼š**",
            "- åœ¨ä¿æŒé£Žæ ¼ä¸€è‡´æ€§çš„å‰æä¸‹ï¼Œå¤§èƒ†å°è¯•æ–°çš„è§†è§‰è¡¨è¾¾æ–¹å¼",
            "- æ ¹æ®å†…å®¹çš„é‡è¦æ€§å’Œå¤æ‚åº¦è°ƒæ•´è§†è§‰å±‚æ¬¡",
            "- è€ƒè™‘è§‚ä¼—çš„é˜…è¯»ä¹ æƒ¯å’Œè®¤çŸ¥è´Ÿè·",
            "- ç¡®ä¿åˆ›æ–°ä¸å½±å“ä¿¡æ¯çš„æ¸…æ™°ä¼ è¾¾",
            "- å¯ä»¥é€‚åº¦ä½¿ç”¨å½“å‰æµè¡Œçš„è®¾è®¡è¶‹åŠ¿ï¼Œä½†è¦ä¸Žæ•´ä½“é£Žæ ¼åè°ƒ"
        ])

        return guidelines

    def _extract_style_info(self, html_content: str) -> List[str]:
        """Extract style information from HTML content for consistency reference"""
        import re
        style_info = []

        try:
            # Extract background colors
            bg_colors = re.findall(r'background[^:]*:\s*([^;]+)', html_content, re.IGNORECASE)
            if bg_colors:
                style_info.append(f"èƒŒæ™¯è‰²è°ƒï¼š{bg_colors[0][:50]}")

            # Extract color schemes
            colors = re.findall(r'color[^:]*:\s*([^;]+)', html_content, re.IGNORECASE)
            if colors:
                unique_colors = list(set(colors[:3]))  # Get first 3 unique colors
                style_info.append(f"ä¸»è¦é¢œè‰²ï¼š{', '.join(unique_colors)}")

            # Extract font families
            fonts = re.findall(r'font-family[^:]*:\s*([^;]+)', html_content, re.IGNORECASE)
            if fonts:
                style_info.append(f"å­—ä½“ï¼š{fonts[0][:50]}")

            # Extract font sizes
            font_sizes = re.findall(r'font-size[^:]*:\s*([^;]+)', html_content, re.IGNORECASE)
            if font_sizes:
                unique_sizes = list(set(font_sizes[:3]))  # Get first 3 unique sizes
                style_info.append(f"å­—ä½“å¤§å°ï¼š{', '.join(unique_sizes)}")

            # Extract border radius for design style
            border_radius = re.findall(r'border-radius[^:]*:\s*([^;]+)', html_content, re.IGNORECASE)
            if border_radius:
                style_info.append(f"åœ†è§’æ ·å¼ï¼š{border_radius[0]}")

            # Extract box shadow for depth effect
            box_shadow = re.findall(r'box-shadow[^:]*:\s*([^;]+)', html_content, re.IGNORECASE)
            if box_shadow:
                style_info.append(f"é˜´å½±æ•ˆæžœï¼š{box_shadow[0][:50]}")

            # Extract layout patterns
            if 'display: flex' in html_content:
                style_info.append("å¸ƒå±€æ–¹å¼ï¼šFlexboxå¸ƒå±€")
            elif 'display: grid' in html_content:
                style_info.append("å¸ƒå±€æ–¹å¼ï¼šGridå¸ƒå±€")

            # Extract padding/margin patterns
            paddings = re.findall(r'padding[^:]*:\s*([^;]+)', html_content, re.IGNORECASE)
            if paddings:
                style_info.append(f"å†…è¾¹è·ï¼š{paddings[0]}")

        except Exception as e:
            logger.warning(f"Error extracting style info: {e}")

        return style_info[:8]  # Limit to 8 most important style elements

    def _validate_html_completeness(self, html_content: str) -> Dict[str, Any]:
        """
        Validate HTML format correctness and tag closure using BeautifulSoup and lxml.

        This validator checks for:
        1. Presence of essential elements (<!DOCTYPE>, <html>, <head>, <body>) as warnings
        2. Correct structural order (<head> before <body>) as a warning
        3. Well-formedness and tag closure using strict parsing, reported as errors
        4. Unescaped special characters ('<' or '>') in text content as a warning

        Returns:
            Dict with 'is_complete', 'errors', 'warnings', 'missing_elements' keys
        """
        from bs4 import BeautifulSoup, MarkupResemblesLocatorWarning
        import warnings

        validation_result = {
            'is_complete': False,
            'errors': [],
            'warnings': [],
            'missing_elements': []  # æ·»åŠ missing_elementså­—æ®µ
        }

        if not html_content or not html_content.strip():
            validation_result['errors'].append('HTMLå†…å®¹ä¸ºç©ºæˆ–ä»…åŒ…å«ç©ºç™½å­—ç¬¦')
            return validation_result

        # --- Primary Validation using Strict Parsing ---
        # This is the most reliable way to find malformed HTML and unclosed tags
        self._check_html_well_formedness(html_content, validation_result)

        # --- Secondary Validation using BeautifulSoup for structural best practices ---
        # This part runs even if there are syntax errors to provide more feedback
        try:
            # Suppress BeautifulSoup warnings about markup that looks like a file path
            with warnings.catch_warnings():
                warnings.filterwarnings("ignore", category=MarkupResemblesLocatorWarning)
                # Use 'html.parser' for better compatibility, fallback to 'lxml' if available
                try:
                    soup = BeautifulSoup(html_content, 'lxml')
                except:
                    soup = BeautifulSoup(html_content, 'html.parser')

            # 1. Check for DOCTYPE declaration (Missing element)
            if not html_content.strip().lower().startswith('<!doctype'):
                validation_result['missing_elements'].append('doctype')

            # 2. Check for essential structural elements (Missing elements)
            essential_tags = {'html', 'head', 'body'}
            for tag_name in essential_tags:
                if not soup.find(tag_name):
                    validation_result['missing_elements'].append(tag_name)

            # 3. Check for correct structure order: <head> before <body> (Warning)
            head_tag = soup.find('head')
            body_tag = soup.find('body')

            if head_tag and body_tag:
                # Check if body tag has a preceding sibling named 'head'
                if not body_tag.find_previous_sibling('head'):
                    validation_result['warnings'].append('HTMLç»“æž„é¡ºåºä¸æ­£ç¡®ï¼š<body>æ ‡ç­¾å‡ºçŽ°åœ¨<head>æ ‡ç­¾ä¹‹å‰')

            # 4. Check for unescaped special characters in text content (Warning)
            # soup.get_text() extracts only human-readable text
            text_content = soup.get_text()
            if '<' in text_content or '>' in text_content:
                validation_result['warnings'].append('æ–‡æœ¬å†…å®¹ä¸­å¯èƒ½åŒ…å«æœªè½¬ä¹‰çš„ç‰¹æ®Šå­—ç¬¦ï¼ˆ\'<\'æˆ–\'>\'ï¼‰')

        except Exception as e:
            # Catch potential errors from BeautifulSoup itself
            validation_result['errors'].append(f'BeautifulSoupè§£æžè¿‡ç¨‹ä¸­å‘ç”Ÿæ„å¤–é”™è¯¯: {e}')

        # Final determination of validity is based on the absence of critical errors
        # missing_elements are treated as warnings only, not errors
        validation_result['is_complete'] = len(validation_result['errors']) == 0

        return validation_result

    def _check_html_well_formedness(self, html_content: str, validation_result: Dict[str, Any]) -> None:
        """
        Uses lxml's strict parser to check if the HTML is well-formed.
        This is the definitive check for syntax errors like unclosed tags.
        Modifies the validation_result dictionary in place.
        """
        try:
            # Try to import lxml for strict parsing
            from lxml import etree

            # Encode the string to bytes for the lxml parser
            encoded_html = html_content.encode('utf-8')
            # Create a parser that does NOT recover from errors. This makes it strict.
            parser = etree.HTMLParser(recover=False, encoding='utf-8')
            etree.fromstring(encoded_html, parser)

        except ImportError:
            # lxml not available, fall back to basic regex checks
            logger.warning("lxml not available, using basic HTML validation")
            self._basic_html_syntax_check(html_content, validation_result)

        except Exception as e:
            # This error is triggered by unclosed tags, malformed tags, etc.
            # It's the most reliable indicator of a syntax problem.
            validation_result['errors'].append(f'HTMLè¯­æ³•é”™è¯¯: {str(e)}')

    def _auto_fix_html_with_parser(self, html_content: str) -> str:
        """
        ä½¿ç”¨ lxml çš„æ¢å¤è§£æžå™¨è‡ªåŠ¨ä¿®å¤ HTML é”™è¯¯

        Args:
            html_content: åŽŸå§‹ HTML å†…å®¹

        Returns:
            ä¿®å¤åŽçš„ HTML å†…å®¹ï¼Œå¦‚æžœä¿®å¤å¤±è´¥åˆ™è¿”å›žåŽŸå§‹å†…å®¹
        """
        try:
            from lxml import etree

            # é¦–å…ˆæ£€æŸ¥åŽŸå§‹ HTML æ˜¯å¦å·²ç»æ˜¯æœ‰æ•ˆçš„
            try:
                # å°è¯•ä¸¥æ ¼è§£æž
                encoded_html = html_content.encode('utf-8')
                strict_parser = etree.HTMLParser(recover=False, encoding='utf-8')
                etree.fromstring(encoded_html, strict_parser)
                # å¦‚æžœä¸¥æ ¼è§£æžæˆåŠŸï¼Œè¯´æ˜Ž HTML å·²ç»æ˜¯æœ‰æ•ˆçš„ï¼Œç›´æŽ¥è¿”å›ž
                logger.debug("HTML å·²ç»æ˜¯æœ‰æ•ˆçš„ï¼Œæ— éœ€ä¿®å¤")
                return html_content
            except:
                # ä¸¥æ ¼è§£æžå¤±è´¥ï¼Œéœ€è¦ä¿®å¤
                pass

            # åˆ›å»ºä¸€ä¸ªå¯ç”¨æ¢å¤åŠŸèƒ½çš„è§£æžå™¨
            parser = etree.HTMLParser(recover=True, encoding='utf-8')
            tree = etree.fromstring(encoded_html, parser)

            # ä¿ç•™ DOCTYPE å£°æ˜Žï¼ˆå¦‚æžœå­˜åœ¨ï¼‰
            doctype_match = None
            import re
            doctype_pattern = r'<!DOCTYPE[^>]*>'
            doctype_match = re.search(doctype_pattern, html_content, re.IGNORECASE)

            # å°†ä¿®å¤åŽçš„æ ‘è½¬æ¢å›žå­—ç¬¦ä¸²
            fixed_html = etree.tostring(tree, encoding='unicode', method='html', pretty_print=True)

            # å¦‚æžœåŽŸå§‹ HTML æœ‰ DOCTYPEï¼Œæ·»åŠ å›žåŽ»
            if doctype_match:
                doctype = doctype_match.group(0)
                if not fixed_html.lower().startswith('<!doctype'):
                    fixed_html = doctype + '\n' + fixed_html

            logger.info("ä½¿ç”¨ lxml è§£æžå™¨è‡ªåŠ¨ä¿®å¤ HTML æˆåŠŸ")
            return fixed_html

        except ImportError:
            logger.warning("lxml ä¸å¯ç”¨ï¼Œæ— æ³•ä½¿ç”¨è§£æžå™¨è‡ªåŠ¨ä¿®å¤")
            return html_content

        except Exception as e:
            logger.warning(f"è§£æžå™¨è‡ªåŠ¨ä¿®å¤å¤±è´¥: {str(e)}")
            return html_content

    def _basic_html_syntax_check(self, html_content: str, validation_result: Dict[str, Any]) -> None:
        """
        Basic HTML syntax checking when lxml is not available.
        Uses regex patterns to detect common HTML syntax errors.
        """
        import re
        from collections import Counter

        # Check for malformed tags (tags containing other tags)
        malformed_tags = re.findall(r'<[^>]*<[^>]*>', html_content)
        if malformed_tags:
            validation_result['errors'].append('å‘çŽ°æ ¼å¼é”™è¯¯çš„æ ‡ç­¾')

        # Check for unclosed critical HTML tags using tag counting
        # Define critical HTML tags that must be properly closed
        critical_tags = {'html', 'head', 'body', 'div', 'p', 'span'}

        # Find all opening and closing tags
        open_tags = re.findall(r'<([a-zA-Z][a-zA-Z0-9]*)[^>]*>', html_content)
        close_tags = re.findall(r'</([a-zA-Z][a-zA-Z0-9]*)>', html_content)

        # Self-closing tags that don't need closing tags
        self_closing_tags = {'meta', 'link', 'img', 'br', 'hr', 'input', 'area', 'base', 'col', 'embed', 'source', 'track', 'wbr'}

        # Filter to only check critical tags, excluding self-closing tags
        open_tags_filtered = [tag.lower() for tag in open_tags
                             if tag.lower() in critical_tags and tag.lower() not in self_closing_tags]
        close_tags_lower = [tag.lower() for tag in close_tags if tag.lower() in critical_tags]

        # Count occurrences of each tag
        open_tag_counts = Counter(open_tags_filtered)
        close_tag_counts = Counter(close_tags_lower)

        # Check for unclosed critical tags
        unclosed_critical_tags = []
        for tag, open_count in open_tag_counts.items():
            close_count = close_tag_counts.get(tag, 0)
            if open_count > close_count:
                unclosed_critical_tags.append(f"{tag}({open_count - close_count}ä¸ªæœªé—­åˆ)")

        if unclosed_critical_tags:
            validation_result['errors'].append(f'æœªé—­åˆçš„å…³é”®HTMLæ ‡ç­¾: {", ".join(unclosed_critical_tags)}')



    async def _generate_html_with_retry(self, context: str, system_prompt: str, slide_data: Dict[str, Any],
                                      page_number: int, total_pages: int, max_retries: int = 3) -> str:
        """Generate HTML with retry mechanism for incomplete responses"""

        for attempt in range(max_retries):
            try:
                logger.info(f"Generating HTML for slide {page_number}, attempt {attempt + 1}/{max_retries}")

                # Add retry-specific instructions to the context
                retry_context = context
                if attempt > 0:
                    retry_context += f"""

**é‡è¦æé†’ï¼ˆç¬¬{attempt + 1}æ¬¡å°è¯•ï¼‰ï¼š**
- å‰é¢çš„å°è¯•å¯èƒ½ç”Ÿæˆäº†ä¸å®Œæ•´çš„HTMLï¼Œè¯·ç¡®ä¿è¿™æ¬¡ç”Ÿæˆå®Œæ•´çš„HTMLæ–‡æ¡£
- å¿…é¡»åŒ…å«å®Œæ•´çš„HTMLç»“æž„ï¼š<!DOCTYPE html>, <html>, <head>, <body>ç­‰æ ‡ç­¾
- ç¡®ä¿æ‰€æœ‰æ ‡ç­¾éƒ½æ­£ç¡®é—­åˆ
- ä½¿ç”¨markdownä»£ç å—æ ¼å¼ï¼š```html\n[å®Œæ•´HTMLä»£ç ]\n```
- ä¸è¦æˆªæ–­HTMLä»£ç ï¼Œç¡®ä¿ä»¥</html>ç»“æŸ
"""

                # Use the existing ai_config from imports

                # Generate HTML
                response = await self.ai_provider.text_completion(
                    prompt=retry_context,
                    system_prompt=system_prompt,
                    max_tokens=ai_config.max_tokens,  # Increase token limit for retries
                    temperature=max(0.1, ai_config.temperature)  # Reduce temperature for retries
                )

                # Clean and extract HTML
                try:
                    html_content = self._clean_html_response(response.content)
                    if not html_content or len(html_content.strip()) < 50:
                        logger.warning(f"AI returned empty or too short HTML content for slide {page_number}")
                        continue
                except Exception as e:
                    logger.error(f"Error cleaning HTML response for slide {page_number}: {e}")
                    continue

                # Validate HTML completeness
                validation_result = self._validate_html_completeness(html_content)

                logger.info(f"HTML validation result for slide {page_number}, attempt {attempt + 1}: "
                          f"Complete: {validation_result['is_complete']}, "
                          f"Errors: {len(validation_result['errors'])}, "
                          f"Missing elements: {len(validation_result['missing_elements'])}")

                if validation_result['is_complete']:
                    # Log any missing elements as warnings only
                    if validation_result['missing_elements']:
                        logger.warning(f"Missing elements (warnings only): {', '.join(validation_result['missing_elements'])}")
                    logger.info(f"Successfully generated complete HTML for slide {page_number} on attempt {attempt + 1}")
                    return html_content
                else:
                    # Log validation issues
                    if validation_result['missing_elements']:
                        logger.warning(f"Missing elements (warnings only): {', '.join(validation_result['missing_elements'])}")
                    if validation_result['errors']:
                        logger.error(f"Validation errors: {'; '.join(validation_result['errors'])}")

                    # Only try to fix HTML with parser if there are actual errors (not just missing elements)
                    if validation_result['errors']:
                        # Try automatic parser-based fix
                        logger.info(f"ðŸ”§ Attempting automatic parser fix for slide {page_number}")
                        parser_fixed_html = self._auto_fix_html_with_parser(html_content)

                        # If parser actually changed something, return the fixed HTML directly
                        if parser_fixed_html != html_content:  # Only if parser actually changed something
                            logger.info(f"âœ… Successfully fixed HTML with parser for slide {page_number}, returning fixed result")
                            return parser_fixed_html
                        else:
                            logger.info(f"ðŸ”§ Parser did not change HTML for slide {page_number}")

                        # If parser fix didn't change anything, retry generation
                        if attempt < max_retries - 1:
                            logger.info(f"ðŸ”„ HTML has errors after parser fix, retrying fresh generation for slide {page_number}...")
                            continue
                        else:
                            # Last attempt failed, use fallback
                            logger.warning(f"âŒ All generation and parser fix attempts failed, using fallback for slide {page_number}")
                            return self._generate_fallback_slide_html(slide_data, page_number, total_pages)
                    else:
                        # No actual errors, just missing elements (warnings), so don't try to fix
                        logger.info(f"âœ… HTML is valid with only missing element warnings for slide {page_number}")
                        return html_content

            except Exception as e:
                error_msg = str(e)
                logger.error(f"Error in HTML generation attempt {attempt + 1} for slide {page_number}: {error_msg}")

                # ç‰¹æ®Šå¤„ç†JSONè§£æžé”™è¯¯å’Œå…¶ä»–AIå“åº”é”™è¯¯
                if "Expecting value" in error_msg or "JSON" in error_msg:
                    logger.warning(f"JSON parsing error detected, this might be due to malformed AI response")
                    # å¯¹äºŽJSONé”™è¯¯ï¼Œç›´æŽ¥é‡è¯•è€Œä¸å°è¯•ä¿®å¤
                    if attempt < max_retries - 1:
                        logger.info("Waiting 1 second before retry due to JSON parsing error...")
                        await asyncio.sleep(1)
                        continue

                if attempt == max_retries - 1:
                    # Last attempt failed with exception
                    logger.error(f"All attempts failed with errors, using fallback for slide {page_number}")
                    return self._generate_fallback_slide_html(slide_data, page_number, total_pages)
                continue

        # This should not be reached, but just in case
        return self._generate_fallback_slide_html(slide_data, page_number, total_pages)

    def _fix_incomplete_html(self, html_content: str, slide_data: Dict[str, Any],
                           page_number: int, total_pages: int) -> str:
        """Try to fix incomplete HTML by adding missing elements"""
        import re

        html_content = html_content.strip()

        # If HTML is completely empty or too short, return fallback
        if len(html_content) < 50:
            return self._generate_fallback_slide_html(slide_data, page_number, total_pages)

        # Check and add DOCTYPE if missing
        if not html_content.lower().startswith('<!doctype'):
            html_content = '<!DOCTYPE html>\n' + html_content

        # Check and add html tags if missing
        if not re.search(r'<html[^>]*>', html_content, re.IGNORECASE):
            html_content = html_content.replace('<!DOCTYPE html>', '<!DOCTYPE html>\n<html lang="zh-CN">')

        if not re.search(r'</html>', html_content, re.IGNORECASE):
            html_content += '\n</html>'

        # Check and add head section if missing
        if not re.search(r'<head[^>]*>', html_content, re.IGNORECASE):
            head_section = '''<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>{}</title>
</head>'''.format(slide_data.get('title', f'ç¬¬{page_number}é¡µ'))

            # Insert head after html tag
            html_content = re.sub(r'(<html[^>]*>)', r'\1\n' + head_section, html_content, flags=re.IGNORECASE)
        else:
            # Check if head section is missing closing tag
            if not re.search(r'</head>', html_content, re.IGNORECASE):
                # Find the head opening tag and add missing elements
                head_match = re.search(r'<head[^>]*>', html_content, re.IGNORECASE)
                if head_match:
                    head_start = head_match.end()
                    # Check if charset is missing
                    if not re.search(r'<meta[^>]*charset[^>]*>', html_content, re.IGNORECASE):
                        charset_meta = '\n    <meta charset="UTF-8">'
                        html_content = html_content[:head_start] + charset_meta + html_content[head_start:]

                    # Add closing head tag before body
                    if '<body' in html_content.lower():
                        html_content = re.sub(r'(<body[^>]*>)', r'</head>\n\1', html_content, flags=re.IGNORECASE)
                    else:
                        # Add closing head tag after title or at the end of head content
                        if '</title>' in html_content.lower():
                            html_content = re.sub(r'(</title>)', r'\1\n</head>', html_content, flags=re.IGNORECASE)
                        else:
                            # Find a good place to close head
                            html_content = re.sub(r'(<html[^>]*>.*?<head[^>]*>.*?)(<body|$)', r'\1\n</head>\n\2', html_content, flags=re.IGNORECASE | re.DOTALL)

        # Check and add body tags if missing
        if not re.search(r'<body[^>]*>', html_content, re.IGNORECASE):
            # Find where to insert body tag (after </head> or after <html>)
            if '</head>' in html_content.lower():
                html_content = re.sub(r'(</head>)', r'\1\n<body>', html_content, flags=re.IGNORECASE)
            else:
                html_content = re.sub(r'(<html[^>]*>)', r'\1\n<body>', html_content, flags=re.IGNORECASE)

        if not re.search(r'</body>', html_content, re.IGNORECASE):
            # Insert </body> before </html>
            html_content = re.sub(r'(</html>)', r'</body>\n\1', html_content, flags=re.IGNORECASE)

        return html_content



    def _clean_html_response(self, raw_content: str) -> str:
        """Clean and extract HTML content from AI response with robust markdown handling"""
        import re

        if not raw_content:
            logger.warning("Received empty response from AI")
            return ""

        content = raw_content.strip()
        logger.debug(f"Raw AI response length: {len(content)}, preview: {content[:200]}...")

        # Check if response is suspiciously short or contains error indicators
        if len(content) < 100:
            logger.warning(f"AI response is very short ({len(content)} chars), might be incomplete")

        if any(error_indicator in content.lower() for error_indicator in ['error', 'sorry', 'cannot', 'unable']):
            logger.warning("AI response contains error indicators")

        # Step 1: Look for markdown code blocks first (most reliable)
        # Pattern to match ```html...``` blocks
        html_block_pattern = r'```html\s*\n(.*?)\n```'
        html_match = re.search(html_block_pattern, content, re.DOTALL | re.IGNORECASE)

        if html_match:
            extracted_html = html_match.group(1).strip()
            logger.debug("Found HTML in markdown code block")
            return extracted_html

        # Step 2: Look for generic code blocks ```...```
        generic_block_pattern = r'```\s*\n(.*?)\n```'
        generic_match = re.search(generic_block_pattern, content, re.DOTALL)

        if generic_match:
            potential_html = generic_match.group(1).strip()
            # Check if it looks like HTML
            if (potential_html.lower().startswith('<!doctype html') or
                potential_html.lower().startswith('<html')):
                logger.debug("Found HTML in generic code block")
                return potential_html

        # Step 3: Remove common AI response prefixes and try direct extraction
        prefixes_to_remove = [
            "è¿™æ˜¯ç”Ÿæˆçš„HTMLä»£ç ï¼š",
            "ä»¥ä¸‹æ˜¯HTMLä»£ç ï¼š",
            "HTMLä»£ç å¦‚ä¸‹ï¼š",
            "ç”Ÿæˆçš„å®Œæ•´HTMLé¡µé¢ï¼š",
            "Here's the HTML code:",
            "The HTML code is:",
            "```html",
            "```",
        ]

        for prefix in prefixes_to_remove:
            if content.startswith(prefix):
                content = content[len(prefix):].strip()

        # Remove trailing markdown markers
        if content.endswith('```'):
            content = content[:-3].strip()

        # Step 4: Extract HTML using DOCTYPE or html tag patterns
        # Look for complete HTML document with DOCTYPE
        doctype_pattern = r'<!DOCTYPE html.*?</html>'
        doctype_match = re.search(doctype_pattern, content, re.DOTALL | re.IGNORECASE)

        if doctype_match:
            extracted_html = doctype_match.group(0)
            logger.debug("Found HTML using DOCTYPE pattern")
            return extracted_html

        # Look for html tag without DOCTYPE
        html_pattern = r'<html.*?</html>'
        html_match = re.search(html_pattern, content, re.DOTALL | re.IGNORECASE)

        if html_match:
            extracted_html = html_match.group(0)
            logger.debug("Found HTML using html tag pattern")
            return extracted_html

        # Step 5: Line-by-line extraction as fallback
        lines = content.split('\n')
        html_lines = []
        in_html = False

        for line in lines:
            line_stripped = line.strip()
            line_lower = line_stripped.lower()

            # Skip empty lines and common non-HTML prefixes
            if not line_stripped or line_stripped.startswith('#') or line_stripped.startswith('//'):
                continue

            # Start collecting when we see HTML start
            if line_lower.startswith('<!doctype') or line_lower.startswith('<html'):
                in_html = True
                html_lines.append(line)
                continue

            # Collect lines if we're in HTML
            if in_html:
                html_lines.append(line)

                # Stop when we see HTML end
                if line_lower.strip().endswith('</html>'):
                    break

        if html_lines:
            extracted_html = '\n'.join(html_lines)
            logger.debug("Found HTML using line-by-line extraction")
            return extracted_html

        # Step 6: If all else fails, check if content looks like HTML at all
        if '<' in content and '>' in content:
            logger.warning("Could not extract HTML using any method, but content contains HTML tags, returning cleaned content")
            return content
        else:
            logger.error("Content does not appear to contain HTML, returning empty string")
            return ""


    
    def _generate_fallback_slide_html(self, slide_data: Dict[str, Any], page_number: int, total_pages: int) -> str:
        """Generate fallback HTML for a slide with improved content visibility and special designs for title/thankyou slides"""
        title = slide_data.get('title', f'ç¬¬{page_number}é¡µ')
        content_points = slide_data.get('content_points', [])
        slide_type = slide_data.get('slide_type', 'content')

        if slide_type == 'title':
            # ç‰¹æ®Šè®¾è®¡çš„é¦–é¡µ - äº®çœ¼çš„è§†è§‰æ•ˆæžœ
            content_html = f"""
            <div style="
                text-align: center;
                width: 100%;
                aspect-ratio: 16/9;
                display: flex;
                flex-direction: column;
                justify-content: center;
                margin: 0 auto;
                box-sizing: border-box;
                position: relative;
                max-width: 1200px;
                padding: 3% 5%;
                background: linear-gradient(135deg, #667eea 0%, #764ba2 50%, #f093fb 100%);
                overflow: hidden;
            ">
                <!-- åŠ¨æ€èƒŒæ™¯è£…é¥° -->
                <div style="
                    position: absolute;
                    top: -50%;
                    left: -50%;
                    width: 200%;
                    height: 200%;
                    background: radial-gradient(circle, rgba(255,255,255,0.1) 1px, transparent 1px);
                    background-size: 50px 50px;
                    animation: float 20s ease-in-out infinite;
                    z-index: 1;
                "></div>

                <!-- å…‰æ•ˆè£…é¥° -->
                <div style="
                    position: absolute;
                    top: 20%;
                    right: 10%;
                    width: 200px;
                    height: 200px;
                    background: radial-gradient(circle, rgba(255,255,255,0.2) 0%, transparent 70%);
                    border-radius: 50%;
                    z-index: 1;
                "></div>

                <div style="
                    position: absolute;
                    bottom: 30%;
                    left: 15%;
                    width: 150px;
                    height: 150px;
                    background: radial-gradient(circle, rgba(255,255,255,0.15) 0%, transparent 70%);
                    border-radius: 50%;
                    z-index: 1;
                "></div>

                <!-- ä¸»è¦å†…å®¹ -->
                <div style="position: relative; z-index: 2;">
                    <h1 style="
                        font-size: clamp(2rem, 5vw, 4rem);
                        color: #ffffff;
                        margin-bottom: clamp(30px, 4vh, 50px);
                        line-height: 1.2;
                        text-shadow: 0 4px 8px rgba(0,0,0,0.3);
                        font-weight: 700;
                        letter-spacing: 1px;
                        background: linear-gradient(45deg, #ffffff, #f8f9fa);
                        -webkit-background-clip: text;
                        -webkit-text-fill-color: transparent;
                        background-clip: text;
                    ">{title}</h1>

                    <div style="
                        width: 80px;
                        height: 4px;
                        background: linear-gradient(90deg, #ff6b6b, #4ecdc4, #45b7d1);
                        margin: 0 auto clamp(20px, 3vh, 30px) auto;
                        border-radius: 2px;
                    "></div>

                    <p style="
                        font-size: clamp(1.2rem, 3vw, 2rem);
                        color: rgba(255,255,255,0.9);
                        line-height: 1.4;
                        font-weight: 300;
                        text-shadow: 0 2px 4px rgba(0,0,0,0.2);
                    ">ä¸“ä¸šæ¼”ç¤ºæ–‡ç¨¿</p>

                    <!-- è£…é¥°æ€§å…ƒç´  -->
                    <div style="
                        margin-top: clamp(30px, 4vh, 50px);
                        display: flex;
                        justify-content: center;
                        gap: 15px;
                    ">
                        <div style="
                            width: 12px;
                            height: 12px;
                            background: rgba(255,255,255,0.6);
                            border-radius: 50%;
                            animation: pulse 2s ease-in-out infinite;
                        "></div>
                        <div style="
                            width: 12px;
                            height: 12px;
                            background: rgba(255,255,255,0.4);
                            border-radius: 50%;
                            animation: pulse 2s ease-in-out infinite 0.5s;
                        "></div>
                        <div style="
                            width: 12px;
                            height: 12px;
                            background: rgba(255,255,255,0.6);
                            border-radius: 50%;
                            animation: pulse 2s ease-in-out infinite 1s;
                        "></div>
                    </div>
                </div>

                <!-- é¡µç  -->
                <div style="
                    position: absolute;
                    bottom: 15px;
                    right: 20px;
                    color: rgba(255,255,255,0.8);
                    font-size: clamp(10px, 1.5vw, 14px);
                    font-weight: 500;
                    background: rgba(0,0,0,0.2);
                    padding: 6px 12px;
                    border-radius: 20px;
                    backdrop-filter: blur(10px);
                    z-index: 3;
                ">
                    ç¬¬{page_number}é¡µ / å…±{total_pages}é¡µ
                </div>

                <style>
                    @keyframes float {{
                        0%, 100% {{ transform: translateY(0px) rotate(0deg); }}
                        50% {{ transform: translateY(-20px) rotate(180deg); }}
                    }}
                    @keyframes pulse {{
                        0%, 100% {{ opacity: 0.6; transform: scale(1); }}
                        50% {{ opacity: 1; transform: scale(1.2); }}
                    }}
                </style>
            </div>
            """
        elif slide_type in ['thankyou', 'conclusion']:
            # ç‰¹æ®Šè®¾è®¡çš„ç»“å°¾é¡µ - äº®çœ¼çš„æ€»ç»“æ•ˆæžœ
            content_html = f"""
            <div style="
                text-align: center;
                width: 100%;
                aspect-ratio: 16/9;
                display: flex;
                flex-direction: column;
                justify-content: center;
                margin: 0 auto;
                box-sizing: border-box;
                position: relative;
                max-width: 1200px;
                padding: 3% 5%;
                background: linear-gradient(135deg, #2c3e50 0%, #3498db 50%, #9b59b6 100%);
                overflow: hidden;
            ">
                <!-- æ˜Ÿç©ºèƒŒæ™¯æ•ˆæžœ -->
                <div style="
                    position: absolute;
                    top: 0;
                    left: 0;
                    width: 100%;
                    height: 100%;
                    background-image:
                        radial-gradient(2px 2px at 20px 30px, rgba(255,255,255,0.8), transparent),
                        radial-gradient(2px 2px at 40px 70px, rgba(255,255,255,0.6), transparent),
                        radial-gradient(1px 1px at 90px 40px, rgba(255,255,255,0.9), transparent),
                        radial-gradient(1px 1px at 130px 80px, rgba(255,255,255,0.7), transparent),
                        radial-gradient(2px 2px at 160px 30px, rgba(255,255,255,0.8), transparent);
                    background-repeat: repeat;
                    background-size: 200px 100px;
                    animation: sparkle 3s ease-in-out infinite;
                    z-index: 1;
                "></div>

                <!-- å…‰åœˆè£…é¥° -->
                <div style="
                    position: absolute;
                    top: 50%;
                    left: 50%;
                    transform: translate(-50%, -50%);
                    width: 300px;
                    height: 300px;
                    border: 2px solid rgba(255,255,255,0.2);
                    border-radius: 50%;
                    animation: rotate 10s linear infinite;
                    z-index: 1;
                "></div>

                <div style="
                    position: absolute;
                    top: 50%;
                    left: 50%;
                    transform: translate(-50%, -50%);
                    width: 200px;
                    height: 200px;
                    border: 1px solid rgba(255,255,255,0.3);
                    border-radius: 50%;
                    animation: rotate 8s linear infinite reverse;
                    z-index: 1;
                "></div>

                <!-- ä¸»è¦å†…å®¹ -->
                <div style="position: relative; z-index: 2;">
                    <h1 style="
                        font-size: clamp(2.5rem, 6vw, 4.5rem);
                        color: #ffffff;
                        margin-bottom: clamp(20px, 3vh, 30px);
                        line-height: 1.2;
                        text-shadow: 0 4px 12px rgba(0,0,0,0.4);
                        font-weight: 700;
                        letter-spacing: 2px;
                        background: linear-gradient(45deg, #ffffff, #f39c12, #e74c3c);
                        -webkit-background-clip: text;
                        -webkit-text-fill-color: transparent;
                        background-clip: text;
                        animation: glow 2s ease-in-out infinite alternate;
                    ">{title}</h1>

                    <!-- è£…é¥°æ€§åˆ†å‰²çº¿ -->
                    <div style="
                        display: flex;
                        justify-content: center;
                        align-items: center;
                        margin: clamp(20px, 3vh, 30px) 0;
                    ">
                        <div style="
                            width: 50px;
                            height: 2px;
                            background: linear-gradient(90deg, transparent, #ffffff, transparent);
                        "></div>
                        <div style="
                            width: 20px;
                            height: 20px;
                            background: radial-gradient(circle, #ffffff 30%, transparent 30%);
                            margin: 0 15px;
                            border-radius: 50%;
                        "></div>
                        <div style="
                            width: 50px;
                            height: 2px;
                            background: linear-gradient(90deg, transparent, #ffffff, transparent);
                        "></div>
                    </div>

                    <p style="
                        font-size: clamp(1.2rem, 3vw, 1.8rem);
                        color: rgba(255,255,255,0.9);
                        line-height: 1.4;
                        font-weight: 300;
                        text-shadow: 0 2px 4px rgba(0,0,0,0.3);
                        margin-bottom: clamp(30px, 4vh, 40px);
                    ">æ„Ÿè°¢æ‚¨çš„è†å¬</p>

                    <!-- å†…å®¹è¦ç‚¹ï¼ˆå¦‚æžœæœ‰ï¼‰ -->"""

            # å¤„ç†å†…å®¹è¦ç‚¹çš„æ˜¾ç¤º
            if content_points:
                content_html += '''
                    <div style="
                        margin-top: clamp(20px, 3vh, 30px);
                        text-align: left;
                        max-width: 600px;
                        margin-left: auto;
                        margin-right: auto;
                    ">'''
                for point in content_points[:3]:
                    content_html += f'''
                        <div style="
                            background: rgba(255,255,255,0.1);
                            padding: 12px 20px;
                            margin: 10px 0;
                            border-radius: 25px;
                            border-left: 4px solid #f39c12;
                            color: rgba(255,255,255,0.9);
                            font-size: clamp(0.9rem, 2vw, 1.2rem);
                            backdrop-filter: blur(5px);
                        ">{point}</div>'''
                content_html += '''
                    </div>'''

            content_html += """

                    <!-- ç»“å°¾è£…é¥° -->
                    <div style="
                        margin-top: clamp(30px, 4vh, 40px);
                        display: flex;
                        justify-content: center;
                        gap: 20px;
                    ">
                        <div style="
                            width: 8px;
                            height: 8px;
                            background: #e74c3c;
                            border-radius: 50%;
                            animation: bounce 1.5s ease-in-out infinite;
                        "></div>
                        <div style="
                            width: 8px;
                            height: 8px;
                            background: #f39c12;
                            border-radius: 50%;
                            animation: bounce 1.5s ease-in-out infinite 0.3s;
                        "></div>
                        <div style="
                            width: 8px;
                            height: 8px;
                            background: #27ae60;
                            border-radius: 50%;
                            animation: bounce 1.5s ease-in-out infinite 0.6s;
                        "></div>
                        <div style="
                            width: 8px;
                            height: 8px;
                            background: #3498db;
                            border-radius: 50%;
                            animation: bounce 1.5s ease-in-out infinite 0.9s;
                        "></div>
                    </div>
                </div>

                <!-- é¡µç  -->
                <div style="
                    position: absolute;
                    bottom: 15px;
                    right: 20px;
                    color: rgba(255,255,255,0.8);
                    font-size: clamp(10px, 1.5vw, 14px);
                    font-weight: 500;
                    background: rgba(0,0,0,0.2);
                    padding: 6px 12px;
                    border-radius: 20px;
                    backdrop-filter: blur(10px);
                    z-index: 3;
                ">
                    ç¬¬{page_number}é¡µ / å…±{total_pages}é¡µ
                </div>

                <style>
                    @keyframes sparkle {{
                        0%, 100% {{ opacity: 0.8; }}
                        50% {{ opacity: 1; }}
                    }}
                    @keyframes rotate {{
                        from {{ transform: translate(-50%, -50%) rotate(0deg); }}
                        to {{ transform: translate(-50%, -50%) rotate(360deg); }}
                    }}
                    @keyframes glow {{
                        0% {{ text-shadow: 0 4px 12px rgba(0,0,0,0.4); }}
                        100% {{ text-shadow: 0 4px 20px rgba(255,255,255,0.3), 0 0 30px rgba(255,255,255,0.2); }}
                    }}
                    @keyframes bounce {{
                        0%, 100% {{ transform: translateY(0); }}
                        50% {{ transform: translateY(-10px); }}
                    }}
                </style>
            </div>
            """
        else:
            points_html = ""
            if content_points:
                points_html = "<div style='max-height: 60vh; overflow-y: auto; padding-right: 10px;'><ul style='font-size: clamp(0.9rem, 2.5vw, 1.4rem); line-height: 1.5; margin: 0; padding-left: 1.5em;'>"
                for point in content_points:
                    points_html += f"<li style='margin-bottom: 0.8em; word-wrap: break-word;'>{point}</li>"
                points_html += "</ul></div>"

            content_html = f"""
            <div style="padding: 3% 5%; width: 100%; aspect-ratio: 16/9; box-sizing: border-box; margin: 0 auto; position: relative; max-width: 1200px; display: flex; flex-direction: column;">
                <h1 style="font-size: clamp(1.5rem, 4vw, 3rem); color: #2c3e50; margin-bottom: clamp(15px, 2vh, 25px); border-bottom: 3px solid #3498db; padding-bottom: 10px; line-height: 1.2; flex-shrink: 0;">{title}</h1>
                <div style="flex: 1; overflow: hidden; display: flex; flex-direction: column;">
                    {points_html}
                </div>
                <div style="position: absolute; bottom: 15px; right: 20px; color: #95a5a6; font-size: clamp(10px, 1.5vw, 14px); font-weight: 500; background: rgba(255,255,255,0.8); padding: 4px 8px; border-radius: 4px; z-index: 10;">
                    ç¬¬{page_number}é¡µ / å…±{total_pages}é¡µ
                </div>
            </div>
            """

        return f"""
<!DOCTYPE html>
<html lang="zh-CN" style="height: 100%; display: flex; align-items: center; justify-content: center;">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>{title}</title>
    <style>
        body {{
            margin: 0;
            padding: 0;
            font-family: 'Microsoft YaHei', Arial, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: #2c3e50;
            width: 1280px;
            height: 720px;
            position: relative;
            overflow: hidden;
        }}
    </style>
</head>
<body>
    {content_html}
</body>
</html>
        """

    def _combine_slides_to_full_html(self, slides_data: List[Dict[str, Any]], title: str) -> str:
        """Combine individual slides into a full presentation HTML and save to temp files"""
        try:
            # éªŒè¯è¾“å…¥æ•°æ®
            if not slides_data:
                logger.warning("No slides data provided for combining")
                return self._generate_empty_presentation_html(title)

            if not title:
                title = "æœªå‘½åæ¼”ç¤º"

            # Create temp directory for this presentation
            presentation_id = f"presentation_{uuid.uuid4().hex[:8]}"
            temp_dir = Path(tempfile.gettempdir()) / "landppt" / presentation_id
            temp_dir.mkdir(parents=True, exist_ok=True)

            logger.info(f"Combining {len(slides_data)} slides into full HTML presentation")

            # Save individual slide HTML files
            slide_files = []
            for i, slide in enumerate(slides_data):
                # å®‰å…¨åœ°èŽ·å–é¡µç ï¼Œå¦‚æžœæ²¡æœ‰åˆ™ä½¿ç”¨ç´¢å¼•+1
                page_number = slide.get('page_number', i + 1)
                slide_filename = f"slide_{page_number}.html"
                slide_path = temp_dir / slide_filename

                # ç¡®ä¿HTMLå†…å®¹å­˜åœ¨
                html_content = slide.get('html_content', '<div>ç©ºå†…å®¹</div>')

                # Write slide HTML to file
                with open(slide_path, 'w', encoding='utf-8') as f:
                    f.write(html_content)

                # Create relative path for HTTP access
                relative_path = f"{presentation_id}/{slide_filename}"
                slide_files.append({
                    'page_number': page_number,
                    'filename': slide_filename,
                    'relative_path': relative_path
                })

            # Generate slides HTML using base64 data URLs to avoid encoding issues
            slides_html = ""
            for i, slide in enumerate(slides_data):
                # å®‰å…¨åœ°èŽ·å–é¡µç å’ŒHTMLå†…å®¹
                page_number = slide.get('page_number', i + 1)
                html_content = slide.get('html_content', '<div>ç©ºå†…å®¹</div>')

                # Encode HTML content as base64 data URL
                encoded_html = self._encode_html_to_base64(html_content)
                data_url = f"data:text/html;charset=utf-8;base64,{encoded_html}"

                slides_html += f'''
                <div class="slide" id="slide-{page_number}" style="display: {'block' if i == 0 else 'none'};">
                    <iframe src="{data_url}"
                            style="width: 100%; height: 100%; border: none;"></iframe>
                </div>
                '''

            return f'''
<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>{title}</title>
    <style>
        body {{
            margin: 0;
            padding: 0;
            font-family: 'Microsoft YaHei', Arial, sans-serif;
            background: #000;
        }}
        .slide {{
            width: 100%;
            max-width: 1200px;
            aspect-ratio: 16/9;
            position: relative;
            margin: 0 auto;
        }}
        .navigation {{
            position: fixed;
            bottom: 20px;
            left: 50%;
            transform: translateX(-50%);
            z-index: 1000;
            background: rgba(0,0,0,0.7);
            padding: 10px 20px;
            border-radius: 25px;
        }}
        .nav-btn {{
            background: #3498db;
            color: white;
            border: none;
            padding: 8px 15px;
            margin: 0 5px;
            border-radius: 5px;
            cursor: pointer;
        }}
        .nav-btn:hover {{
            background: #2980b9;
        }}
        .nav-btn:disabled {{
            background: #95a5a6;
            cursor: not-allowed;
        }}
        .slide-counter {{
            color: white;
            margin: 0 15px;
        }}
    </style>
</head>
<body>
    {slides_html}

    <div class="navigation">
        <button class="nav-btn" onclick="previousSlide()">â¬…ï¸ ä¸Šä¸€é¡µ</button>
        <span class="slide-counter" id="slideCounter">1 / {len(slides_data)}</span>
        <button class="nav-btn" onclick="nextSlide()">ä¸‹ä¸€é¡µ âž¡ï¸</button>
    </div>

    <script>
        let currentSlide = 0;
        const totalSlides = {len(slides_data)};

        // No need for initialization - iframes already have src set to file paths

        function showSlide(index) {{
            document.querySelectorAll('.slide').forEach(slide => slide.style.display = 'none');
            const targetSlide = document.getElementById('slide-' + (index + 1));
            if (targetSlide) {{
                targetSlide.style.display = 'block';
            }}
            document.getElementById('slideCounter').textContent = (index + 1) + ' / ' + totalSlides;
        }}

        function nextSlide() {{
            if (currentSlide < totalSlides - 1) {{
                currentSlide++;
                showSlide(currentSlide);
            }}
        }}

        function previousSlide() {{
            if (currentSlide > 0) {{
                currentSlide--;
                showSlide(currentSlide);
            }}
        }}

        // Keyboard navigation
        document.addEventListener('keydown', function(e) {{
            if (e.key === 'ArrowRight') nextSlide();
            if (e.key === 'ArrowLeft') previousSlide();
        }});

        // Initialize when page loads
        document.addEventListener('DOMContentLoaded', function() {{
            showSlide(0);
        }});
    </script>
</body>
</html>
            '''

        except Exception as e:
            logger.error(f"Error combining slides to full HTML: {e}")
            import traceback
            traceback.print_exc()
            return self._generate_empty_presentation_html(title)

    def _generate_empty_presentation_html(self, title: str) -> str:
        """Generate empty presentation HTML as fallback"""
        return f'''
<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>{title}</title>
    <style>
        body {{
            margin: 0;
            padding: 0;
            font-family: 'Microsoft YaHei', Arial, sans-serif;
            background: #f0f0f0;
            display: flex;
            justify-content: center;
            align-items: center;
            height: 100vh;
        }}
        .empty-message {{
            text-align: center;
            color: #666;
            font-size: 24px;
        }}
    </style>
</head>
<body>
    <div class="empty-message">
        <h1>æš‚æ— å¹»ç¯ç‰‡å†…å®¹</h1>
        <p>è¯·å…ˆç”Ÿæˆå¹»ç¯ç‰‡å†…å®¹</p>
    </div>
</body>
</html>
        '''

    def _encode_html_for_iframe(self, html_content: str) -> str:
        """Encode HTML content for iframe src"""
        import urllib.parse
        return urllib.parse.quote(html_content)

    def _encode_html_to_base64(self, html_content: str) -> str:
        """Encode HTML content to base64 for safe JavaScript transmission"""
        import base64
        return base64.b64encode(html_content.encode('utf-8')).decode('ascii')

    async def _design_theme(self, scenario: str, language: str) -> Dict[str, Any]:
        """Design theme configuration based on scenario"""
        theme_configs = {
            "general": {
                "primary_color": "#3498db",
                "secondary_color": "#2c3e50",
                "accent_color": "#e74c3c",
                "background": "linear-gradient(135deg, #667eea 0%, #764ba2 100%)",
                "font_family": "Arial, sans-serif",
                "style": "professional"
            },
            "tourism": {
                "primary_color": "#27ae60",
                "secondary_color": "#16a085",
                "accent_color": "#f39c12",
                "background": "linear-gradient(135deg, #74b9ff 0%, #0984e3 100%)",
                "font_family": "Georgia, serif",
                "style": "vibrant"
            },
            "education": {
                "primary_color": "#9b59b6",
                "secondary_color": "#8e44ad",
                "accent_color": "#f1c40f",
                "background": "linear-gradient(135deg, #a29bfe 0%, #6c5ce7 100%)",
                "font_family": "Comic Sans MS, cursive",
                "style": "playful"
            },
            "analysis": {
                "primary_color": "#34495e",
                "secondary_color": "#2c3e50",
                "accent_color": "#e67e22",
                "background": "linear-gradient(135deg, #636e72 0%, #2d3436 100%)",
                "font_family": "Helvetica, sans-serif",
                "style": "analytical"
            },
            "history": {
                "primary_color": "#8b4513",
                "secondary_color": "#a0522d",
                "accent_color": "#daa520",
                "background": "linear-gradient(135deg, #d63031 0%, #74b9ff 100%)",
                "font_family": "Times New Roman, serif",
                "style": "classical"
            },
            "technology": {
                "primary_color": "#6c5ce7",
                "secondary_color": "#a29bfe",
                "accent_color": "#00cec9",
                "background": "linear-gradient(135deg, #00cec9 0%, #6c5ce7 100%)",
                "font_family": "Roboto, sans-serif",
                "style": "modern"
            },
            "business": {
                "primary_color": "#1f4e79",
                "secondary_color": "#2980b9",
                "accent_color": "#f39c12",
                "background": "linear-gradient(135deg, #2980b9 0%, #1f4e79 100%)",
                "font_family": "Arial, sans-serif",
                "style": "corporate"
            }
        }

        return theme_configs.get(scenario, theme_configs["general"])

    def _normalize_slide_type(self, slide_type: str) -> str:
        """Normalize slide type to supported values"""
        type_mapping = {
            "agenda": "agenda",
            "section": "section",
            "conclusion": "conclusion",
            "thankyou": "thankyou",
            "title": "title",
            "content": "content",
            "image": "image",
            "chart": "chart",
            "list": "list",
            # Handle any other types by mapping to content
            "overview": "content",
            "summary": "conclusion",
            "intro": "content",
            "ending": "thankyou"
        }
        return type_mapping.get(slide_type, "content")

    async def _generate_enhanced_content(self, outline: PPTOutline, request: PPTGenerationRequest) -> List[SlideContent]:
        """Generate enhanced content for each slide"""
        enhanced_slides = []

        for i, slide_data in enumerate(outline.slides):
            try:
                # Generate detailed content using AI
                content = await self.generate_slide_content(
                    slide_data["title"],
                    request.scenario,
                    request.topic,
                    request.language
                )

                # Create enhanced slide content with improved image suggestions
                slide_content = SlideContent(
                    type=self._normalize_slide_type(slide_data.get("type", "content")),
                    title=slide_data["title"],
                    subtitle=slide_data.get("subtitle", ""),
                    content=content,
                    bullet_points=self._extract_bullet_points(content),
                    image_suggestions=await self._suggest_images(
                        slide_data["title"],
                        request.scenario,
                        content,
                        request.topic,
                        i + 1,
                        len(outline.slides)
                    ),
                    layout="default"
                )

                enhanced_slides.append(slide_content)

            except Exception as e:
                logger.error(f"Error generating content for slide {slide_data['title']}: {e}")
                # Fallback to basic content
                slide_content = SlideContent(
                    type=self._normalize_slide_type(slide_data.get("type", "content")),
                    title=slide_data["title"],
                    subtitle=slide_data.get("subtitle", ""),
                    content=slide_data.get("content", ""),
                    layout="default"
                )
                enhanced_slides.append(slide_content)

        return enhanced_slides

    async def _verify_layout(self, slides: List[SlideContent], theme_config: Dict[str, Any]) -> List[SlideContent]:
        """Verify and optimize slide layouts"""
        verified_slides = []

        for slide in slides:
            # Create a copy to avoid modifying original
            verified_slide = SlideContent(**slide.model_dump())

            # Apply layout optimizations based on content type
            if slide.type == "title":
                verified_slide.layout = "title_layout"
            elif slide.type == "agenda":
                verified_slide.layout = "agenda_layout"
            elif slide.type == "section":
                verified_slide.layout = "section_layout"
            elif slide.type == "conclusion":
                verified_slide.layout = "conclusion_layout"
            elif slide.type == "thankyou":
                verified_slide.layout = "thankyou_layout"
            elif slide.type == "content" and slide.bullet_points:
                verified_slide.layout = "bullet_layout"
            elif slide.type == "content" and slide.image_suggestions:
                verified_slide.layout = "image_content_layout"
            elif slide.type == "list":
                verified_slide.layout = "list_layout"
            elif slide.type == "chart":
                verified_slide.layout = "chart_layout"
            elif slide.type == "image":
                verified_slide.layout = "image_layout"
            else:
                verified_slide.layout = "default_layout"

            # Ensure content length is appropriate
            if verified_slide.content and len(verified_slide.content) > 500:
                verified_slide.content = verified_slide.content[:500] + "..."

            verified_slides.append(verified_slide)

        return verified_slides

    async def _generate_html_output(self, slides: List[SlideContent], theme_config: Dict[str, Any]) -> str:
        """Generate HTML output for slides"""
        try:
            # Convert SlideContent to dict format for parent class
            slides_dict = []
            for i, slide in enumerate(slides):
                slide_dict = {
                    "id": i + 1,
                    "type": slide.type,
                    "title": slide.title,
                    "subtitle": slide.subtitle or "",
                    "content": slide.content or "",
                    "bullet_points": slide.bullet_points or [],
                    "layout": slide.layout
                }
                slides_dict.append(slide_dict)

            # Create a temporary outline for the parent class method
            from ..api.models import PPTOutline
            temp_outline = PPTOutline(
                title="Generated PPT",
                slides=slides_dict,
                metadata={"theme_config": theme_config}
            )

            # Use parent class method to generate HTML
            html_content = await self.generate_slides_from_outline(temp_outline, "general")
            return html_content

        except Exception as e:
            logger.error(f"Error generating HTML output: {e}")
            # Fallback to basic HTML
            return self._generate_basic_html(slides, theme_config)

    def _extract_bullet_points(self, content: str) -> List[str]:
        """Extract bullet points from content"""
        if not content:
            return []

        bullet_points = []
        lines = content.split('\n')

        for line in lines:
            line = line.strip()
            if line.startswith('â€¢') or line.startswith('-') or line.startswith('*'):
                bullet_points.append(line[1:].strip())
            elif re.match(r'^\d+\.', line):
                bullet_points.append(line.split('.', 1)[1].strip())

        return bullet_points[:5]  # Limit to 5 bullet points

    async def _suggest_images(self, slide_title: str, scenario: str, content: str = "", topic: str = "", page_number: int = 1, total_pages: int = 1) -> List[str]:
        """Suggest images for a slide based on title and scenario"""
        try:
            # å¦‚æžœå›¾ç‰‡æœåŠ¡å¯ç”¨ï¼Œä½¿ç”¨æ™ºèƒ½å›¾ç‰‡æŽ¨è
            if self.image_service:
                # åˆ›å»ºå¹»ç¯ç‰‡ä¸Šä¸‹æ–‡
                slide_context = PPTSlideContext(
                    title=slide_title,
                    content=content,
                    scenario=scenario,
                    topic=topic,
                    page_number=page_number,
                    total_pages=total_pages,
                    language="zh"
                )

                # èŽ·å–å›¾ç‰‡å»ºè®®
                suggested_images = await self.image_service.suggest_images_for_ppt_slide(
                    slide_context, max_suggestions=5
                )

                # å¦‚æžœæ‰¾åˆ°äº†å›¾ç‰‡ï¼Œè¿”å›žå›¾ç‰‡è·¯å¾„
                if suggested_images:
                    return [img.local_path for img in suggested_images if img.local_path]

            # å›žé€€åˆ°åŸºç¡€å»ºè®®
            image_suggestions = {
                "general": ["business-meeting.jpg", "professional-chart.jpg", "office-space.jpg"],
                "tourism": ["landscape.jpg", "travel-destination.jpg", "cultural-site.jpg"],
                "education": ["classroom.jpg", "learning-materials.jpg", "students.jpg"],
                "analysis": ["data-visualization.jpg", "analytics-dashboard.jpg", "research.jpg"],
                "history": ["historical-artifact.jpg", "ancient-building.jpg", "timeline.jpg"],
                "technology": ["innovation.jpg", "digital-technology.jpg", "futuristic.jpg"],
                "business": ["corporate-building.jpg", "business-strategy.jpg", "team-meeting.jpg"]
            }

            return image_suggestions.get(scenario, image_suggestions["general"])

        except Exception as e:
            logger.error(f"Failed to suggest images: {e}")
            # è¿”å›žåŸºç¡€å»ºè®®ä½œä¸ºå›žé€€
            return ["professional-slide.jpg", "business-background.jpg", "presentation-template.jpg"]

    async def generate_slide_image(self,
                                 slide_title: str,
                                 slide_content: str,
                                 scenario: str,
                                 topic: str,
                                 page_number: int = 1,
                                 total_pages: int = 1,
                                 provider: str = "dalle") -> Optional[str]:
        """ä¸ºPPTå¹»ç¯ç‰‡ç”ŸæˆAIå›¾ç‰‡"""
        try:
            if not self.image_service:
                logger.warning("Image service not available")
                return None

            # åˆ›å»ºå¹»ç¯ç‰‡ä¸Šä¸‹æ–‡
            slide_context = PPTSlideContext(
                title=slide_title,
                content=slide_content,
                scenario=scenario,
                topic=topic,
                page_number=page_number,
                total_pages=total_pages,
                language="zh"
            )

            # é€‰æ‹©å›¾ç‰‡æä¾›è€…
            from .image.models import ImageProvider
            image_provider = ImageProvider.DALLE if provider.lower() == "dalle" else ImageProvider.STABLE_DIFFUSION

            # ç”Ÿæˆå›¾ç‰‡
            result = await self.image_service.generate_ppt_slide_image(
                slide_context, image_provider
            )

            if result.success and result.image_info:
                logger.info(f"Generated AI image for slide '{slide_title}': {result.image_info.local_path}")
                return result.image_info.local_path
            else:
                logger.warning(f"Failed to generate AI image: {result.message}")
                return None

        except Exception as e:
            logger.error(f"Error generating slide image: {e}")
            return None

    async def create_image_prompt_for_slide(self,
                                          slide_title: str,
                                          slide_content: str,
                                          scenario: str,
                                          topic: str,
                                          page_number: int = 1,
                                          total_pages: int = 1) -> str:
        """ä¸ºPPTå¹»ç¯ç‰‡åˆ›å»ºå›¾ç‰‡ç”Ÿæˆæç¤ºè¯"""
        try:
            if not self.image_service:
                return f"Professional PPT slide background for {slide_title}, {scenario} style"

            # åˆ›å»ºå¹»ç¯ç‰‡ä¸Šä¸‹æ–‡
            slide_context = PPTSlideContext(
                title=slide_title,
                content=slide_content,
                scenario=scenario,
                topic=topic,
                page_number=page_number,
                total_pages=total_pages,
                language="zh"
            )

            # ç”Ÿæˆæç¤ºè¯
            prompt = await self.image_service.create_ppt_image_prompt(slide_context)
            return prompt

        except Exception as e:
            logger.error(f"Error creating image prompt: {e}")
            return f"Professional PPT slide background for {slide_title}, {scenario} style"

    def _generate_basic_html(self, slides: List[SlideContent], theme_config: Dict[str, Any]) -> str:
        """Generate basic HTML as fallback"""
        html_parts = [
            "<!DOCTYPE html>",
            "<html>",
            "<head>",
            "<title>PPT Presentation</title>",
            "<style>",
            "body { margin: 0; padding: 0; font-family: " + theme_config.get('font_family', 'Arial, sans-serif') + "; }",
            ".presentation-container { width: 1280px; height: 720px; margin: 0 auto; position: relative; }",
            ".slide { width: 1280px; height: 720px; background: " + theme_config.get('background', '#f0f0f0') + "; padding: 40px; box-sizing: border-box; position: relative; }",
            ".title { color: " + theme_config.get('primary_color', '#333') + "; font-size: 2em; margin-bottom: 20px; }",
            ".content { color: " + theme_config.get('secondary_color', '#666') + "; font-size: 1.2em; line-height: 1.6; }",
            ".page-number { position: absolute; bottom: 20px; right: 20px; color: #999; font-size: 0.9em; }",
            "@media (max-width: 1280px) { .presentation-container, .slide { width: 100vw; height: 56.25vw; max-height: 100vh; } }",
            "</style>",
            "</head>",
            "<body>",
            "<div class='presentation-container'>"
        ]

        for i, slide in enumerate(slides):
            html_parts.extend([
                f"<div class='slide' id='slide-{i+1}'>",
                f"<h1 class='title'>{slide.title}</h1>",
                f"<div class='content'>{slide.content or ''}</div>",
                f"<div class='page-number'>{i+1}</div>",
                "</div>"
            ])

        html_parts.extend(["</div>", "</body>", "</html>"])

        return "\n".join(html_parts)

    # Project management integration methods
    async def get_project_todo_board(self, project_id: str) -> Optional[TodoBoard]:
        """Get TODO board for a project"""
        return await self.project_manager.get_todo_board(project_id)

    async def update_project_stage(self, project_id: str, stage_id: str, status: str,
                                 progress: float = None, result: Dict[str, Any] = None) -> bool:
        """Update project stage status"""
        return await self.project_manager.update_stage_status(
            project_id, stage_id, status, progress, result
        )

    async def reset_stages_from(self, project_id: str, stage_id: str) -> bool:
        """Reset all stages from the specified stage onwards"""
        try:
            project = await self.project_manager.get_project(project_id)
            if not project or not project.todo_board:
                return False

            # Find the stage index
            stage_index = -1
            for i, stage in enumerate(project.todo_board.stages):
                if stage.id == stage_id:
                    stage_index = i
                    break

            if stage_index == -1:
                logger.error(f"Stage {stage_id} not found in project {project_id}")
                return False

            # Reset all stages from the specified stage onwards
            for i in range(stage_index, len(project.todo_board.stages)):
                stage = project.todo_board.stages[i]
                stage.status = "pending"
                stage.progress = 0.0
                stage.result = None
                stage.updated_at = time.time()

            # Update current stage index
            project.todo_board.current_stage_index = stage_index

            # Recalculate overall progress
            completed_stages = sum(1 for s in project.todo_board.stages if s.status == "completed")
            project.todo_board.overall_progress = (completed_stages / len(project.todo_board.stages)) * 100
            project.todo_board.updated_at = time.time()

            # Clear related project data based on the stage being reset
            if stage_id == "outline_generation":
                # Reset outline and all subsequent data
                project.outline = None
                project.slides_html = None
                project.slides_data = None
            elif stage_id == "ppt_creation":
                # Reset only PPT data, keep outline
                project.slides_html = None
                project.slides_data = None

            project.updated_at = time.time()

            # ä¿å­˜é‡ç½®åŽçš„é¡¹ç›®çŠ¶æ€åˆ°æ•°æ®åº“
            try:
                from .db_project_manager import DatabaseProjectManager
                db_manager = DatabaseProjectManager()

                # æ›´æ–°é¡¹ç›®çŠ¶æ€
                await db_manager.update_project_status(project_id, "in_progress")

                # é‡ç½®ç›¸å…³é˜¶æ®µçŠ¶æ€åˆ°æ•°æ®åº“
                for i in range(stage_index, len(project.todo_board.stages)):
                    stage = project.todo_board.stages[i]
                    await db_manager.update_stage_status(
                        project_id,
                        stage.id,
                        "pending",
                        0.0,
                        None
                    )

                # å¦‚æžœé‡ç½®äº†å¤§çº²ç”Ÿæˆé˜¶æ®µï¼Œæ¸…é™¤æ•°æ®åº“ä¸­çš„å¤§çº²å’Œå¹»ç¯ç‰‡æ•°æ®
                if stage_id == "outline_generation":
                    # æ¸…é™¤å¤§çº²æ•°æ®
                    await db_manager.save_project_outline(project_id, None)
                    # æ¸…é™¤å¹»ç¯ç‰‡æ•°æ®
                    await db_manager.save_project_slides(project_id, "", [])
                elif stage_id == "ppt_creation":
                    # åªæ¸…é™¤å¹»ç¯ç‰‡æ•°æ®ï¼Œä¿ç•™å¤§çº²
                    await db_manager.save_project_slides(project_id, "", [])

                logger.info(f"Successfully saved reset stages to database for project {project_id}")

            except Exception as save_error:
                logger.error(f"Failed to save reset stages to database: {save_error}")
                # ç»§ç»­æ‰§è¡Œï¼Œå› ä¸ºå†…å­˜ä¸­çš„æ•°æ®å·²ç»é‡ç½®

            logger.info(f"Reset stages from {stage_id} onwards for project {project_id}")
            return True

        except Exception as e:
            logger.error(f"Error resetting stages from {stage_id}: {e}")
            return False

    async def start_workflow_from_stage(self, project_id: str, stage_id: str) -> bool:
        """Start workflow execution from a specific stage"""
        try:
            project = await self.project_manager.get_project(project_id)
            if not project:
                return False

            # Check if requirements are confirmed (needed for all stages except requirements_confirmation)
            if stage_id != "requirements_confirmation" and not project.confirmed_requirements:
                logger.error(f"Cannot start from stage {stage_id}: requirements not confirmed")
                return False

            # Start the workflow from the specified stage
            # This will be handled by the existing workflow execution logic
            # For now, just mark the stage as ready to start
            await self.project_manager.update_stage_status(
                project_id, stage_id, "pending", 0.0
            )

            logger.info(f"Workflow ready to start from stage {stage_id} for project {project_id}")
            return True

        except Exception as e:
            logger.error(f"Error starting workflow from stage {stage_id}: {e}")
            return False

    async def regenerate_slide(self, project_id: str, slide_index: int,
                             request: PPTGenerationRequest) -> Optional[SlideContent]:
        """Regenerate a specific slide"""
        try:
            project = await self.project_manager.get_project(project_id)
            if not project or not project.outline:
                return None

            if slide_index >= len(project.outline.slides):
                return None

            slide_data = project.outline.slides[slide_index]

            # Generate new content
            content = await self.generate_slide_content(
                slide_data["title"],
                request.scenario,
                request.topic,
                request.language
            )

            # Create new slide content
            new_slide = SlideContent(
                type=self._normalize_slide_type(slide_data.get("type", "content")),
                title=slide_data["title"],
                subtitle=slide_data.get("subtitle", ""),
                content=content,
                bullet_points=self._extract_bullet_points(content),
                image_suggestions=await self._suggest_images(slide_data["title"], request.scenario),
                layout="default"
            )

            return new_slide

        except Exception as e:
            logger.error(f"Error regenerating slide: {e}")
            return None

    async def lock_slide(self, project_id: str, slide_index: int) -> bool:
        """Lock a slide to prevent regeneration"""
        # This would be implemented with proper slide state management
        # For now, return True as placeholder
        return True

    async def unlock_slide(self, project_id: str, slide_index: int) -> bool:
        """Unlock a slide to allow regeneration"""
        # This would be implemented with proper slide state management
        # For now, return True as placeholder
        return True

    def _standardize_summeryfile_outline(self, summeryfile_outline: Dict[str, Any]) -> Dict[str, Any]:
        """
        å°†summeryanyfileç”Ÿæˆçš„å¤§çº²æ ¼å¼æ ‡å‡†åŒ–ä¸ºLandPPTæ ¼å¼

        Args:
            summeryfile_outline: summeryanyfileç”Ÿæˆçš„å¤§çº²æ•°æ®

        Returns:
            æ ‡å‡†åŒ–åŽçš„LandPPTæ ¼å¼å¤§çº²
        """
        try:
            # æå–åŸºæœ¬ä¿¡æ¯
            title = summeryfile_outline.get("title", "PPTå¤§çº²")
            slides_data = summeryfile_outline.get("slides", [])
            metadata = summeryfile_outline.get("metadata", {})

            # è½¬æ¢slidesæ ¼å¼
            standardized_slides = []

            for slide in slides_data:
                # ä¼˜å…ˆä½¿ç”¨content_pointså­—æ®µï¼Œå¦‚æžœæ²¡æœ‰åˆ™å°è¯•ä»Žcontentå­—æ®µæå–
                content_points = slide.get("content_points", [])

                # å¦‚æžœcontent_pointsä¸ºç©ºæˆ–ä¸æ˜¯åˆ—è¡¨ï¼Œå°è¯•ä»Žcontentå­—æ®µæå–
                if not content_points or not isinstance(content_points, list):
                    content = slide.get("content", "")
                    content_points = []

                    if content:
                        # åˆ†å‰²contentä¸ºè¦ç‚¹åˆ—è¡¨
                        lines = content.split('\n')
                        for line in lines:
                            line = line.strip()
                            if line:
                                # ç§»é™¤bullet pointç¬¦å·
                                line = re.sub(r'^[â€¢\-\*]\s*', '', line)
                                if line:
                                    content_points.append(line)

                # å¦‚æžœä»ç„¶æ²¡æœ‰content_pointsï¼Œä½¿ç”¨é»˜è®¤å€¼
                if not content_points:
                    content_points = ["å†…å®¹è¦ç‚¹"]

                # æ ‡å‡†åŒ–slide_type
                slide_type = slide.get("slide_type", slide.get("type", "content"))
                page_number = slide.get("page_number", slide.get("id", 1))
                title_text = slide.get("title", "").lower()

                # æ›´æ™ºèƒ½çš„slide_typeè¯†åˆ« - ä¿ç•™summeryanyfileçš„åŽŸå§‹ç±»åž‹
                if slide_type not in ["title", "content", "agenda", "thankyou", "conclusion"]:
                    if page_number == 1 or "æ ‡é¢˜" in title_text or "title" in title_text:
                        slide_type = "title"
                    elif "ç›®å½•" in title_text or "agenda" in title_text or "å¤§çº²" in title_text:
                        slide_type = "agenda"
                    elif "è°¢è°¢" in title_text or "thank" in title_text or "è‡´è°¢" in title_text:
                        slide_type = "thankyou"
                    elif "æ€»ç»“" in title_text or "ç»“è®º" in title_text or "conclusion" in title_text or "summary" in title_text:
                        slide_type = "conclusion"
                    else:
                        slide_type = "content"
                else:
                    # å³ä½¿å·²ç»æœ‰slide_typeï¼Œä¹Ÿè¦æ£€æŸ¥ç‰¹æ®Šé¡µé¢ç±»åž‹
                    if ("ç›®å½•" in title_text or "agenda" in title_text or "å¤§çº²" in title_text) and slide_type == "content":
                        slide_type = "agenda"
                    elif ("è°¢è°¢" in title_text or "thank" in title_text or "è‡´è°¢" in title_text) and slide_type == "content":
                        slide_type = "thankyou"
                    elif ("æ€»ç»“" in title_text or "ç»“è®º" in title_text or "conclusion" in title_text or "summary" in title_text) and slide_type == "content":
                        slide_type = "conclusion"

                # æ˜ å°„slide_typeåˆ°enhanced_ppt_serviceæœŸæœ›çš„typeå­—æ®µ
                type_mapping = {
                    "title": "title",
                    "content": "content",
                    "conclusion": "thankyou",
                    "agenda": "agenda"
                }
                mapped_type = type_mapping.get(slide_type, "content")

                # æž„å»ºæ ‡å‡†åŒ–çš„slideå¯¹è±¡
                standardized_slide = {
                    "page_number": slide.get("page_number", slide.get("id", len(standardized_slides) + 1)),
                    "title": slide.get("title", f"ç¬¬{len(standardized_slides) + 1}é¡µ"),
                    "content_points": content_points,
                    "slide_type": slide_type,  # ä¿ç•™åŽŸå§‹å­—æ®µ
                    "type": mapped_type,  # æ·»åŠ enhanced_ppt_serviceæœŸæœ›çš„typeå­—æ®µ
                    "description": slide.get("description", "")  # ä¿ç•™æè¿°å­—æ®µ
                }

                # å¦‚æžœåŽŸå§‹slideåŒ…å«chart_configï¼Œåˆ™ä¿ç•™
                if "chart_config" in slide and slide["chart_config"]:
                    standardized_slide["chart_config"] = slide["chart_config"]

                standardized_slides.append(standardized_slide)

            # æž„å»ºæ ‡å‡†åŒ–çš„metadata
            standardized_metadata = {
                "generated_with_summeryfile": True,
                "page_count_settings": {
                    "mode": metadata.get("page_count_mode", "ai_decide"),
                    "min_pages": None,
                    "max_pages": None,
                    "fixed_pages": None
                },
                "actual_page_count": len(standardized_slides),
                "generated_at": time.time(),
                "original_metadata": metadata  # ä¿ç•™åŽŸå§‹å…ƒæ•°æ®
            }

            # å¦‚æžœåŽŸå§‹metadataä¸­æœ‰é¡µæ•°è®¾ç½®ï¼Œå°è¯•è½¬æ¢
            if "total_pages" in metadata:
                standardized_metadata["page_count_settings"]["expected_pages"] = metadata["total_pages"]

            # æž„å»ºæ ‡å‡†åŒ–çš„å¤§çº²
            standardized_outline = {
                "title": title,
                "slides": standardized_slides,
                "metadata": standardized_metadata
            }

            logger.info(f"Successfully standardized summeryfile outline: {title}, {len(standardized_slides)} slides")
            return standardized_outline

        except Exception as e:
            logger.error(f"Error standardizing summeryfile outline: {e}")
            # è¿”å›žé»˜è®¤ç»“æž„
            return {
                "title": "PPTå¤§çº²",
                "slides": [
                    {
                        "page_number": 1,
                        "title": "æ ‡é¢˜é¡µ",
                        "content_points": ["æ¼”ç¤ºæ ‡é¢˜", "æ¼”ç¤ºè€…", "æ—¥æœŸ"],
                        "slide_type": "title",
                        "type": "title",  # æ·»åŠ typeå­—æ®µ
                        "description": "PPTæ ‡é¢˜é¡µ"
                    }
                ],
                "metadata": {
                    "generated_with_summeryfile": True,
                    "page_count_settings": {"mode": "ai_decide"},
                    "actual_page_count": 1,
                    "generated_at": time.time(),
                    "error": str(e)
                }
            }

    async def generate_outline_from_file(self, request) -> Dict[str, Any]:
        """ä½¿ç”¨summeryanyfileä»Žæ–‡ä»¶ç”ŸæˆPPTå¤§çº²"""
        # å¯¼å…¥å¿…è¦çš„æ¨¡å—
        from ..api.models import FileOutlineGenerationResponse

        try:
            # å°è¯•ä½¿ç”¨summeryanyfileç”Ÿæˆå¤§çº²
            logger.info(f"å¼€å§‹ä½¿ç”¨summeryanyfileä»Žæ–‡ä»¶ç”ŸæˆPPTå¤§çº²: {request.filename}")

            try:
                # å¯¼å…¥summeryanyfileæ¨¡å—
                from summeryanyfile.generators.ppt_generator import PPTOutlineGenerator
                from summeryanyfile.core.models import ProcessingConfig, ChunkStrategy

                # èŽ·å–æœ€æ–°çš„AIé…ç½®
                current_ai_config = self._get_current_ai_config()
                logger.info(f"ä½¿ç”¨æœ€æ–°AIé…ç½®: provider={current_ai_config['llm_provider']}, model={current_ai_config['llm_model']}")

                # åˆ›å»ºé…ç½® - ä½¿ç”¨æœ€æ–°çš„AIé…ç½®
                min_slides, max_slides = self._get_slides_range_from_request(request)
                config = ProcessingConfig(
                    min_slides=min_slides,
                    max_slides=max_slides,
                    chunk_size=self._get_chunk_size_from_request(request),
                    chunk_strategy=self._get_chunk_strategy_from_request(request),
                    llm_model=current_ai_config["llm_model"],
                    llm_provider=current_ai_config["llm_provider"],
                    temperature=current_ai_config["temperature"],
                    max_tokens=current_ai_config["max_tokens"],
                    target_language=request.language  # ä½¿ç”¨ç”¨æˆ·åœ¨è¡¨å•ä¸­é€‰æ‹©çš„è¯­è¨€
                )

                # æ ¹æ®file_processing_modeè®¾ç½®use_magic_pdfå‚æ•°
                use_magic_pdf = request.file_processing_mode == "magic_pdf"
                logger.info(f"æ–‡ä»¶å¤„ç†æ¨¡å¼: {request.file_processing_mode}, ä½¿ç”¨Magic-PDF: {use_magic_pdf}")

                # åˆ›å»ºç”Ÿæˆå™¨å¹¶ä¼ é€’APIé…ç½®å’Œæ–‡ä»¶å¤„ç†æ¨¡å¼
                # è®¾ç½®ç¼“å­˜ç›®å½•åˆ°é¡¹ç›®æ ¹ç›®å½•ä¸‹çš„tempæ–‡ä»¶å¤¹
                from pathlib import Path
                project_root = Path(__file__).parent.parent.parent.parent
                cache_dir = project_root / "temp" / "summeryanyfile_cache"

                generator = PPTOutlineGenerator(config, use_magic_pdf=use_magic_pdf, cache_dir=str(cache_dir))

                # è®¾ç½®APIé…ç½®åˆ°LLMç®¡ç†å™¨
                self._configure_summeryfile_api(generator)

                # ä»Žæ–‡ä»¶ç”Ÿæˆå¤§çº²
                logger.info(f"æ­£åœ¨ä½¿ç”¨summeryanyfileå¤„ç†æ–‡ä»¶: {request.file_path}")
                outline = await generator.generate_from_file(
                    request.file_path,
                    project_topic=request.topic or "",
                    project_scenario=request.scenario or "general",
                    project_requirements=getattr(request, 'requirements', '') or "",
                    target_audience=getattr(request, 'target_audience', 'æ™®é€šå¤§ä¼—'),
                    custom_audience="",  # FileOutlineGenerationRequest æ²¡æœ‰ custom_audience å±žæ€§
                    ppt_style=getattr(request, 'ppt_style', 'general'),
                    custom_style_prompt=getattr(request, 'custom_style_prompt', ''),
                    page_count_mode=getattr(request, 'page_count_mode', 'ai_decide'),
                    min_pages=getattr(request, 'min_pages', None),
                    max_pages=getattr(request, 'max_pages', None),
                    fixed_pages=getattr(request, 'fixed_pages', None)
                )

                logger.info(f"summeryanyfileç”ŸæˆæˆåŠŸ: {outline.title}, å…±{outline.total_pages}é¡µ")

                # è½¬æ¢ä¸ºLandPPTæ ¼å¼ - ä½¿ç”¨æ–°çš„æ ‡å‡†åŒ–å‡½æ•°
                summeryfile_dict = outline.to_dict()
                landppt_outline = self._standardize_summeryfile_outline(summeryfile_dict)

                # éªŒè¯å’Œä¿®å¤æ–‡ä»¶ç”Ÿæˆçš„å¤§çº²
                # æž„å»ºconfirmed_requirementsç”¨äºŽéªŒè¯
                confirmed_requirements = {
                    'topic': request.topic or landppt_outline.get('title', 'æ–‡æ¡£æ¼”ç¤º'),
                    'target_audience': getattr(request, 'target_audience', 'é€šç”¨å—ä¼—'),
                    'focus_content': [],  # FileOutlineGenerationRequest æ²¡æœ‰ focus_content å±žæ€§
                    'tech_highlights': [],  # FileOutlineGenerationRequest æ²¡æœ‰ tech_highlights å±žæ€§
                    'page_count_settings': {
                        'mode': request.page_count_mode,
                        'min_pages': getattr(request, 'min_pages', None),
                        'max_pages': getattr(request, 'max_pages', None),
                        'fixed_pages': getattr(request, 'fixed_pages', None)
                    }
                }

                landppt_outline = await self._validate_and_repair_outline_json(landppt_outline, confirmed_requirements)

                # èŽ·å–æ–‡ä»¶ä¿¡æ¯
                file_info = {
                    "filename": request.filename,
                    "file_path": request.file_path,
                    "processing_mode": request.file_processing_mode,
                    "analysis_depth": request.content_analysis_depth,
                    "used_summeryanyfile": True
                }

                # èŽ·å–å¤„ç†ç»Ÿè®¡ä¿¡æ¯
                processing_stats = {
                    "total_pages": outline.total_pages,
                    "page_count_mode": request.page_count_mode,
                    "slides_count": len(outline.slides),
                    "processing_time": "å®Œæˆ",
                    "generator": "summeryanyfile"
                }

                return FileOutlineGenerationResponse(
                    success=True,
                    outline=landppt_outline,
                    file_info=file_info,
                    processing_stats=processing_stats,
                    message=f"æˆåŠŸä½¿ç”¨summeryanyfileä»Žæ–‡ä»¶ {request.filename} ç”ŸæˆPPTå¤§çº²ï¼Œå…±{len(outline.slides)}é¡µ"
                )

            except ImportError as ie:
                logger.warning(f"summeryanyfileæ¨¡å—ä¸å¯ç”¨: {ie}ï¼Œä½¿ç”¨ç®€åŒ–ç‰ˆæœ¬")
                return await self._generate_outline_from_file_fallback(request)
            except Exception as se:
                logger.error(f"summeryanyfileç”Ÿæˆå¤±è´¥: {se}ï¼Œä½¿ç”¨ç®€åŒ–ç‰ˆæœ¬")
                return await self._generate_outline_from_file_fallback(request)

        except Exception as e:
            logger.error(f"ä»Žæ–‡ä»¶ç”Ÿæˆå¤§çº²å¤±è´¥: {e}")
            return FileOutlineGenerationResponse(
                success=False,
                error=str(e),
                message=f"ä»Žæ–‡ä»¶ç”Ÿæˆå¤§çº²å¤±è´¥: {str(e)}"
            )

    def _convert_summeryfile_outline_to_landppt(self, summery_outline, request) -> Dict[str, Any]:
        """å°†summeryanyfileçš„å¤§çº²æ ¼å¼è½¬æ¢ä¸ºLandPPTæ ¼å¼"""
        try:
            slides = []

            for i, slide in enumerate(summery_outline.slides):
                # è½¬æ¢å¹»ç¯ç‰‡ç±»åž‹
                slide_type = "content"
                if slide.slide_type == "title":
                    slide_type = "title"
                elif slide.slide_type == "agenda":
                    slide_type = "agenda"
                elif slide.slide_type == "conclusion":
                    slide_type = "thankyou"

                # æž„å»ºå†…å®¹ç‚¹
                content_points = slide.content_points if hasattr(slide, 'content_points') else []
                if isinstance(content_points, list):
                    content = "\n".join([f"â€¢ {point}" for point in content_points])
                else:
                    content = str(content_points)

                landppt_slide = {
                    "id": i + 1,
                    "type": slide_type,
                    "title": slide.title,
                    "subtitle": getattr(slide, 'subtitle', ''),
                    "content": content,
                    "page_number": getattr(slide, 'page_number', i + 1),
                    "description": getattr(slide, 'description', ''),
                    "slide_type": slide_type,
                    "content_points": slide.content_points if hasattr(slide, 'content_points') else []
                }

                slides.append(landppt_slide)

            # æž„å»ºå®Œæ•´çš„å¤§çº²
            landppt_outline = {
                "title": summery_outline.title,
                "slides": slides,
                "metadata": {
                    "scenario": request.scenario,
                    "language": "zh",
                    "total_slides": len(slides),
                    "generated_with_summeryfile": True,
                    "file_source": request.filename,
                    "page_count_mode": summery_outline.page_count_mode,
                    "total_pages": summery_outline.total_pages,
                    "ppt_style": request.ppt_style,
                    "focus_content": request.focus_content,
                    "tech_highlights": request.tech_highlights,
                    "target_audience": request.target_audience
                }
            }

            return landppt_outline

        except Exception as e:
            logger.error(f"å¤§çº²æ ¼å¼è½¬æ¢å¤±è´¥: {e}")
            # è¿”å›žåŸºæœ¬æ ¼å¼
            return {
                "title": request.topic or "æ–‡æ¡£æ¼”ç¤º",
                "slides": [
                    {
                        "id": 1,
                        "type": "title",
                        "title": request.topic or "æ–‡æ¡£æ¼”ç¤º",
                        "subtitle": "åŸºäºŽæ–‡æ¡£å†…å®¹ç”Ÿæˆ",
                        "content": ""
                    }
                ],
                "metadata": {
                    "scenario": request.scenario,
                    "language": "zh",
                    "total_slides": 1,
                    "generated_with_summeryfile": False,
                    "error": str(e)
                }
            }

    def _get_max_slides_from_request(self, request) -> int:
        """æ ¹æ®è¯·æ±‚èŽ·å–æœ€å¤§å¹»ç¯ç‰‡æ•°é‡"""
        if request.page_count_mode == "fixed":
            return request.fixed_pages or 20
        elif request.page_count_mode == "custom_range":
            return request.max_pages or 20
        else:  # ai_decide
            return 25  # é»˜è®¤æœ€å¤§å€¼

    def _get_slides_range_from_request(self, request) -> tuple[int, int]:
        """æ ¹æ®è¯·æ±‚èŽ·å–å¹»ç¯ç‰‡æ•°é‡èŒƒå›´"""
        if request.page_count_mode == "fixed":
            fixed_pages = request.fixed_pages or 10
            return fixed_pages, fixed_pages
        elif request.page_count_mode == "custom_range":
            min_pages = request.min_pages or 8
            max_pages = request.max_pages or 15
            return min_pages, max_pages
        else:  # ai_decide
            # AIå†³å®šæ¨¡å¼ï¼šè®¾ç½®ä¸€ä¸ªå®½æ³›çš„èŒƒå›´ï¼Œä½†ä¸»è¦é€šè¿‡æç¤ºè¯è®©AIè‡ªä¸»å†³å®š
            return 5, 30  # å®½æ³›èŒƒå›´ï¼Œå®žé™…ç”±AIæ ¹æ®å†…å®¹å†³å®š

    def _get_chunk_size_from_request(self, request) -> int:
        """æ ¹æ®è¯·æ±‚èŽ·å–åˆ†å—å¤§å°"""
        if request.content_analysis_depth == "fast":
            return 1500  # å¿«é€Ÿåˆ†å—ï¼Œé€‚åˆç ”ç©¶æŠ¥å‘Šçš„å¿«é€Ÿå¤„ç†
        elif request.content_analysis_depth == "deep":
            return 4000
        else:  # standard
            return 3000

    def _get_chunk_strategy_from_request(self, request):
        """æ ¹æ®è¯·æ±‚èŽ·å–åˆ†å—ç­–ç•¥"""
        try:
            from summeryanyfile.core.models import ChunkStrategy

            if request.content_analysis_depth == "fast":
                return ChunkStrategy.FAST
            elif request.content_analysis_depth == "deep":
                return ChunkStrategy.HYBRID
            else:  # standard
                return ChunkStrategy.PARAGRAPH
        except ImportError:
            return "paragraph"  # å›žé€€å€¼

    async def _generate_outline_from_file_fallback(self, request):
        """å½“summeryanyfileä¸å¯ç”¨æ—¶çš„å›žé€€æ–¹æ³•"""
        from ..api.models import FileOutlineGenerationResponse

        logger.info(f"ä½¿ç”¨ç®€åŒ–ç‰ˆæœ¬ä»Žæ–‡ä»¶ç”ŸæˆPPTå¤§çº²: {request.filename}")

        try:
            # åœ¨çº¿ç¨‹æ± ä¸­è¯»å–æ–‡ä»¶å†…å®¹
            content = await run_blocking_io(self._read_file_with_fallback_encoding, request.file_path)
        except Exception as e:
            logger.error(f"Failed to read file {request.file_path}: {e}")
            raise

        # åˆ›å»ºåŸºäºŽæ–‡ä»¶å†…å®¹çš„PPTå¤§çº²
        landppt_outline = self._create_outline_from_file_content(content, request)

        # éªŒè¯å’Œä¿®å¤fallbackç”Ÿæˆçš„å¤§çº²
        # æž„å»ºconfirmed_requirementsç”¨äºŽéªŒè¯
        confirmed_requirements = {
            'topic': request.topic or landppt_outline.get('title', 'æ–‡æ¡£æ¼”ç¤º'),
            'target_audience': getattr(request, 'target_audience', 'é€šç”¨å—ä¼—'),
            'focus_content': [],  # FileOutlineGenerationRequest æ²¡æœ‰ focus_content å±žæ€§
            'tech_highlights': [],  # FileOutlineGenerationRequest æ²¡æœ‰ tech_highlights å±žæ€§
            'page_count_settings': {
                'mode': request.page_count_mode,
                'min_pages': getattr(request, 'min_pages', None),
                'max_pages': getattr(request, 'max_pages', None),
                'fixed_pages': getattr(request, 'fixed_pages', None)
            }
        }

        landppt_outline = await self._validate_and_repair_outline_json(landppt_outline, confirmed_requirements)

        # èŽ·å–æ–‡ä»¶ä¿¡æ¯
        file_info = {
            "filename": request.filename,
            "file_path": request.file_path,
            "processing_mode": request.file_processing_mode,
            "analysis_depth": request.content_analysis_depth,
            "used_summeryanyfile": False
        }

        # èŽ·å–å¤„ç†ç»Ÿè®¡ä¿¡æ¯
        slides_count = len(landppt_outline.get('slides', []))
        processing_stats = {
            "total_pages": slides_count,
            "page_count_mode": request.page_count_mode,
            "slides_count": slides_count,
            "processing_time": "å®Œæˆ",
            "generator": "fallback"
        }

        logger.info(f"ç®€åŒ–ç‰ˆæœ¬å¤§çº²ç”ŸæˆæˆåŠŸ: {landppt_outline.get('title', 'æœªçŸ¥')}, å…±{slides_count}é¡µ")

        return FileOutlineGenerationResponse(
            success=True,
            outline=landppt_outline,
            file_info=file_info,
            processing_stats=processing_stats,
            message=f"æˆåŠŸä»Žæ–‡ä»¶ {request.filename} ç”ŸæˆPPTå¤§çº²ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰ï¼Œå…±{slides_count}é¡µ"
        )

    def _create_outline_from_file_content(self, content: str, request) -> Dict[str, Any]:
        """ä»Žæ–‡ä»¶å†…å®¹åˆ›å»ºPPTå¤§çº²ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰"""
        try:
            # æå–æ ‡é¢˜
            lines = content.strip().split('\n')
            title = request.topic or lines[0].strip() if lines else "æ–‡æ¡£æ¼”ç¤º"

            # ç®€å•çš„å†…å®¹åˆ†æž
            sections = []
            current_section = None

            for line in lines:
                line = line.strip()
                if not line:
                    continue

                # æ£€æµ‹æ ‡é¢˜ï¼ˆæ•°å­—å¼€å¤´æˆ–ç‰¹æ®Šå­—ç¬¦ï¼‰
                if (line.startswith(('1.', '2.', '3.', '4.', '5.', '6.', '7.', '8.', '9.')) or
                    line.startswith(('#', '##', '###')) or
                    len(line) < 50 and not line.endswith('ã€‚')):

                    if current_section:
                        sections.append(current_section)

                    current_section = {
                        "title": line.replace('#', '').replace('1.', '').replace('2.', '').replace('3.', '').strip(),
                        "content": []
                    }
                elif current_section:
                    current_section["content"].append(line)

            if current_section:
                sections.append(current_section)

            # åˆ›å»ºå¹»ç¯ç‰‡
            slides = []

            # æ ‡é¢˜é¡µ
            slides.append({
                "page_number": 1,
                "title": title,
                "content_points": ["åŸºäºŽæ–‡æ¡£å†…å®¹ç”Ÿæˆ", "æ¼”ç¤ºè€…", "æ—¥æœŸ"],
                "slide_type": "title"
            })

            # ç›®å½•é¡µ
            if len(sections) > 1:
                agenda_points = [section['title'] for section in sections[:8]]
                slides.append({
                    "page_number": 2,
                    "title": "ç›®å½•",
                    "content_points": agenda_points,
                    "slide_type": "agenda"
                })

            # å†…å®¹é¡µ
            for i, section in enumerate(sections[:10], start=len(slides) + 1):
                content_points = section["content"][:5] if section["content"] else ["å†…å®¹è¦ç‚¹1", "å†…å®¹è¦ç‚¹2"]
                slides.append({
                    "page_number": i,
                    "title": section["title"],
                    "content_points": content_points,
                    "slide_type": "content"
                })

            # ç»“æŸé¡µ
            slides.append({
                "page_number": len(slides) + 1,
                "title": "è°¢è°¢",
                "content_points": ["æ„Ÿè°¢è†å¬", "æ¬¢è¿Žæé—®"],
                "slide_type": "thankyou"
            })

            # æ ¹æ®é¡µæ•°è®¾ç½®è°ƒæ•´
            if request.page_count_mode == "fixed" and request.fixed_pages:
                target_pages = request.fixed_pages
                if len(slides) > target_pages:
                    slides = slides[:target_pages]
                elif len(slides) < target_pages:
                    # æ·»åŠ æ›´å¤šå†…å®¹é¡µ
                    for i in range(len(slides), target_pages):
                        slides.append({
                            "page_number": i + 1,
                            "title": f"è¡¥å……å†…å®¹ {i - 1}",
                            "content_points": ["å¾…è¡¥å……çš„å†…å®¹è¦ç‚¹", "æ ¹æ®éœ€è¦æ·»åŠ è¯¦ç»†ä¿¡æ¯"],
                            "slide_type": "content"
                        })

            return {
                "title": title,
                "slides": slides,
                "metadata": {
                    "scenario": request.scenario,
                    "language": "zh",
                    "total_slides": len(slides),
                    "generated_with_file": True,
                    "file_source": request.filename,
                    "page_count_mode": request.page_count_mode,
                    "total_pages": len(slides),
                    "ppt_style": request.ppt_style,
                    "focus_content": request.focus_content,
                    "tech_highlights": request.tech_highlights,
                    "target_audience": request.target_audience
                }
            }

        except Exception as e:
            logger.error(f"ä»Žæ–‡ä»¶å†…å®¹åˆ›å»ºå¤§çº²å¤±è´¥: {e}")
            # è¿”å›žåŸºæœ¬æ ¼å¼
            return {
                "title": request.topic or "æ–‡æ¡£æ¼”ç¤º",
                "slides": [
                    {
                        "page_number": 1,
                        "title": request.topic or "æ–‡æ¡£æ¼”ç¤º",
                        "content_points": ["åŸºäºŽæ–‡æ¡£å†…å®¹ç”Ÿæˆ", "æ¼”ç¤ºè€…", "æ—¥æœŸ"],
                        "slide_type": "title"
                    }
                ],
                "metadata": {
                    "scenario": request.scenario,
                    "language": "zh",
                    "total_slides": 1,
                    "generated_with_file": False,
                    "error": str(e)
                }
            }

    async def _ensure_global_master_template_selected(self, project_id: str) -> Optional[Dict[str, Any]]:
        """ç¡®ä¿é¡¹ç›®å·²é€‰æ‹©å…¨å±€æ¯ç‰ˆæ¨¡æ¿ï¼Œå¦‚æžœæ²¡æœ‰åˆ™ä½¿ç”¨é»˜è®¤æ¨¡æ¿"""
        try:
            # æ£€æŸ¥é¡¹ç›®æ˜¯å¦å·²æœ‰é€‰æ‹©çš„æ¨¡æ¿ï¼ˆå¯ä»¥åœ¨é¡¹ç›®å…ƒæ•°æ®ä¸­å­˜å‚¨ï¼‰
            project = await self.project_manager.get_project(project_id)
            if not project:
                logger.error(f"Project {project_id} not found")
                return None

            # æ£€æŸ¥é¡¹ç›®å…ƒæ•°æ®ä¸­æ˜¯å¦å·²æœ‰é€‰æ‹©çš„æ¨¡æ¿ID
            selected_template_id = None
            if hasattr(project, 'project_metadata') and project.project_metadata:
                selected_template_id = project.project_metadata.get('selected_global_template_id')

            # å¦‚æžœå·²æœ‰é€‰æ‹©çš„æ¨¡æ¿ï¼ŒèŽ·å–æ¨¡æ¿ä¿¡æ¯
            if selected_template_id:
                template = await self.global_template_service.get_template_by_id(selected_template_id)
                if template and template.get('is_active', True):
                    logger.info(f"Project {project_id} using selected template: {template['template_name']}")
                    return template

            # å¦‚æžœæ²¡æœ‰é€‰æ‹©æˆ–é€‰æ‹©çš„æ¨¡æ¿ä¸å¯ç”¨ï¼Œä½¿ç”¨é»˜è®¤æ¨¡æ¿
            default_template = await self.global_template_service.get_default_template()
            if default_template:
                # å°†é»˜è®¤æ¨¡æ¿IDä¿å­˜åˆ°é¡¹ç›®å…ƒæ•°æ®ä¸­
                await self._save_selected_template_to_project(project_id, default_template['id'])
                logger.info(f"Project {project_id} using default template: {default_template['template_name']}")
                return default_template

            logger.warning(f"No global master template available for project {project_id}")
            return None

        except Exception as e:
            logger.error(f"Error ensuring global master template for project {project_id}: {e}")
            return None

    async def _save_selected_template_to_project(self, project_id: str, template_id: int):
        """å°†é€‰æ‹©çš„æ¨¡æ¿IDä¿å­˜åˆ°é¡¹ç›®å…ƒæ•°æ®ä¸­"""
        try:
            project = await self.project_manager.get_project(project_id)
            if project:
                # æ›´æ–°é¡¹ç›®å…ƒæ•°æ®
                project_metadata = project.project_metadata or {}
                project_metadata['selected_global_template_id'] = template_id

                # ä¿å­˜æ›´æ–°çš„å…ƒæ•°æ®
                await self.project_manager.update_project_metadata(project_id, project_metadata)
                logger.info(f"Saved selected template {template_id} to project {project_id}")

        except Exception as e:
            logger.error(f"Error saving selected template to project {project_id}: {e}")

    async def select_global_template_for_project(self, project_id: str, template_id: Optional[int] = None) -> Dict[str, Any]:
        """ä¸ºé¡¹ç›®é€‰æ‹©å…¨å±€æ¯ç‰ˆæ¨¡æ¿"""
        try:
            if template_id:
                # éªŒè¯æ¨¡æ¿æ˜¯å¦å­˜åœ¨ä¸”å¯ç”¨
                template = await self.global_template_service.get_template_by_id(template_id)
                if not template:
                    raise ValueError(f"Template {template_id} not found")
                if not template.get('is_active', True):
                    raise ValueError(f"Template {template_id} is not active")
            else:
                # ä½¿ç”¨é»˜è®¤æ¨¡æ¿
                template = await self.global_template_service.get_default_template()
                if not template:
                    raise ValueError("No default template available")
                template_id = template['id']

            # ä¿å­˜é€‰æ‹©åˆ°é¡¹ç›®
            await self._save_selected_template_to_project(project_id, template_id)

            # å¢žåŠ æ¨¡æ¿ä½¿ç”¨æ¬¡æ•°
            await self.global_template_service.increment_template_usage(template_id)

            return {
                "success": True,
                "message": "Template selected successfully",
                "selected_template": template
            }

        except Exception as e:
            logger.error(f"Error selecting global template for project {project_id}: {e}")
            return {
                "success": False,
                "message": str(e),
                "selected_template": None
            }

    async def get_selected_global_template(self, project_id: str) -> Optional[Dict[str, Any]]:
        """èŽ·å–é¡¹ç›®é€‰æ‹©çš„å…¨å±€æ¯ç‰ˆæ¨¡æ¿"""
        try:
            project = await self.project_manager.get_project(project_id)
            if not project:
                return None

            # ä»Žé¡¹ç›®å…ƒæ•°æ®ä¸­èŽ·å–é€‰æ‹©çš„æ¨¡æ¿ID
            selected_template_id = None
            if hasattr(project, 'project_metadata') and project.project_metadata:
                selected_template_id = project.project_metadata.get('selected_global_template_id')

            if selected_template_id:
                return await self.global_template_service.get_template_by_id(selected_template_id)

            return None

        except Exception as e:
            logger.error(f"Error getting selected global template for project {project_id}: {e}")
            return None

    def clear_cached_style_genes(self, project_id: Optional[str] = None):
        """æ¸…ç†ç¼“å­˜çš„è®¾è®¡åŸºå› """
        if not hasattr(self, '_cached_style_genes'):
            return

        if project_id:
            # æ¸…ç†ç‰¹å®šé¡¹ç›®çš„ç¼“å­˜
            if project_id in self._cached_style_genes:
                del self._cached_style_genes[project_id]
                logger.info(f"æ¸…ç†é¡¹ç›® {project_id} çš„è®¾è®¡åŸºå› ç¼“å­˜")
        else:
            # æ¸…ç†æ‰€æœ‰ç¼“å­˜
            self._cached_style_genes.clear()
            logger.info("æ¸…ç†æ‰€æœ‰è®¾è®¡åŸºå› ç¼“å­˜")

    def get_cached_style_genes_info(self) -> Dict[str, Any]:
        """èŽ·å–ç¼“å­˜çš„è®¾è®¡åŸºå› ä¿¡æ¯"""
        if not hasattr(self, '_cached_style_genes'):
            return {"cached_projects": [], "total_count": 0}

        return {
            "cached_projects": list(self._cached_style_genes.keys()),
            "total_count": len(self._cached_style_genes)
        }

    def _read_file_with_fallback_encoding(self, file_path: str) -> str:
        """ä½¿ç”¨å¤šç§ç¼–ç å°è¯•è¯»å–æ–‡ä»¶ï¼ˆåœ¨çº¿ç¨‹æ± ä¸­è¿è¡Œï¼‰"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                return f.read()
        except UnicodeDecodeError:
            # å°è¯•å…¶ä»–ç¼–ç 
            try:
                with open(file_path, 'r', encoding='gbk') as f:
                    return f.read()
            except:
                with open(file_path, 'r', encoding='latin-1') as f:
                    return f.read()

    def _save_research_to_temp_file(self, research_content: str) -> str:
        """å°†ç ”ç©¶å†…å®¹ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶ï¼ˆåœ¨çº¿ç¨‹æ± ä¸­è¿è¡Œï¼‰"""
        import tempfile
        with tempfile.NamedTemporaryFile(mode='w', suffix='.md', delete=False, encoding='utf-8') as temp_file:
            temp_file.write(research_content)
            return temp_file.name

    def _cleanup_temp_file(self, file_path: str) -> None:
        """æ¸…ç†ä¸´æ—¶æ–‡ä»¶ï¼ˆåœ¨çº¿ç¨‹æ± ä¸­è¿è¡Œï¼‰"""
        import os
        if os.path.exists(file_path):
            os.unlink(file_path)
